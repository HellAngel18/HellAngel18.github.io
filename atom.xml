<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>地狱天使&#39;s Blog</title>
  
  <subtitle>欢迎来到我的世界</subtitle>
  <link href="http://lixrangel.com/atom.xml" rel="self"/>
  
  <link href="http://lixrangel.com/"/>
  <updated>2026-01-26T07:36:02.974Z</updated>
  <id>http://lixrangel.com/</id>
  
  <author>
    <name>地狱天使</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Redis集群</title>
    <link href="http://lixrangel.com/2025/12/29/java-ba-gu/redis/redis-ji-qun/"/>
    <id>http://lixrangel.com/2025/12/29/java-ba-gu/redis/redis-ji-qun/</id>
    <published>2025-12-28T16:00:00.000Z</published>
    <updated>2026-01-26T07:36:02.974Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis主从同步"><a href="#Redis主从同步" class="headerlink" title="Redis主从同步"></a>Redis主从同步</h2><p>单节点的redis并发能力是有上限的，要进一步提高redis的并发能力，就需要搭建主从集群，实现读写分离。一般都是一主多从，主节点负责写数据，从节点负责读数据。</p><h3 id="完全同步"><a href="#完全同步" class="headerlink" title="完全同步"></a>完全同步</h3><ul><li>发生情况：<ul><li><strong>初次同步</strong>：当一个从服务器（slave）首次连接到主服务器（master）时，会进行一次完全同步。</li><li><strong>从服务器数据丢失</strong>：如果从服务器数据因为某种原因（如断电）丢失，会请求进行完全同步。</li><li><strong>主服务器数据发生变化</strong>：如果从服务器长时间未与主服务器同步，导致数据差异太大，也可能触发完全同步。</li></ul></li><li>完全同步过程：<ol><li><strong>从节点发送命令</strong>：从节点向主节点发送<code>PSYNC ? -1</code>命令，请求同步数据（-1表示我是新来的，没有之前的同步速度）。</li><li><strong>主节点确认同步</strong>：主节点收到命令后，判断需要进行完全同步，于是返回<code>FULLRESYNC &lt;runid&gt; &lt;offset&gt;</code>。<ul><li><code>runid</code>：主节点的运行id；</li><li><code>offset</code>：当前的复制偏移量。</li><li>从节点保存这些信息。</li></ul></li><li><strong>fork子进程生成RDB</strong>：主节点执行<code>BGSAVE</code>命令，fork出一个子进程，将当前内存中的全量数据生成RDB快照文件。</li><li><strong>主节点发送RDB</strong>：RDB生成完成后，主节点通过网络将该文件发送给从节点。</li><li><strong>从节点加载</strong>：从节点接收完RDB文件后，会先清空自己当前数据库中的所有数据库，将RDB文件写入本地磁盘，然后再从本地磁盘加载到内存。这个过程中<font color="#ff0000">从节点会阻塞</font>。（在清空旧数据之前，从节点依然会基于旧的数据版本对外提供服务）。</li><li><strong>写入缓冲区</strong>：在主节点生成和发送RDB的这段时间里，<font color="#ff0000">主节点并没有阻塞写操作</font>。所有新接收到的写命令，会被写入到专门为该从节点分配的<font color="#ff0000">Replication Buffer（复制缓冲区）</font>中。</li><li><strong>发送缓冲命令</strong>：当从节点RDB加载完成后，通知主节点。主节点将Replication Buffer 中<font color="#ff0000">积压的所有写命令发送给从节点</font>。</li><li><strong>最终一致</strong>：<font color="#ff0000">从节点执行这些写命令</font>，此时主从节点的数据状态达到一致。之后双方进入“命令传播”阶段，进行持续的增量同步。<br><img src="Redis%E5%85%A8%E9%87%8F%E5%A4%8D%E5%88%B6.png" alt="Redis全量复制"></li></ol></li></ul><h3 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h3><ul><li>增量同步是“断网重连”后的补救措施。</li><li>增量同步过程：<ol><li>从服务器在恢复网络后，会发送<code>PSYNC</code>命令给主服务器，此时的<code>PSYNC</code>命令里的offset参数不是-1；</li><li>主服务器收到该命令后，然后用<code>CONTINUE</code>响应命令告诉从服务器接下来采用增量复制的方式同步数据；</li><li>然后主服务器将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。</li></ol></li><li>但是出现以下两种情况，增量同步会强制转为全量同步：<ul><li><strong>RunID不匹配</strong>：说明master重启过，或者slave连到了一个新的master。</li><li><strong>积压缓冲区溢出</strong>：slave掉线时间太长，导致所需的offset数据在环形缓冲区中已经被新数据覆盖了。此时master找不到就数据，只能发起全量同步。</li></ul></li><li>主服务器怎么知道要将哪些增量数据发送给从服务器呢？<ul><li><code>repl_backlog_buffer</code>，是一个「环形」缓冲区，用于主从服务器断连后，从中找到差异的数据；</li><li><code>replication offset</code>，标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用<code>master_repl_offset</code>来记录自己「写」到的位置，从服务器使用<code>slave_repl_offset</code>来记录自己「读」到的位置。</li><li>如果判断出从服务器要复制的数据还在<code>repl_backlog_buffer</code>中，就执行增量同步；如果要复制的数据已经不在<code>repl_backlog_buffer</code>中，也就是这个期间主服务器更新了太多写命令覆盖掉了，那么就要执行完全同步。</li></ul></li></ul><h2 id="哨兵机制（Redis-Sentinel）"><a href="#哨兵机制（Redis-Sentinel）" class="headerlink" title="哨兵机制（Redis Sentinel）"></a>哨兵机制（Redis Sentinel）</h2><p>当redis集群的主节点故障时，Sentinel集群将从剩余的从节点中选举一个新的主节点，有以下步骤：</p><ol><li><strong>故障节点主观下线</strong>：Sentinel集群的每一个Sentinel节点会定时对redis集群的所有节点发心跳包检测节点是否正常。如果一个节点在<code>down-after-milliseconds</code>时间内没有回复Sentinel节点的心跳包，则该redis节点被该Sentinel节点主观下线。</li><li><strong>故障节点客观下线</strong>：当节点被一个Sentinel节点记为主观下线时，还需要Sentinel集群的其他Sentinel节点共同判断为主观下线才行。该Sentinel节点会询问其他Sentinel节点，如果Sentinel集群中超过<code>quorum</code>数量的Sentinel节点认为该redis节点主观下线，则该redis节点客观下线。如果客观下线的redis节点是从节点或者是Sentinel节点，则操作到此为止；如果<font color="#ff0000">客观下线的redis节点为主节点，则开始故障转移</font>，从从节点中选举一个节点升级为主节点。</li><li><strong>Sentinel集群选取leader</strong>：如果需要从redis集群选举一个节点为主节点，首先需要<font color="#ff0000">从Sentinel集群中选举一个Sentinel节点作为leader</font>。每一个Sentinel节点都可以成为leader，当一个Sentinel节点确认redis集群的主节点主观下线后，会请求其他Sentinel节点要求将自己选举为leader。被请求的Sentinel节点如果没有同意过其他Sentinel节点的选举请求，则同意该请求（选举票数+1），否则不同意。如果一个Sentinel节点获得的选举票数达到leader最低票数（<code>quorum</code>和Sentinel节点数/2 + 1的最大值），则该Sentinel节点选举为leader，否则重新进行选举。</li><li><strong>Sentinel leader决定新主节点</strong>：当Sentinel集群选举出Sentinel leader后，由Sentinel leader从redis从节点中选择一个redis节点作为主节点：<ul><li>过滤故障（网络状况不好）的节点，就是主节点和从节点断开的时间太大。</li><li>选择优先级<code>slave-priority</code>（可以通过配置文件配置）最大的从节点作为主节点，如果不在则继续。</li><li>如果<code>slave-priority</code>一样，则判断slave节点的offset值，最大优先级越高，也就是复制进度最大的从节点。</li><li>最后是判断slave节点运行id的大小，越小优先级越高。<br><img src="redis%E9%80%89%E4%B8%BE%E6%96%B0%E4%B8%BB%E8%8A%82%E7%82%B9.png" alt="redis选举新主节点"></li></ul></li></ol><h2 id="Redis集群模式（Redis-Cluster）"><a href="#Redis集群模式（Redis-Cluster）" class="headerlink" title="Redis集群模式（Redis Cluster）"></a>Redis集群模式（Redis Cluster）</h2><ul><li>当Redis缓存数据量大到一台服务器无法缓存时，就需要使用Redis切片集群（Redis Cluster）方案，<strong>它将数据分布在不同的服务器上</strong>（多个master，每个master多个slave），以此来降低系统对单主节点的依赖，从而提高Redis服务的读写性能。</li><li>Redis Cluster方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。一个切片集群共有16384个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的key，被映射到一个哈希槽中，具体执行过程分为两大步：<ul><li>根据键值对的key，按照CRC16算法计算一个16bit的值。</li><li>再用16bit值对16384取模，得到0～16383范围内的模数，每个模数代表一个相应编号的哈希槽。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Redis主从同步&quot;&gt;&lt;a href=&quot;#Redis主从同步&quot; class=&quot;headerlink&quot; title=&quot;Redis主从同步&quot;&gt;&lt;/a&gt;Redis主从同步&lt;/h2&gt;&lt;p&gt;单节点的redis并发能力是有上限的，要进一步提高redis的并发能力，就需要搭建主</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="Redis" scheme="http://lixrangel.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis场景</title>
    <link href="http://lixrangel.com/2025/12/28/java-ba-gu/redis/redis-chang-jing/"/>
    <id>http://lixrangel.com/2025/12/28/java-ba-gu/redis/redis-chang-jing/</id>
    <published>2025-12-27T16:00:00.000Z</published>
    <updated>2026-01-26T07:34:19.458Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么要用redis？"><a href="#为什么要用redis？" class="headerlink" title="为什么要用redis？"></a>为什么要用redis？</h2><ul><li><strong>访问速度更快</strong>：传统数据库数据保存在磁盘，而Redis基于内存，内存的访问速度比磁盘快很多。引入Redis之后，我们可以把一些高频访问的数据放到Redis中，这样下次就可以直接从内存中读取，速度可以提升几十倍甚至上百倍。</li><li><strong>高并发</strong>：<font color="#ff0000">单台设备的Redis的QPS是MySQL的10倍</font>，Redis单机的QPS能轻松破10w，而MySQL单机的QPS很难破1w。所以，直接访问Redis能够承受的请求是远远大于直接访问MySQL的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。</li><li><strong>功能全面</strong>：Redis除了可以用作缓存之外，还可以用于分布式锁、限流、消息队列、延时队列等场景，功能强大。</li></ul><h2 id="为什么Redis比MySQL快？"><a href="#为什么Redis比MySQL快？" class="headerlink" title="为什么Redis比MySQL快？"></a>为什么Redis比MySQL快？</h2><ul><li><strong>内存存储</strong>：Redis是基于内存存储的NoSQL数据库，而MySQL是基于磁盘存储的关系型数据库。由于内存存储速度快，Redis能够更快地读取和写入数据，而无需像MySQL那样频繁进行磁盘I/O操作。</li><li><strong>简单数据结构</strong>：Redis是基于键值对存储数据的，支持简单的数据结构（字符串、哈希、列表、集合、有序集合）。相比之下，MySQL需要定义表结构、索引等复杂的关系型数据结构，因此在某些场景下Redis的数据操作更为简单高效，比如Redis用哈希表查询，只需要O(1)时间复杂度，而MySQL引擎的底层实现是B+树，时间复杂度是O(logn)。</li><li><strong>线程模型</strong>：Redis采用单线程模型可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。</li></ul><h2 id="为什么用Redis而不用本地缓存？"><a href="#为什么用Redis而不用本地缓存？" class="headerlink" title="为什么用Redis而不用本地缓存？"></a>为什么用Redis而不用本地缓存？</h2><table><thead><tr><th>特性</th><th>本地缓存</th><th>Redis</th></tr></thead><tbody><tr><td>数据一致性</td><td>多服务器部署时存在数据不一致问题</td><td>数据一致</td></tr><tr><td>内存限制</td><td>受限于单台服务器内存</td><td>独立部署，内存空间更大</td></tr><tr><td>数据丢失风险</td><td>服务器宕机数据丢失</td><td>可持久化，数据不易丢失</td></tr><tr><td>管理维护</td><td>分散，管理不便</td><td>集中管理，提供丰富的管理工具</td></tr><tr><td>功能丰富性</td><td>功能有限，通常只能提供简单的键值对存储</td><td>功能丰富，支持多种数据结构和功能</td></tr></tbody></table><h2 id="Redis应用场景"><a href="#Redis应用场景" class="headerlink" title="Redis应用场景"></a>Redis应用场景</h2><ul><li><strong>缓存</strong>：Redis最常见的用途就是作为缓存系统。通过将热门数据存储在内存中，可以极大地提高访问速度，减轻数据库负载。</li><li><strong>排行榜</strong>：Redis的有序集合结构非常适合用于实现排行榜和排名系统，可以方便地进行数据排序和排名。</li><li><strong>分布式锁</strong>：Redis的特性可以用来实现分布式锁，确保多个进程或服务之间的数据操作的原子性和一致性。</li><li><strong>计数器</strong>：由于Redis的原子操作和高性能，它非常适合用于实现计数器和统计数据的存储，如网站访问量统计、点赞数统计等。</li><li><strong>消息队列</strong>：Redis的发布订阅功能使其成为一个轻量级的消息队列，它可以用来实现发布和订阅模式，以便实时处理消息。使用List的方式通常是使用LPUSH命令将消息推入一个列表，消费者使用BLPOP或BRPOP阻塞地从列表中取出消息（先进先出FIFO）。这种方式可以实现简单的任务队列。</li><li><strong>延时队列</strong>：Redisson内置了延时队列（基于Sorted Set实现的）。<h2 id="Redis分布式锁的实现原理"><a href="#Redis分布式锁的实现原理" class="headerlink" title="Redis分布式锁的实现原理"></a>Redis分布式锁的实现原理</h2></li><li>当使用redisson实现分布式锁，底层是<code>setnx</code>和lua脚本（保证释放锁时的原子性）。</li><li>Redis实现分布式锁的核心命令是<code>set</code>：<ul><li>命令：<code>SET lock_key unique_value NX PX 30000</code></li><li>核心参数：<ul><li>NX（Not Exists）：只有当key不存在时才设置成功。</li><li>PX（Expiration）：设置过期时间。这保证了安全性，防止某个客户端挂掉后锁永远不释放。</li><li>unique_value：每个客户端生成的唯一标识（如UUID）。防止A删掉了B的锁。</li></ul></li></ul></li><li>释放锁时，不能简单地执行<code>DEL</code>，因为可能出现以下情况：<ul><li>A加锁成功，执行业务时间太长，锁过期自动释放了。</li><li>B随即获取了锁。</li><li>A业务执行完，直接DEL，直接把B的锁给删了。</li></ul></li><li>因此，为了保证释放锁的安全性，必须验证唯一标识。由于“查询-比较-删除”是三个操作，为了保证原子性，必须使用lua脚本执行。</li></ul><h3 id="如果业务没执行完，锁过期了怎么办？"><a href="#如果业务没执行完，锁过期了怎么办？" class="headerlink" title="如果业务没执行完，锁过期了怎么办？"></a>如果业务没执行完，锁过期了怎么办？</h3><p>Redisson启动后，如果业务没完，会开启一个后台线程（Watch Dog），每隔一段时间（默认10秒）检查一下，如果客户端还持有锁，就自动延长锁的生存时间，防止锁提前过期。</p><h3 id="可重入性"><a href="#可重入性" class="headerlink" title="可重入性"></a>可重入性</h3><ul><li>原理：Redisson利用Redis的Hash数据结构。key是锁名，Field是客户端ID，Value是计数器。</li><li>逻辑：同一线程再次获取锁时，计数器+1；释放锁时，计数器-1。当计数器为0时，彻底删除key。</li></ul><h2 id="什么是大key？"><a href="#什么是大key？" class="headerlink" title="什么是大key？"></a>什么是大key？</h2><ul><li>如果一个key对应的value所占用的内存比较大，那这个key就可以看作是大key。</li><li>具体多大算大？<ul><li>String类型的value超过1MB；</li><li>复合类型的value包含的元素超过5000个。</li></ul></li></ul><h2 id="大key造成的问题"><a href="#大key造成的问题" class="headerlink" title="大key造成的问题"></a>大key造成的问题</h2><ul><li><strong>内存占用过高</strong>。大key占用过多的内存空间，可能导致可用内存不足，从而触发内存淘汰策略。在极端情况下，可能导致内存耗尽，Redis实例崩溃，影响系统的稳定性。</li><li><strong>性能下降</strong>。大key会占用大量内存空间，导致内存碎片增加，进而影响Redis的性能。对于大key的操作，如读取、写入、删除等，都会<font color="#ff0000">消耗更多的CPU时间和内存资源</font>，进一步降低系统性能。</li><li><strong>客户端超时阻塞</strong>。由于Redis执行命令是<font color="#ff0000">单线程处理</font>，在操作大key时会比较耗时，可能会导致Redis实例阻塞。例如，使用DEL命令删除一个大Key时，可能会导致Redis实例<font color="#ff0000">在一段时间内无法响应其他客户端请求</font>，从而影响系统的响应时间和吞吐量。</li><li><strong>网络拥塞</strong>。每次<font color="#ff0000">获取大key产生的网络流量较大</font>，可能造成机器或局域网的带宽被打满，同时波及其他服务。例如：一个大key占用空间是1MB，每秒访问1000次，就有1000MB的流量。</li><li><strong>主从同步延迟</strong>。当Redis实例配置了主从同步时，大key可能导致主从同步延迟。由于大key占用较多内存，同步过程中需要传输大量数据，这会导致<font color="#ff0000">主从之间的网络传输延迟增加</font>，进而影响数据一致性。</li><li><strong>数据倾斜</strong>。在redis集群模式中，某个数据分片的内存使用率远超其他数据分片，<font color="#ff0000">无法使数据分片的内存资源达到均衡</font>。另外也可能造成redis内存达到<code>maxmemory</code>参数定义的上线导致重要的key被逐出，甚至引发内存溢出。</li></ul><h2 id="如何处理大key？"><a href="#如何处理大key？" class="headerlink" title="如何处理大key？"></a>如何处理大key？</h2><ul><li><strong>对大key进行拆分</strong>。例如将含有数万成员的一个hash key拆分为多个hash key，并确保每个key的成员数量在合理范围。在redis集群架构中，拆分大key能对数据分片间的内存平衡起到显著作用。</li><li><strong>对大key进行清理</strong>。将不适用redis能力的数据存至其他存储，并在redis中删除此类数据。</li><li><strong>监控redis的内存水位</strong>。可以通过监控系统设置合理的redis内存报警阈值进行提醒，例如redis内存使用率超过70%、redis内存在1小时内增长率超过20%等。</li><li><strong>对过期数据进行定期清理</strong>。堆积大量过期数据会造成大key的产生，例如在hash数据类型中以增量的形式不断写入大量数据而忽略了数据的时效性。可以通过定时任务的方式对失效数据进行清理。</li></ul><h2 id="什么是热key？"><a href="#什么是热key？" class="headerlink" title="什么是热key？"></a>什么是热key？</h2><p>如果一个key的<strong>访问次数比较多且明显多于其他key</strong>的话，那这个key就可以看作是hot key。例如在redis实例的每秒处理请求达到5000次，而其中某个key的每秒访问量就高达2000次，那这个key就可以看作是hot key。</p><h2 id="如何解决热key？"><a href="#如何解决热key？" class="headerlink" title="如何解决热key？"></a>如何解决热key？</h2><ul><li><strong>读写分离</strong>：主节点处理写请求，从节点处理读请求。</li><li><strong>使用Redis Cluster</strong>：将热点数据分散存储在多个Redis节点上。</li><li><strong>二级缓存</strong>：hot key采用二级缓存的方式进行处理，将hot key存放一份到JVM本地内存中。</li></ul><h2 id="如何保证缓存和数据库的一致性？"><a href="#如何保证缓存和数据库的一致性？" class="headerlink" title="如何保证缓存和数据库的一致性？"></a>如何保证缓存和数据库的一致性？</h2><h3 id="旁路缓存模式（Cache-Aside-Pattern）"><a href="#旁路缓存模式（Cache-Aside-Pattern）" class="headerlink" title="旁路缓存模式（Cache Aside Pattern）"></a>旁路缓存模式（Cache Aside Pattern）</h3><ul><li><strong>读操作</strong>：<ul><li>先尝试从缓存读取数据</li><li>如果缓存命中，直接返回数据</li><li>如果缓存未命中，从数据库查询数据，将查到的数据放入缓存并返回数据</li></ul></li><li><strong>写操作</strong>：<ul><li>先更新数据库</li><li>再删除缓存中对应的数据<br>如果更新数据库成功，则删除缓存这一步失败的情况的话，简单说有几个解决方案：</li></ul></li><li><strong>增加缓存更新重试机制（常用）</strong>：如果缓存服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。不过，这里更适合引入消息队列实现异步重试，将删除缓存重试的消息投递到消息对立额，然后由专门的消费者来重试，直到成功。</li><li><strong>订阅数据库变更日志，再操作缓存</strong>：当一条数据发生修改时，MySQL就会产生一条变更日志（Binlog），我们可以订阅这个日志，拿到具体操作的数据，然后再根据这条数据，去删除对应的缓存。 </li></ul><h2 id="如果先删除缓存再更新数据库会怎样？"><a href="#如果先删除缓存再更新数据库会怎样？" class="headerlink" title="如果先删除缓存再更新数据库会怎样？"></a>如果先删除缓存再更新数据库会怎样？</h2><ul><li>数据库的写操作（IO操作）通常比内存操作慢得多。在A更新数据库的这段“漫长”时间里，非常容易插进来一个读请求B，把旧数据重新“种”回缓存。</li><li>解决方案：延迟双删：<ul><li>先删除缓存</li><li>更新数据库</li><li>休眠N毫秒</li><li>再次删除缓存</li></ul></li></ul><h2 id="缓存雪崩、击穿、穿透"><a href="#缓存雪崩、击穿、穿透" class="headerlink" title="缓存雪崩、击穿、穿透"></a>缓存雪崩、击穿、穿透</h2><ul><li><strong>缓存雪崩</strong>：当<font color="#ff0000">大量缓存数据在同一时间过期（失效）</font>或者<font color="#ff0000">Redis故障宕机</font>时，如果此时有大量的用户请求，都无法在redis中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃。</li><li><strong>缓存击穿</strong>：如果<font color="#ff0000">缓存中的某个热点数据过期</font>了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮。</li><li><strong>缓存穿透</strong>：当用户访问的数据，<font color="#ff0000">既不在缓存中，也不在数据库中</font>，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增。</li></ul><h2 id="缓存雪崩解决方案"><a href="#缓存雪崩解决方案" class="headerlink" title="缓存雪崩解决方案"></a>缓存雪崩解决方案</h2><h3 id="针对redis服务宕机问题"><a href="#针对redis服务宕机问题" class="headerlink" title="针对redis服务宕机问题"></a>针对redis服务宕机问题</h3><ul><li><strong>redis集群</strong>：采用redis集群，避免单机出现问题整个缓存服务都没办法使用。Redis Cluster和Redis Sentinel是两种最常用的Redis集群实现访问。</li><li><strong>多级缓存</strong>：设置多级缓存，例如本地缓存+Redis缓存的二级缓存组合，当Redis缓存出现问题时，还可以从本地缓存中获取到部分数据。</li><li><strong>限流与熔断</strong>：<ul><li>限流：每秒只允许N个请求通过</li><li>熔断：当检测到redis无法连接或数据库压力过大时，直接触发熔断，后续请求直接返回系统繁忙或默认值，不再去查数据库。</li></ul></li></ul><h3 id="针对集中失效问题"><a href="#针对集中失效问题" class="headerlink" title="针对集中失效问题"></a>针对集中失效问题</h3><ul><li><strong>均匀设置过期时间</strong>：如果要给缓存数据设置过期时间，应该避免大量的数据设置成同一个过期时间。我们可以在对缓存数据设置过期时间时，<font color="#ff0000">给这些数据的过期时间加上一个随机数</font>，这样就保证数据不会在同一时间过期。</li><li><strong>提前预热（推荐）</strong>：针对热点数据提前预热，将其存入缓存中并设置合理的过期时间，比如秒杀场景下的数据在秒杀结束之前不过期。</li></ul><h2 id="缓存击穿解决办法"><a href="#缓存击穿解决办法" class="headerlink" title="缓存击穿解决办法"></a>缓存击穿解决办法</h2><ul><li><strong>永不过期（不推荐）</strong>：设置热点数据永不过期或者过期时间比较长。</li><li><strong>提前预热（推荐）</strong>：针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。</li><li><strong>互斥锁（看情况）</strong>：在缓存失效后，通过<font color="#ff0000">设置互斥锁确保只有一个请求去查询数据库并把数据更新到缓存</font>中。</li></ul><h2 id="缓存穿透解决办法"><a href="#缓存穿透解决办法" class="headerlink" title="缓存穿透解决办法"></a>缓存穿透解决办法</h2><ul><li><strong>非法请求的限制</strong>：在API入口处我们要判断请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。</li><li><strong>缓存空值或者默认值</strong>：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。</li><li><strong>布隆过滤器</strong>：我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在。即使发生了缓存穿透，大量请求只会查询Redis和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis自身也是支持布隆过滤器的。</li></ul><h2 id="布隆过滤器的原理"><a href="#布隆过滤器的原理" class="headerlink" title="布隆过滤器的原理"></a>布隆过滤器的原理</h2><ul><li>布隆过滤器由「<strong>初始值都为0的位图数组</strong>」和「<strong>N个哈希函数</strong>」两部分组成。当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。</li><li>布隆过滤器会通过3个操作完成标记：<ul><li>使用N个哈希函数分别对数据做哈希计算，<strong>得到N个哈希值</strong>；</li><li>将第一步得到的N个哈希值对位图数组的长度取模，<strong>得到每个哈希值在位图数组的对应位置</strong>；</li><li><strong>将每个哈希值在位图数组的对应位置的值设置为1</strong>。</li></ul></li><li>查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;为什么要用redis？&quot;&gt;&lt;a href=&quot;#为什么要用redis？&quot; class=&quot;headerlink&quot; title=&quot;为什么要用redis？&quot;&gt;&lt;/a&gt;为什么要用redis？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;访问速度更快&lt;/strong&gt;：传统数据</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="Redis" scheme="http://lixrangel.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis持久化</title>
    <link href="http://lixrangel.com/2025/12/27/java-ba-gu/redis/redis-chi-jiu-hua/"/>
    <id>http://lixrangel.com/2025/12/27/java-ba-gu/redis/redis-chi-jiu-hua/</id>
    <published>2025-12-26T16:00:00.000Z</published>
    <updated>2026-01-26T07:31:55.100Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis持久化方式"><a href="#Redis持久化方式" class="headerlink" title="Redis持久化方式"></a>Redis持久化方式</h2><ul><li><strong>快照（snapshotting，RDB）</strong>：将某一时刻的内存数据，以二进制的方式写入磁盘。</li><li><strong>只追加文件（append-only file，AOF）</strong>：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里。</li><li>ROB和AOF的混合持久化。</li></ul><h2 id="RDB持久化"><a href="#RDB持久化" class="headerlink" title="RDB持久化"></a>RDB持久化</h2><ul><li>Redis可以通过创建快照来获得存储在内存里面的数据<strong>在某个时间点上的副本</strong>。Redis创建快照之后，可以<strong>将快照复制到其他服务器</strong>从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。RDB记录的就是数据，而不是操作。</li><li>Redis提供了两个命令来生成RDB快照文件，区别在于是否在【主线程】里执行：<ul><li><code>save</code>：在主线程生成RDB文件，同步保存操作，会阻塞Redis主线程；</li><li><code>bgsave</code>：fork出一个子进程，子进程执行，不会阻塞Redis主线程，默认选项。</li></ul></li></ul><h2 id="AOF持久化"><a href="#AOF持久化" class="headerlink" title="AOF持久化"></a>AOF持久化</h2><ul><li>与快照持久化相比，AOF持久化的实时性更好。默认情况下Redis没有开启AOF方式的持久化（Redis6.0之后已经默认是开启了），可以通过<code>appendonly</code>参数开启。</li><li>开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入到<strong>AOF缓冲区</strong><code>server.aof_buf</code>中，然后再写入到AOF文件中（此时还在<strong>系统内核缓冲区</strong>未同步到磁盘），最后再根据<strong>持久化方式</strong>（fsync策略）的配置来决定何时将系统内核缓冲区的数据同步到硬盘中。（只有同步到磁盘中才算持久化保存了，否则依然存在数据丢失的风险，比如说：系统内核缓冲区的数据还未同步，磁盘机器就宕机了，那这部分数据就算丢失了）。</li></ul><h2 id="AOF工作基本流程"><a href="#AOF工作基本流程" class="headerlink" title="AOF工作基本流程"></a>AOF工作基本流程</h2><ol><li><strong>命令追加（append）</strong>：所有的写命令会追加到AOF缓冲区中。</li><li><strong>文件写入（write）</strong>：调用<font color="#ff0000">write函数</font>（系统调用），write将数据写入到了系统内核缓冲区之后直接返回了（延迟写）。<blockquote><p>此时还没有同步到磁盘。</p></blockquote></li><li><strong>文件同步（fsync）</strong>：根据你在<code>redis.conf</code>文件里<code>appendfsync</code>配置的策略，Redis会在不同的时机调用<code>fsync</code>函数（系统调用）。<code>fsync</code>针对单个文件操作，对其进行强制硬盘同步（文件在内核缓冲区里的数据写到硬盘），<code>fsync</code>将阻塞直到写入磁盘完成后返回，保证了数据持久化。</li><li><strong>文件重写（rewrite）</strong>：随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的。</li><li><strong>重启加载（load）</strong>：当Redis重启时，可以加载AOF文件进行数据恢复。<br><img src="AOF%E5%B7%A5%E4%BD%9C%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B.png" alt="AOF工作基本流程"></li></ol><h2 id="AOF持久化方式有哪些？"><a href="#AOF持久化方式有哪些？" class="headerlink" title="AOF持久化方式有哪些？"></a>AOF持久化方式有哪些？</h2><p>三种<code>fsync</code>策略：</p><ol><li><code>appendfsync always</code>：主线程调用<code>write</code>执行写操作后，会<strong>立刻调用</strong><code>fsync</code>函数同步AOF文件（刷盘）。<strong>主线程会阻塞</strong>，直到<code>fsync</code>将数据完全刷到磁盘后才会返回。这种方式数据最安全，理论上不会有任何数据丢失。但因为每个写操作都会同步阻塞主线程，所以性能极差。</li><li><code>appendfsync everysec</code>：主线程调用<code>write</code>执行写操作后<strong>立即返回</strong>，由<strong>后台线程</strong>（<code>aof_fsync</code>线程）<strong>每秒钟</strong>调用<code>fsync</code>函数（系统调用）同步一次AOF文件。这种方式<strong>主线程的性能基本不受影响</strong>。在性能和数据安全之间做出了绝佳的平衡。不过，在Redis异常宕机时，最多可能丢失最近1秒内的数据。</li><li><code>appendfsync no</code>：主线程调用<code>write</code>执行写操作后立即返回，让<strong>操作系统决定</strong>何时进行同步，Linux下一般为30秒一次（<code>write</code>但不<code>fsync</code>，<code>fsync</code>的时机由操作系统决定）。这种方式性能最好，因为避免了<code>fsync</code>的阻塞。但数据安全性最差，宕机时丢失的数据量不可控，取决于操作系统上一次同步的时间点。</li></ol><h2 id="AOF的重写机制"><a href="#AOF的重写机制" class="headerlink" title="AOF的重写机制"></a>AOF的重写机制</h2><ol><li><strong>Fork子进程</strong>：Redis主进程fork出一个子进程（此时利用操作系统的写时复制Copy-On-Write机制，子进程拥有父进程那一瞬间的内存数据快照）。</li><li><strong>子进程写新的AOF文件</strong>：子进程不关心旧的AOF文件，它直接遍历内存中的数据。如果内存里有<code>key1 = 10000</code>（他可能在旧的AOF文件中是10000条INCR命令），它就在新的临时AOF文件里写一条<code>SET key1 10000</code>；如果内存里有一个list，它就用一条<code>RPUSH</code>命令把里面所有元素记录下来。总结：<font color="#ff0000">用最少的命令，还原当前内存里的数据状态</font>。</li><li><strong>父进程处理新请求（AOF重写缓冲区）</strong>：在子进程重写的过程中，主进程依然在接收客户端的新写入命令。主进程会把这些新命令写入到一个专门的<font color="#ff0000">AOF重写缓冲区</font>中，防止数据丢失。</li><li><strong>合并</strong>：当子进程写完临时文件后，通知主进程。主进程把”AOF重写缓冲区”里积累的<font color="#ff0000">新命令追加到临时文件末尾</font>。</li><li><strong>替换</strong>：用这个新的、体积很小的临时文件，原子地<strong>替换掉旧的AOF文件</strong>。</li></ol><h2 id="AOF和RDB的优缺点"><a href="#AOF和RDB的优缺点" class="headerlink" title="AOF和RDB的优缺点"></a>AOF和RDB的优缺点</h2><h3 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h3><ul><li>优点：<ul><li>AOF提供了更好的数据安全性，因为它默认每接收到一个写命令就会追加到文件末尾。即使Redis服务器宕机，也只会丢失最后一次写入前的数据。</li><li>AOF支持<strong>多种同步策略</strong>，可以根据需要调整数据安全性和性能之间的平衡。</li><li>AOF文件在redis启动时可以通过<strong>重写机制优化</strong>，减少文件体积，加快恢复速度。</li></ul></li><li>缺点：<ul><li>因为记录了每一个写操作，所以<strong>AOF文件通常比RDB文件更大</strong>，消耗更多的磁盘空间。</li><li>频繁的磁盘IO操作可能会对redis的写入性能造成一定影响。</li></ul></li></ul><h3 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h3><ul><li>优点：<ul><li>RDB文件存储的内容是<strong>经过压缩的二进制数据</strong>，<strong>文件体积小</strong>，备份和恢复的速度非常快。</li><li>RDB是在主线程之外通过fork子线程来进行的，不会阻塞服务器处理命令请求，对redis服务的性能影响较小。</li><li>使用RDB文件恢复数据，<strong>直接解析还原数据即可</strong>，不需要一条一条地执行命令，速度非常快。</li></ul></li><li>缺点：<ul><li>RDB方式在两次快照之间，如果redis服务器发生故障，这段时间的数据会丢失。</li><li>如果在RDB创建快照到恢复期间有写操作，恢复后的数据可能与故障前的数据不完全一致。</li></ul></li></ul><h2 id="两种持久化方式的使用场景"><a href="#两种持久化方式的使用场景" class="headerlink" title="两种持久化方式的使用场景"></a>两种持久化方式的使用场景</h2><ul><li>Redis保存的数据丢失一些也没什么影响的话，可以选择使用RDB。</li><li>不建议单独使用AOF，因为时不时地创建一个RDB快照可以进行数据库备份、更快的重启以及解决AOF引擎错误。</li><li>如果保存的数据要求安全性比较高的话，建议同时开启RDB和AOF持久化或者开启RDB和AOF混合持久化。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Redis持久化方式&quot;&gt;&lt;a href=&quot;#Redis持久化方式&quot; class=&quot;headerlink&quot; title=&quot;Redis持久化方式&quot;&gt;&lt;/a&gt;Redis持久化方式&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;快照（snapshotting，RDB）&lt;/st</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="Redis" scheme="http://lixrangel.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis缓存淘汰和过期删除</title>
    <link href="http://lixrangel.com/2025/12/26/java-ba-gu/redis/redis-huan-cun-tao-tai-he-guo-qi-shan-chu/"/>
    <id>http://lixrangel.com/2025/12/26/java-ba-gu/redis/redis-huan-cun-tao-tai-he-guo-qi-shan-chu/</id>
    <published>2025-12-25T16:00:00.000Z</published>
    <updated>2026-01-26T07:28:19.996Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis过期删除策略"><a href="#Redis过期删除策略" class="headerlink" title="Redis过期删除策略"></a>Redis过期删除策略</h2><ol><li><strong>惰性删除</strong>：不主动删除过期键，<font color="#ff0000">只会在取出/查询key的时候才会对数据进行过期检查</font>，如果过期则删除该key。这种方式对CPU最友好，但是可能会造成太多过期key没有被删除。</li><li><strong>定期删除</strong>：<font color="#ff0000">周期性地随机从设置了过期时间的key中抽查一批</font>，然后逐个检查这些key是否过期，过期就删除key。相比于惰性删除，定期删除对内存更友好，对CPU不太友好。</li><li>Redis选择「<strong>惰性删除+定期删除</strong>」这两种策略配合使用，以求在合理使用CPU时间和避免内存浪费之间取得平衡。<br>惰性删除的流程图：<br><img src="%E6%83%B0%E6%80%A7%E5%88%A0%E9%99%A4%E6%B5%81%E7%A8%8B%E5%9B%BE.png#pic_center" alt="惰性删除流程图"><br>定期删除流程图：<br><img src="%E5%AE%9A%E6%9C%9F%E5%88%A0%E9%99%A4%E6%B5%81%E7%A8%8B%E5%9B%BE.png#pic_center" alt="定期删除流程图"><br>定期删除参数：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> ACTIVE_EXPIRE_CYCLE_FAST_DURATION 1000 <span class="comment">/* Microseconds. */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC 25 <span class="comment">/* Max % of CPU to use. */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ACTIVE_EXPIRE_CYCLE_ACCEPTABLE_STALE 10 <span class="comment">/* % of stale keys after which</span></span></span><br><span class="line"><span class="comment"><span class="meta">                                                   we do extra efforts. */</span></span></span><br></pre></td></tr></table></figure></li></ol><h2 id="大量key集中过期怎么办？"><a href="#大量key集中过期怎么办？" class="headerlink" title="大量key集中过期怎么办？"></a>大量key集中过期怎么办？</h2><ol><li><strong>尽量避免key集中过期</strong>：在设置键的过期时间时尽量随机一点。</li><li><strong>开启lazy free机制</strong>：修改<code>redis.conf</code>配置文件，将<code>lazyfree-lazy-expire</code>参数设置为yes，即可开启lazy free机制。开启lazy free机制后，Redis会<font color="#ff0000">在后台异步删除过期的key</font>，不会阻塞主线程的运行，从而降低对Redis性能的影响。</li></ol><h2 id="内存淘汰策略"><a href="#内存淘汰策略" class="headerlink" title="内存淘汰策略"></a>内存淘汰策略</h2><ul><li>Redis的内存淘汰策略<strong>只有在运行内存达到了配置的最大内存阈值时才会触发</strong>，这个阈值是通过<code>redis.conf</code>的<code>maxmemory</code>参数来定义的。64位操作系统下，<code>maxmemory</code>默认为0，表示不限制内存大小。32位操作系统下，默认的最大内存值是3GB。</li><li>redis提供了6种内存淘汰策略：<ul><li><strong>volatile-lru（least recently used）</strong>：从已设置过期时间的数据（<code>server.db[i].expires</code>）中挑选最久未使用的键的数据淘汰。</li><li><strong>volatile-ttl</strong>：从已设置过期时间的数据（<code>server.db[i].expires</code>）中挑选将要过期的数据淘汰。</li><li><strong>volatile- random</strong>：从已设置过期时间的数据（<code>server.db[i].expires</code>）中任意选择数据淘汰。</li><li><strong>allkeys-lru（least recently used）</strong>：从所有数据（<code>server.db[i].dict</code>）中移除最近最少使用的数据淘汰。</li><li><strong>allkeys-random</strong>：从所有数据（<code>server.db[i].dict</code>）中任意选择数据淘汰。</li><li><strong>no-eviction（默认内存淘汰策略）</strong>：禁止驱逐数据（也就是不淘汰），当内存不足以容纳新写入数据时，新写入操作会报错。</li></ul></li><li>4.0版本后增加以下两种：<ul><li><strong>volatile-lfu（least frequently used）</strong>：从已设置过期时间的数据（<code>server.db[i].expires</code>）中挑选最不经常使用的数据淘汰。</li><li><strong>allkeys-lfu（least frequently used）</strong>：从所有数据（<code>server.db[i].dict</code>）中移除最不经常使用的数据淘汰。<blockquote><p>lru是时间，lfu是频率。</p></blockquote></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Redis过期删除策略&quot;&gt;&lt;a href=&quot;#Redis过期删除策略&quot; class=&quot;headerlink&quot; title=&quot;Redis过期删除策略&quot;&gt;&lt;/a&gt;Redis过期删除策略&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;惰性删除&lt;/strong&gt;：不主动删除过</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="Redis" scheme="http://lixrangel.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis事务</title>
    <link href="http://lixrangel.com/2025/12/25/java-ba-gu/redis/redis-shi-wu/"/>
    <id>http://lixrangel.com/2025/12/25/java-ba-gu/redis/redis-shi-wu/</id>
    <published>2025-12-24T16:00:00.000Z</published>
    <updated>2026-01-26T07:24:34.401Z</updated>
    
    <content type="html"><![CDATA[<h2 id="如何实现Redis原子性？"><a href="#如何实现Redis原子性？" class="headerlink" title="如何实现Redis原子性？"></a>如何实现Redis原子性？</h2><ul><li>redis执行一条命令的时候是具备原子性的，因为redis执行命令的时候是单线程处理的，不存在多线程安全的问题。</li><li>如果要保证2条命令的原子性的话，可以考虑用lua脚本，将多个操作写到一个lua脚本中，redis会把整个lua脚本作为一个整体执行，在执行过程中不会被其他命令打断，从而保证了lua脚本中操作的原子性。</li></ul><h2 id="除了lua有没有什么也能保证redis的原子性？"><a href="#除了lua有没有什么也能保证redis的原子性？" class="headerlink" title="除了lua有没有什么也能保证redis的原子性？"></a>除了lua有没有什么也能保证redis的原子性？</h2><ul><li>redis事务也可以保证多个操作的原子性。</li><li>如果redis事务正常执行，没有发生任何错误，那么使用 MULTI（开始事务）和 EXEC（执行事务） 配合使用，就可以保证多个操作都完成。</li><li>但是，如果事务执行发生错误了，就没办法保证原子性了。比如说 2 个操作，第一个操作执行成功了，但是第二个操作执行的时候，命令出错了，那事务并不会回滚，因为<strong>Redis 中并没有提供回滚机制</strong>。</li><li>因此，Redis 对事务原子性属性的保证情况：<ul><li>Redis 事务正常执行，可以保证原子性；</li><li>Redis 事务执行中某一个操作执行失败，不保证原子性；</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;如何实现Redis原子性？&quot;&gt;&lt;a href=&quot;#如何实现Redis原子性？&quot; class=&quot;headerlink&quot; title=&quot;如何实现Redis原子性？&quot;&gt;&lt;/a&gt;如何实现Redis原子性？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;redis执行一条命令的时候是具备原子性</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="Redis" scheme="http://lixrangel.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis线程模型</title>
    <link href="http://lixrangel.com/2025/12/24/java-ba-gu/redis/redis-xian-cheng-mo-xing/"/>
    <id>http://lixrangel.com/2025/12/24/java-ba-gu/redis/redis-xian-cheng-mo-xing/</id>
    <published>2025-12-23T16:00:00.000Z</published>
    <updated>2026-01-22T13:30:56.404Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis为什么快？"><a href="#Redis为什么快？" class="headerlink" title="Redis为什么快？"></a>Redis为什么快？</h2><ul><li><strong>纯内存操作</strong>：Redis的大部分操作都<font color="#ff0000">在内存中完成</font>，并且采用了高效的数据结构，访问速度是纳秒级别，而传统的数据库频繁读写磁盘的速度是毫秒级别，两者相差数个数量级。</li><li><strong>高效的I/O模型</strong>：Redis使用单线程时间循环配合I/O多路复用技术，让<font color="#ff0000">单个线程可以同时处理多个网络连接上的I/O事件</font>（如读写），避免了多线程模型中的上下文切换和锁竞争问题。</li><li><strong>优化的内部数据结构</strong>：Redis提供多种数据类型，其内部实现<font color="#ff0000">采用高度优化的编码方式</font>，Redis会根据数据大小和类型动态选择最合适的内部编码，以在性能和空间效率之间取得最佳平衡。</li><li><strong>简洁高效的通信协议</strong>：Redis使用的是自己设计的RESP协议。该协议<font color="#ff0000">实现简单</font>、<font color="#ff0000">解析性能好</font>，并且是<font color="#ff0000">二进制安全</font>的。客户端和服务端之间通信的序列化/反序列化开销很小，有助于提升整体的交互速度。</li></ul><h2 id="Redis哪些地方使用了多线程？"><a href="#Redis哪些地方使用了多线程？" class="headerlink" title="Redis哪些地方使用了多线程？"></a>Redis哪些地方使用了多线程？</h2><ul><li>Redis单线程指的是「<strong>接收客户端请求 -&gt; 解析请求 -&gt; 进行数据读写等操作 -&gt; 发送数据给客户端</strong>」这个过程是由一个线程（主线程）来完成的。也就是Redis的主要工作（<strong>网络I/O和执行命令</strong>）是单线程来处理的。</li><li>Redis程序并不是单线程的，Redis在启动的时候，是会<strong>启动后台线程</strong>（BIO）的。Redis为「<strong>关闭文件、AOF刷盘、释放内存</strong>」这些任务创建单独的线程来处理，因为这些任务耗时，所以创建其他线程来异步处理这些任务。</li><li>为了提高网络I/O的并行度，Redis6.0对于网络I/O采用多线程来处理。但是对于命令的执行，Redis仍然使用单线程来处理。</li><li>Redis6.0版本之后，Redis在启动的时候，默认情况下会额外创建6个线程（这里的线程不包括主线程）：<ul><li><code>Redis-server</code>：Redis的主线程，主要负责执行命令；</li><li><code>bio_close_file</code>、<code>bio_aof_fsync</code>、<code>bio_lazy_free</code>：三个后台线程，分别异步处理「关闭文件任务」、「AOF刷盘任务」、「释放内存任务」；</li><li><code>io_thd_1</code>、<code>io_thd_2</code>、<code>io_thd_3</code>：三个I/O线程，io_threads默认是4，所以会启动3（4 - 1）个I/O多线程，用来分担Redis网络I/O的压力。</li></ul></li></ul><h2 id="Redis单线程模型？"><a href="#Redis单线程模型？" class="headerlink" title="Redis单线程模型？"></a>Redis单线程模型？</h2><ul><li>Redis基于 Reactor 模式设计开发了一套高效的事件处理模型，这套事件处理模型对应的是Redis中的<strong>文件事件处理器</strong>（file event handler）。由于文件事件处理器（file event handler）是单线程方式运行的，所以我们一般都说Redis是单线程模型。</li><li>文件事件处理器（file event handler）主要是包含4个部分：<ul><li>多个socket（客户端连接）；</li><li>IO多路复用程序（支持多个客户端连接的关键）；</li><li>文件事件分派器（将socket关联到相应的事件处理器）；</li><li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）。<br><img src="%E6%96%87%E4%BB%B6%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E5%99%A8.png" alt="文件事件处理器"></li></ul></li></ul><h2 id="Redis怎么实现的IO多路复用？"><a href="#Redis怎么实现的IO多路复用？" class="headerlink" title="Redis怎么实现的IO多路复用？"></a>Redis怎么实现的IO多路复用？</h2><ul><li>Redis是跑在「单线程」中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以I/O操作在一般情况下往往不能直接返回，这会导致某一文件的I/O阻塞掉，致整个进程无法对其他客户提供服务。而I/O多路复用就是为了解决这个问题而出现的。为了<strong>让单线程（进程）的服务端应用同时处理多个客户端的事件</strong>，Redis采用了IO多路复用机制。</li><li>这里“多路”指的是<strong>多个网络连接客户端</strong>，“复用”指的是<strong>复用同一个线程</strong>（单进程）。I/O多路复用其实是使用一个线程来检查多个socket的就绪状态，在单个线程中通过记录跟踪每一个socket（I/O流）的状态来管理处理多个I/O流。如下图是Redis的I/O多路复用模型：<br><img src="Redis%E7%9A%84IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E6%A8%A1%E5%9E%8B.png" alt="Redis的IO多路复用模型"></li><li>一个socket客户端与服务端连接时，会生成对应的一个<strong>套接字描述符</strong>（其实就是一个整数，是这个连接在操作系统中的一个索引），每一个socket网络连接其实都对应一个文件描述符。</li><li>多个客户端与服务端连接时，Redis使用I/O多路复用程序<strong>将客户端socket对应的FD注册到监听列表</strong>中。当客户端执行read、write等操作命令时，数据到达内核缓冲区，epoll检测到该FD状态变为“可读”，便会生成一个事件通知Redis。Redis拿到时间后，调用对应的处理函数读取并解析命令。<blockquote><p>IO多路复用程序是一个封装层，封装了操作系统底层的多路复用函数（如Linux的epoll、macOS的kqueue或旧的select。</p></blockquote></li><li>文件事件处理器使用I/O多路复用模块同时监控多个文件描述符（FD）的读写情况，当accept、read、write和close文件事件产生时，文件事件处理器就会回调FD绑定的事件处理器进行处理相关命令操作。</li><li>例如：以Redis的IO多路复用程序epoll函数为例。多个客户端连接服务端时，Redis会将客户端socket对应的FD（文件描述符）注册进epoll，然后epoll同时监听多个文件描述符（FD）是否有数据到来，如果有数据来了就通知事件处理器赶紧处理，这样就不会存在服务端一直等待某个客户端给数据的情形。</li><li>整个<strong>文件事件处理器是在单线程上运行的</strong>，但是通过I/O多路复用模块的引入，实现了同时对多个FD读写的监控，当其中一个client端达到写或读的状态，文件事件处理器就马上执行，从而就不会出现I/O阻塞的问题，提高了网络通信的性能。</li></ul><table><thead><tr><th>状态</th><th>过程</th><th>线程状态</th></tr></thead><tbody><tr><td>等待事件</td><td>Redis主线程调用epoll_wait()，将自己挂起。</td><td>阻塞（但同时高效监听所有FD）</td></tr><tr><td>事件就绪</td><td>内核通知epoll，有N个FD就绪。epoll将线程唤醒。</td><td>运行</td></tr><tr><td>处理数据</td><td>主线程遍历这N个就绪FD，执行read和命令处理。</td><td>运行</td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Redis为什么快？&quot;&gt;&lt;a href=&quot;#Redis为什么快？&quot; class=&quot;headerlink&quot; title=&quot;Redis为什么快？&quot;&gt;&lt;/a&gt;Redis为什么快？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;纯内存操作&lt;/strong&gt;：Redis的大部分</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="Redis" scheme="http://lixrangel.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis数据结构</title>
    <link href="http://lixrangel.com/2025/12/23/java-ba-gu/redis/redis-shu-ju-jie-gou/"/>
    <id>http://lixrangel.com/2025/12/23/java-ba-gu/redis/redis-shu-ju-jie-gou/</id>
    <published>2025-12-22T16:00:00.000Z</published>
    <updated>2026-01-21T12:29:42.616Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis底层数据结构"><a href="#Redis底层数据结构" class="headerlink" title="Redis底层数据结构"></a>Redis底层数据结构</h2><table><thead><tr><th>结构类型</th><th>底层数据结构</th><th>结构存储的值</th><th>结构的读写能力</th></tr></thead><tbody><tr><td><strong>String字符串</strong></td><td>简单动态字符串（SDS）</td><td>可以是字符串、整型或浮点数</td><td>对整个字符串或字符串的一部份进行操作；对整数或浮点数进行自增或自减操作；</td></tr><tr><td><strong>List列表</strong></td><td>LinkedList、ZipList、QuickList</td><td>一个链表，链表上的每个节点都包含一个字符串</td><td>对链表的两端进行push和pop操作，读取单个或多个元素；根据值查找或删除元素；</td></tr><tr><td><strong>Set集合</strong></td><td>Dict、ZipList</td><td>包含字符串的无序集合</td><td>字符串的集合，包含基础的方法：是否存在、添加、获取、删除；还包含计算交集、并集、差集等；</td></tr><tr><td><strong>Hash散列</strong></td><td>Dict、ZipList</td><td>包含键值对的无序散列表</td><td>包含方法有添加、获取、删除单个元素</td></tr><tr><td><strong>Zset有序集合</strong></td><td>ZipList、SkipList</td><td>和散列一样，用于存储键值对</td><td>字符串成员与浮点数分数之间的有序映射；元素的排列顺序由分数的大小决定；包含方法有添加、获取、删除单个元素以及根据分值范围或成员来获取元素。</td></tr></tbody></table><ul><li>五种数据类型的应用场景：<ul><li><strong>String类型</strong>：缓存对象、常规计数、分布式锁、共享session信息等；</li><li><strong>List类型</strong>：消息队列（问题：1. 生产者需要自行实现全局唯一ID；2. 不能以消费组形式消费数据）等。</li><li><strong>Hash类型</strong>：缓存对象、购物车等；</li><li><strong>Set类型</strong>：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。</li><li><strong>Zset类型</strong>：排序场景，比如排行榜、电话和姓名排序等。</li></ul></li><li>后续版本支持的四种数据类型，它们的应用场景：<ul><li><strong>BitMap（2.2版新增）</strong>：二值状态统计的场景，比如签到、判断用户登录状态、连续签到用户总数等；</li><li><strong>HyperLogLog（2.8版新增）</strong>：海量数据基数统计的场景，比如百万级网页UV计数等；</li><li><strong>GEO（3.2版新增）</strong>：存储地理位置信息的场景，比如滴滴叫车；</li><li><strong>Stream（5.0版新增）</strong>：消息队列，相比于基于List类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组的形式消费数据。<br><img src="redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="redis数据结构"></li></ul></li></ul><h2 id="Zset底层是怎么实现的？"><a href="#Zset底层是怎么实现的？" class="headerlink" title="Zset底层是怎么实现的？"></a>Zset底层是怎么实现的？</h2><p>Zset类型的底层数据结构是由压缩列表或跳表实现的：</p><ul><li>如果有序集合的元素个数小于128个，并且每个元素的值小于64字节时，Redis会使用压缩列表作为Zset类型的底层数据结构；</li><li>如果有序集合的元素不满足上面的条件，Redis会使用跳表作为Zset类型的底层数据结构；<br>在Redis 7.0中，压缩列表数据结构已经废弃了，交由listpack数据结构来实现了。</li></ul><h2 id="跳表是怎么实现的？"><a href="#跳表是怎么实现的？" class="headerlink" title="跳表是怎么实现的？"></a>跳表是怎么实现的？</h2><ul><li>链表在查找元素的时候，因为需要逐一查找，所以查询效率非常低，时间复杂度是$O(N)$，于是就出现了跳表。跳表是在链表基础上改进过来的，实现了一种【多层】的有序链表，这样的好处是能<strong>快速定位数据</strong>。<br><img src="%E8%B7%B3%E8%A1%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="跳表数据结构"></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">zskiplistNode</span> &#123;</span><br><span class="line">    <span class="comment">//Zset 对象的元素值</span></span><br><span class="line">    sds ele;</span><br><span class="line">    <span class="comment">//元素权重值</span></span><br><span class="line">    <span class="type">double</span> score;</span><br><span class="line">    <span class="comment">//后向指针</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">zskiplistNode</span> *backward;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">//节点的level数组，保存每层上的前向指针和跨度</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">zskiplistLevel</span> &#123;</span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">zskiplistNode</span> *forward;</span><br><span class="line">        <span class="type">unsigned</span> <span class="type">long</span> span;</span><br><span class="line">    &#125; level[];</span><br><span class="line">&#125; zskiplistNode;</span><br></pre></td></tr></table></figure><ul><li>Zset 对象要同时保存【<strong>元素</strong>】和【<strong>元素的权重</strong>】，对应到跳表节点结构里就是SDS类型的ele变量和double类型的score变量。每个跳表节点都有一个后向指针（<code>struct zskiplistNode *backward</code>），指向前一个节点，目的是为了<font color="#ff0000">方便从跳表的尾节点开始访问节点</font>，这样倒序查找时很方便。</li><li>跳表是一个带有层级关系的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的<code>zskiplistLevel</code>结构体类型的level数组。</li><li>level数组中的每一个元素代表跳表的一层，也就是由zskiplistLevel结构体表示，比如<code>level[0]</code>就表示第一层，<code>level[1]</code>就表示第二层。zskiplistLevel结构体里定义了【<strong>指向下一跳表节点的指针</strong>】和【<strong>跨度</strong>】，跨度是用来记录两个节点之间的距离。<br><img src="%E8%B7%B3%E8%A1%A8%E8%B7%A8%E5%BA%A6.png" alt="跳表跨度"></li><li>Redis跳表在创建节点的时候，随机生成每个节点的层数，并没有严格维持相邻两层的节点数量比例为2:1的情况。</li><li>具体的做法是，跳表在创建节点的时候，会生成范围为$[0-1]$的一个随机数，如果这个随机数小于0.25（相当于概率25%），那么层数就增加1层，然后继续生成下一个随机数，直到随机数的结果大于0.25结束，最终确定该节点的层数。（【跳表是怎么设置层高的？】的答案）。</li><li>这样的做法相当于**每增加一层的概率不超过25%**，层数越高，概率越多，层高最大限制是64。在创建跳表头节点时，会直接创建64层高的头节点。</li></ul><h2 id="面试——跳表"><a href="#面试——跳表" class="headerlink" title="面试——跳表"></a>面试——跳表</h2><ul><li>跳表（SkipList）本质上是一种可以通过“<strong>多级索引</strong>”进行快速查找的有序链表。它利用空间换时间的思想，把普通链表的查找复杂度从$O(N)$降到了$O(\log N)$，性能可以媲美红黑树，但实现更简单。</li><li>它的结构可以分为两部分：<ul><li><strong>最底层（L0）</strong>：是一个包含所有数据的<font color="#ff0000">有序双向链表</font>。</li><li><strong>上层索引（L1, L2,…）</strong>：是在底层链表的基础上，<font color="#ff0000">每隔一段距离提取一个节点作为索引</font>。层级越高，节点越稀疏。</li></ul></li><li>查找时，从最高层索引开始，像“坐电梯”一样，发现目标太大就往右跳，发现目标太小就往下一层沉，直到找到数据。</li><li>每个节点的层高是由$[0-1]$的随机数决定的，如果小于0.25，就增加一层；如果大于0.25，就停止。</li></ul><h2 id="Redis为什么使用跳表而不是B-树？"><a href="#Redis为什么使用跳表而不是B-树？" class="headerlink" title="Redis为什么使用跳表而不是B+树？"></a>Redis为什么使用跳表而不是B+树？</h2><ol><li>内存 vs. 磁盘的设计初衷：<ol><li><strong>B+数是为磁盘I/O优化的</strong>：B+树的设计核心是降低树的的高度，从而减少磁盘I/O次数。</li><li><strong>Redis是纯内存操作</strong>：在内存中，没有磁盘I/O的瓶颈。内存中指针跳转的速度非常快。跳表虽然比B+树高（层数多），但在内存中多几次指针跳转的开销非常小。</li></ol></li><li>实现复杂度与代码维护：<ol><li>跳表（Skip List）：本质上是“<strong>多层链表</strong>”，其插入、删除逻辑主要是修改指针，代码实现非常简洁。</li><li>B+树：插入和删除可能引发节点的分裂和合并，甚至需要<strong>对整棵树进行重平衡</strong>。实现一个健壮、高效的B+树非常复杂，代码量大且难以调试。</li></ol></li><li>写入性能与重平衡代价：<ol><li>B+树的写入抖动：当插入数据导致页分裂时，可能需要移动大量数据或改变树结构，这会产生性能抖动。</li><li>跳表的局限性：跳表的插入和删除操作是局部的。插入一个节点只需要修改前后节点的指针，并根据概率随机生成层高。它不需要像红黑树或B+树那样进行全局的旋转或复杂的结构调整。</li></ol></li></ol><h2 id="String是用什么存储的？为什么不用C语言中的字符串？"><a href="#String是用什么存储的？为什么不用C语言中的字符串？" class="headerlink" title="String是用什么存储的？为什么不用C语言中的字符串？"></a>String是用什么存储的？为什么不用C语言中的字符串？</h2><p>Redis的String字符串是用SDS数据结构存储的。<br><img src="SDS%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="SDS数据结构"></p><ul><li><code>len</code>，记录了字符串长度。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要$O(1)$。</li><li><code>alloc</code>，分配给字符数组的空间长度。这样在修改字符串的时候，可以通过<code>alloc - len</code> 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将SDS的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用SDS既不需要手动修改SDS的空间大小，也不会出现前面所说的缓冲区溢出的问题。</li><li><code>flags</code>，用来表示不同类型的SDS。一共设计了5种类型，分别是<code>sdshdr5</code>、<code>sdshdr8</code>、<code>sdshdr16</code>、<code>sdshdr32</code>、<code>sdshdr64</code>。</li><li><code>buf[]</code>，字符数组，用来保存实际数据。不仅可以保存字符串，也可以保存二进制数据。</li></ul><h3 id="相比于C语言的优势："><a href="#相比于C语言的优势：" class="headerlink" title="相比于C语言的优势："></a>相比于C语言的优势：</h3><ul><li><strong>$O(1)$复杂度获取字符串的长度</strong>。C语言需要遍历，时间复杂度是$O(N)$。</li><li><strong>二进制安全</strong>。因为SDS不需要用”\0”字符来标识字符串结尾了，而是有个专门的len成员变量来记录长度，所以可以存储包含”\0”的数据。但是SDS为了兼容部分C语言标准库的函数，SDS字符串结尾还是会加上”\0”字符。而C语言会通过”\0”来判断字符串的结束，所以不能存储任何带有”\0”的字符串。</li><li><strong>不会发生缓冲区溢出</strong>。Redis的SDS结构里引入了<code>alloc</code>和<code>len</code>成员变量，这样SDS API通过<code>alloc - len</code>计算，可以算出剩余可用的空间大小，这样在对字符串做修改的时候，就可以由程序内部判断缓冲区大小是否足够用。当判断出缓冲区大小不够用时，Redis会自动将扩大SDS的空间大小，以满足修改所需的大小。而C语言需要开发者来保证缓冲区大小。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Redis底层数据结构&quot;&gt;&lt;a href=&quot;#Redis底层数据结构&quot; class=&quot;headerlink&quot; title=&quot;Redis底层数据结构&quot;&gt;&lt;/a&gt;Redis底层数据结构&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;结构类型&lt;/th&gt;
&lt;t</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="Redis" scheme="http://lixrangel.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>MySQL架构</title>
    <link href="http://lixrangel.com/2025/12/20/java-ba-gu/mysql/mysql-jia-gou/"/>
    <id>http://lixrangel.com/2025/12/20/java-ba-gu/mysql/mysql-jia-gou/</id>
    <published>2025-12-19T16:00:00.000Z</published>
    <updated>2026-01-19T11:56:22.685Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MySQL主从复制"><a href="#MySQL主从复制" class="headerlink" title="MySQL主从复制"></a>MySQL主从复制</h2><ul><li>MySQL的主从复制依赖于bin log，也就是记录MySQL上的所有变化并以二进制形式保存在磁盘上。<font color="#ff0000">复制的过程就是将bin log中的数据从主库传输到从库上</font>。</li><li>这个过程一般是<font color="#ff0000">异步</font>的，也就是主库上执行事务操作的线程不会等待复制binlog的线程同步完成。</li><li>MySQL集群的主从复制过程梳理成3个阶段：<ul><li><strong>写入bin log</strong>：MySQL主库在收到客户端提交事务的请求之后，会先写入bin log，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。</li><li><strong>同步bin log</strong>：从库会创建一个专门的I/O线程，连接主库的log dump线程，来接收主库的bin log日志，再把bin log的信息写入从库的relay log中继日志里，再返回给主库“复制成功”的响应。</li><li><strong>回放bin log</strong>：从库会创建一个用于回放bin log的线程，去读relay log中继日志，然后回放bin log更新存储引擎中的数据，最终实现主从的数据一致性。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;MySQL主从复制&quot;&gt;&lt;a href=&quot;#MySQL主从复制&quot; class=&quot;headerlink&quot; title=&quot;MySQL主从复制&quot;&gt;&lt;/a&gt;MySQL主从复制&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;MySQL的主从复制依赖于bin log，也就是记录MySQL上的所有变</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="MySQL" scheme="http://lixrangel.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL性能调优</title>
    <link href="http://lixrangel.com/2025/12/19/java-ba-gu/mysql/mysql-xing-neng-diao-you/"/>
    <id>http://lixrangel.com/2025/12/19/java-ba-gu/mysql/mysql-xing-neng-diao-you/</id>
    <published>2025-12-18T16:00:00.000Z</published>
    <updated>2026-01-19T11:55:36.083Z</updated>
    
    <content type="html"><![CDATA[<h2 id="给你张表，发现查询速度很慢，你有哪些解决方案？"><a href="#给你张表，发现查询速度很慢，你有哪些解决方案？" class="headerlink" title="给你张表，发现查询速度很慢，你有哪些解决方案？"></a>给你张表，发现查询速度很慢，你有哪些解决方案？</h2><ul><li><strong>分析查询语句</strong>：使用<font color="#ff0000">EXPLAIN命令分析SQL执行计划</font>，找出慢查询的原因，比如是否使用了全表扫描，是否存在索引未被利用的情况等，并根据相应情况对索引进行适当修改。</li><li><strong>创建或优化索引</strong>：<font color="#ff0000">根据查询条件创建合适的索引</font>，特别是经常用于WHERE子句的字段、Order by排序的字段、Join联表查询的字段、group by的字段，并且如果查询中经常涉及多个字段，考虑创建联合索引（注意要符合最左匹配原则）。</li><li><strong>避免索引失效</strong>：比如不要用左模糊匹配、函数计算、表达式计算等等。</li><li><strong>表结构优化</strong>：优化表结构设计，包括选择合适的字段类型、避免冗余字段、合理使用范式和反范式设计等等。</li><li><strong>查询优化</strong>：避免使用SELECT*，只查询真正需要的列；使用覆盖索引，即索引包含所有查询的字段；联表查询最好要以小表驱动大表，并且被驱动表的字段要有索引，当然最好通过冗余字段的设计，避免联表查询。</li><li><strong>分页优化</strong>：针对<code>limit n, y</code>深分页的查询优化，可以把limit查询转换成某个位置的查询：<code>select * from tb_sku where id &gt; 20000 limit 10</code>，该方案适用于主键自增的表。</li><li><strong>优化数据库表</strong>：如果单表的数据超过了千万级别，考虑是否需要将大表拆分为小表，减轻单个表的查询压力。也可以将字段多的表分解成多个表，有些字段使用频率高，有些低，数据量大时，会由于使用频率低的存在而变慢，可以考虑分开。</li><li><strong>使用缓存技术</strong>：引入缓存层，如redis，存储热点数据和频繁查询的结果，但是要考虑缓存一致性的问题，对于读请求会选择旁路缓存策略，对于写请求会选择先更新db，再删除缓存的策略。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;给你张表，发现查询速度很慢，你有哪些解决方案？&quot;&gt;&lt;a href=&quot;#给你张表，发现查询速度很慢，你有哪些解决方案？&quot; class=&quot;headerlink&quot; title=&quot;给你张表，发现查询速度很慢，你有哪些解决方案？&quot;&gt;&lt;/a&gt;给你张表，发现查询速度很慢，你有哪</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="MySQL" scheme="http://lixrangel.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL日志</title>
    <link href="http://lixrangel.com/2025/12/18/java-ba-gu/mysql/mysql-ri-zhi/"/>
    <id>http://lixrangel.com/2025/12/18/java-ba-gu/mysql/mysql-ri-zhi/</id>
    <published>2025-12-17T16:00:00.000Z</published>
    <updated>2026-01-19T11:57:33.742Z</updated>
    
    <content type="html"><![CDATA[<h2 id="日志文件分为哪几种？"><a href="#日志文件分为哪几种？" class="headerlink" title="日志文件分为哪几种？"></a>日志文件分为哪几种？</h2><ul><li><strong>redo log重做日志</strong>：是InnoDB存储引擎层生成的日志，实现了事务中的<font color="#ff0000">持久性</font>，主要用于<font color="#ff0000">掉电等故障恢复</font>。</li><li><strong>undo log回滚日志</strong>：是InnoDB存储引擎层生成的日志，实现了事务中的<font color="#ff0000">原子性</font>，主要用于<font color="#ff0000">事务回滚</font>和<font color="#ff0000">MVCC</font>。</li><li><strong>bin log二进制日志</strong>：是Server层生成的日志，主要用于<font color="#ff0000">数据备份</font>和<font color="#ff0000">主从复制</font>。</li><li><strong>relay log中继日志</strong>：用于主从复制场景下，slave通过IO线程拷贝master的bin log后生成本地的日志。</li><li><strong>慢查询日志</strong>：用于记录执行时间过长的SQL，需要设置阈值后手动开启。</li></ul><h2 id="bin-log"><a href="#bin-log" class="headerlink" title="bin log"></a>bin log</h2><ul><li>MySQL在完成一条<font color="#ff0000">更新操作</font>后，Server层会生成一条bin log，等之后事务提交的时候，会将该事务执行过程中产生的所有bin log统一写入bin log文件，bin log是MySQL的Server层实现的日志，所有存储引擎都可以使用。</li><li>bin log是<font color="#ff0000">追加写</font>，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志，用于<font color="#ff0000">备份恢复</font>、<font color="#ff0000">主从复制</font>。</li><li>bin log文件记录了所有数据库表结构变更和表数据修改，不会记录查询类的操作，比如<code>SELECT</code>和<code>SHOW</code>操作。</li><li>bin log有三种格式类型：<ul><li><strong>STATEMENT（默认格式）</strong>：每一条修改数据的SQL语句都会被记录到bin log中（相当于记录了逻辑操作，所以针对这种格式，bin log可以称为逻辑日志），主从复制中slave端再根据SQL语句重现。但STATEMENT有<font color="#ff0000">动态函数</font>的问题，比如用了<font color="#ff0000">uuid或者now</font>这些函数，在主库上执行的结果和在从库上执行的结果不一致，这种随时在变的函数会导致复制的数据不一致。</li><li><strong>ROW</strong>：记录行数据最后被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现STATEMENT下动态函数的问题。但ROW的缺点是每行数据的变化结果都会被记录，比如执行批量update语句，<font color="#ff0000">更新多少行数据就会产生多少条记录，使bin log文件过大</font>，而在STATEMENT格式下只会记录一个update语句而已。</li><li><strong>MIXED</strong>：包含了STATEMENT和ROW模式，它会根据不同的情况自动使用ROW模式和STATEMENT模式。</li></ul></li></ul><h2 id="undo-log日志的作用是什么？"><a href="#undo-log日志的作用是什么？" class="headerlink" title="undo log日志的作用是什么？"></a>undo log日志的作用是什么？</h2><ul><li>是一种用于撤销回退的日志，它保证了事务的ACID特性中的<font color="#ff0000">原子性</font>。</li><li>每当InnoDB引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到undo log里，比如：<ul><li>在<strong>插入</strong>一条记录时，要把<strong>这条记录的主键值</strong>记下来，这样之后回滚时只需要把这个主键值对应的记录删除就好了。</li><li>在<strong>删除</strong>一条记录时，要把<strong>这条记录中的内容</strong>都记下来，这样之后回滚时再把由这些内容组成的记录插入到表中就好了。</li><li>在<strong>更新</strong>一条记录时，要把<strong>被更新的列的旧值</strong>记下来，这样之后回滚时再把这些列更新为旧值就好了。</li></ul></li><li>undo log是更新在内存中的，依赖于redo log保护。如果undo log更新了，那么redo log也随之更新，避免断电后undo log丢失。</li></ul><h2 id="为什么需要redo-log？"><a href="#为什么需要redo-log？" class="headerlink" title="为什么需要redo log？"></a>为什么需要redo log？</h2><ul><li>为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以redo log的形式记录下来（<font color="#ff0000">不止记录数据的修改，还记录undo log的修改</font>），这个时候更新就算完成了。</li><li>后续，InnoDB引擎会在适当的时候，由后台线程将缓存在Buffer Pool的脏页刷新到磁盘里，这就是 WAL（Write-Ahead Logging）技术。WAL 技术指的是，MySQL的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。</li><li>redo log是<font color="#ff0000">物理日志</font>，记录了某个数据页做了什么修改，比如对XXX表空间中的YYY数据页ZZZ偏移量的地方做了AAA更新，每当执行一个事务就会产生这样的一条或多条物理日志。</li><li>写入redo log的方式使用了追加操作，所以磁盘操作是<font color="#ff0000">顺序写</font>，而写入数据需要先找到写入位置，然后才写到磁盘，磁盘操作是随机写。顺序写比随机写高效的多，因此redo log写入磁盘的开销更小。</li><li>好处：<ul><li><font color="#ff0000">实现事务的持久性</font>，让MySQL有崩溃恢复的能力，能够保证MySQL在任何时间段突然崩溃，重启后之前已提交的数据都不会丢失。</li><li>将写操作从【<font color="#ff0000">随机写</font>】变成了【<font color="#ff0000">顺序写</font>】，提升MySQL写入磁盘的性能。</li></ul></li></ul><h2 id="redo-log是怎么保持持久性的？"><a href="#redo-log是怎么保持持久性的？" class="headerlink" title="redo log是怎么保持持久性的？"></a>redo log是怎么保持持久性的？</h2><ul><li><strong>Write-Ahead Logging（WAL）</strong>：在事务提交之前，将事务所做的修改操作记录到redo log中，然后再将数据写入磁盘。这样即使在数据写入磁盘之前发生了宕机，系统可以通过redo log中的记录来恢复数据。</li><li><strong>redo log的顺序写入</strong>：redo log采用追加写入的方式，将redo日志记录追加到文件末尾，而不是随机写入。这样可以减少磁盘的随机I/O操作，提高写入性能。</li><li><strong>Checkpoint机制</strong>：MySQL会定期将内存中的数据刷新到磁盘，同时将最新的LSN（Log Sequence Number）记录到磁盘中，这个LSN可以确保redo log中的操作是按顺序执行的。在恢复数据时，系统会根据LSN来确定从哪个位置开始应用redo log。</li></ul><h2 id="Update语句的具体执行过程？"><a href="#Update语句的具体执行过程？" class="headerlink" title="Update语句的具体执行过程？"></a>Update语句的具体执行过程？</h2><p>更新一条记录<code>Update t_user SET name = &#39;xiaolin&#39; WHERE id = 1;</code>的流程如下：</p><ol><li>执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取id = 1 这一行记录：<ol><li>如果 id = 1 这一行所在的数据页本来就在buffer pool中，就直接返回给执行器更新；</li><li>如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器；</li></ol></li><li>执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：<ol><li>如果一样的话就不进行后续更新流程；</li><li>如果不一样的话就把更新前的记录和更新后的记录都当作参数传给InnoDB层，让InnoDB真正的执行更新记录的操作；</li></ol></li><li>开启事务，InnoDB层更新记录前，首先要记录相应的undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条undo log，undo log会写入 Buffer Pool 中的undo页面，不过在内存修改该undo页面后，需要记录对应的redo log。</li><li>InnoDB层开始更新记录，会<strong>先更新内存（同时标记为脏页）</strong>，然后<strong>将记录写到redo log</strong>里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是WAL技术，MySQL的写操作并不是立刻写到磁盘上，而是先写redo日志，然后在合适的时间再将修改的行数据写到磁盘上。</li><li>至此，一条记录更新完成了。</li><li>在一条更新语句执行完成后，然后开始记录该语句对应的bin log，此时记录的bin log会被保存到bin log cache，并没有刷新到硬盘上的bin log文件，在事务提交时才会统一将该事务运行过程中的所有bin log刷新到硬盘。</li><li>事务提交：<ol><li>prepare阶段：将redo log对应的事务状态设置为prepare，然后将redo log刷新到硬盘。</li><li>commit阶段：将bin log刷新到磁盘，接着调用引擎的提交事务接口，将redo log状态设置为commit。</li></ol></li><li>至此，一条更新语句执行完成。</li></ol><table><thead><tr><th>redo log状态</th><th>bin log状态</th><th>InnoDB动作</th><th>结果</th></tr></thead><tbody><tr><td>Commit</td><td>存在</td><td>事务已完成，不需要操作</td><td>一致</td></tr><tr><td>Prepare</td><td>不存在</td><td>Rollback事务</td><td>保证bin log为空，主从一致</td></tr><tr><td>Prepare</td><td>存在</td><td>提交事务，补齐commit状态</td><td>保证bin log存在，主从一致</td></tr></tbody></table><p>redo log处于prepare状态时，InnoDB会去检查是否存在相应的bin log记录。如果bin log存在，说明MySQL Server认为该提交已经发生，InnoDB必须执行提交操作；如果bin log不存在，则执行回滚。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;日志文件分为哪几种？&quot;&gt;&lt;a href=&quot;#日志文件分为哪几种？&quot; class=&quot;headerlink&quot; title=&quot;日志文件分为哪几种？&quot;&gt;&lt;/a&gt;日志文件分为哪几种？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;redo log重做日志&lt;/strong&gt;：是I</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="MySQL" scheme="http://lixrangel.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL事务</title>
    <link href="http://lixrangel.com/2025/12/17/java-ba-gu/mysql/mysql-shi-wu/"/>
    <id>http://lixrangel.com/2025/12/17/java-ba-gu/mysql/mysql-shi-wu/</id>
    <published>2025-12-16T16:00:00.000Z</published>
    <updated>2026-01-19T11:53:21.296Z</updated>
    
    <content type="html"><![CDATA[<h2 id="事务的特性"><a href="#事务的特性" class="headerlink" title="事务的特性"></a>事务的特性</h2><ul><li><strong>原子性（Atomicity）</strong>：一个事务中的所有操作，<font color="#ff0000">要么全部完成，要么全部不完成</font>，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态。</li><li><strong>一致性（Consistency）</strong>：事务操作前和操作后，数据满足完整性约束，<font color="#ff0000">数据库保持一致性状态</font>。</li><li><strong>隔离性（Isolation）</strong>：隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，多个事务是同时使用相同的数据时，<font color="#ff0000">不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的</font>。</li><li><strong>持久性（Durability）</strong>：事务处理结束后，<font color="#ff0000">对数据的修改就是永久的</font>，即使系统故障也不会丢失。<br>MySQL的InnoDB引擎通过什么技术来保证事务的这四个特性？</li><li><strong>持久性</strong>是通过<strong>redolog（重做日志）</strong>来保证的。</li><li><strong>原子性</strong>是通过<strong>undolog（回滚日志）</strong>来保证的。</li><li><strong>隔离性</strong>是通过<strong>MVCC（多版本并发控制）或锁机制</strong>来保证的。</li><li><strong>一致性</strong>是通过<strong>持久性+原子性+隔离性</strong>来保证的。</li></ul><h2 id="并发事务带来了哪些问题？"><a href="#并发事务带来了哪些问题？" class="headerlink" title="并发事务带来了哪些问题？"></a>并发事务带来了哪些问题？</h2><ul><li><strong>脏读（Dirty read）</strong>：【<font color="#ff0000">一个事务读到了另一个未提交事务修改过的数据</font>】。一个事务读取数据并且对数据进行了修改，这个修改对其他事务来说是可见的，即使当前事务没有提交。这时另一个事务读取到了这个还未提交的数据，但是第一个事务突然回滚，导致数据并没有提交到数据库，那第二个事务读取到的就是脏数据。<br><img src="%E8%84%8F%E8%AF%BB.png" alt="脏读"></li><li><strong>不可重复读（Unrepeatable read）</strong>：【在<font color="#ff0000">一个事务内多次读取同一个数据</font>，出现前后两次读到的数据不一样的情况】。指在一个事务内多次读同一个数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读到的数据不一样。<br><img src="%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB.png" alt="不可重复读"></li><li><strong>幻读（Phantom read）</strong>：【在一个事务内多次查询某个符合查询条件的<font color="#ff0000">记录数量</font>，出现前后两次查询到的记录不一样的情况】。幻读发生在一个事务读取了几行数据，接着另一个并发事务插入了一些数据。在随后的查询中，第一个事务就会发现多了一些原本不存在的记录。<br><img src="%E5%B9%BB%E8%AF%BB.png" alt="幻读"></li></ul><h2 id="并发事务的控制方式"><a href="#并发事务的控制方式" class="headerlink" title="并发事务的控制方式"></a>并发事务的控制方式</h2><ul><li><strong>锁机制</strong>：MySQL提供了多种锁机制来保证数据一致性，包括行级锁、表级锁、页级锁等。通过锁机制，可以在读写操作时对数据进行加锁，确保同时只有一个操作能够访问或修改数据。</li><li><strong>事务隔离级别</strong>：MySQL提供了多种事务隔离级别，包括读未提交、读已提交、可重复读和串行化。通过合适的事务隔离级别，可以在多个并发执行时，控制事务之间的隔离程度，以避免数据不一致的问题。</li><li><strong>MVCC（多版本并发控制）</strong>：<font color="#ff0000">对一份数据会存储多个版本</font>，通过事务的可见性来保证事务能看到自己应该看到的版本。</li></ul><h2 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h2><ul><li><strong>读未提交（read uncommitted）</strong>：指一个事务还没提交时，它做的变更就可以被其他事务看到；可能会<font color="#ff0000">导致脏读、幻读或不可重复读</font>。这种级别在实际应用中很少使用。</li><li><strong>读已提交（read committed）</strong>：指一个事务提交之后，它做的变更才能被其他事务看到；<font color="#ff0000">可以阻止脏读，但是幻读或不可重复读仍有可能发生</font>。（通过read view实现，在<font color="#ff0000">每个语句执行前</font>会重新生成一个read view）</li><li><strong>可重复读（repeatable read）</strong>：在一个事务内多次读取的数据和事务启动时的数据是一致的，也就是说多次读的该事务只要不提交，就看不到最新的修改数据。<font color="#ff0000">可以阻止脏读和不可重复读，但幻读仍有可能发生</font>。MySQL InnoDB引擎的默认隔离级别；（通过read view实现，<font color="#ff0000">在启动事务时</font>生成一个read view）</li><li><strong>串行化（serializable）</strong>：最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰。可以防止脏读、不可重复读以及幻读。（通过加读写锁实现）</li></ul><h2 id="MVCC（多版本并发控制）"><a href="#MVCC（多版本并发控制）" class="headerlink" title="MVCC（多版本并发控制）"></a>MVCC（多版本并发控制）</h2><p><img src="mvcc_read_view.png" alt="MVCC的Read View"></p><ul><li><strong>Read View</strong>，用于判断当前事务“能看到哪些版本的数据”：<ul><li><code>m_ids</code>：表示在生成Read View时，当前系统中已经启动但未提交的读写事务的ID列表（就是说有些事务虽然id很大，但是可能已经提交了，就不会在这个列表中）。</li><li><code>min_trx_id</code>：<code>m_ids</code>中的最小值，小于这个ID的事务都已经提交了，它们修改的数据对当前事务可见。</li><li><code>max_trx_id</code>：等于生成Read View时，系统应该分配给下一个事务的ID值（即当前最大事务ID+1）。大于等于这个ID的事务是在Read View生成之后才开启的，它们修改的数据对当前事务不可见。</li></ul></li><li>数据库中每行数据都有三个隐藏字段：<ul><li><code>trx_id</code>：最后一次插入或者更新该行数据的事务id；</li><li><code>roll_pointer</code>：回滚指针，指向该行数据的undo log；</li><li><code>row_id</code>：如果没有设置主键且该表没有唯一非空索引时，InnoDB会使用该id来生成聚簇索引。</li></ul></li><li>一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有几种情况：<ul><li>如果记录的<code>trx_id</code>值小于Read View中的<code>min_trx_id</code>值，表示这个版本的记录是在创建Read View前已经提交的事务生成的，所以该版本的记录对当前事务可见。</li><li>如果记录的<code>trx_id</code>值大于等于Read View中的<code>max_trx_id</code>值，表示这个版本的记录是在创建Read View后才启动的事务生成的，所以该版本的记录对当前事务不可见。</li><li>如果记录的<code>trx_id</code>值在Read View的<code>min_trx_id</code>和<code>max_trx_id</code>之间，需要判断<code>trx_id</code>是否在<code>m_ids</code>列表中：<ul><li>如果记录的<code>trx_id</code>在<code>m_ids</code>列表中，表示生成该版本记录的事务还没有提交，所以该版本的记录对当前事务不可见。</li><li>如果记录的<code>trx_id</code>不在<code>m_ids</code>列表中，表示生成该版本记录的事务已经被提交，所以该版本的记录对当前事务可见。</li></ul></li></ul></li></ul><h2 id="读已提交和可重复读隔离级别创建Read-View时间"><a href="#读已提交和可重复读隔离级别创建Read-View时间" class="headerlink" title="读已提交和可重复读隔离级别创建Read View时间"></a>读已提交和可重复读隔离级别创建Read View时间</h2><ul><li><strong>读已提交</strong>是在【每个select语句执行前】都会重新生成一个read view；</li><li><strong>可重复读</strong>是在执行第一条select时，生成一个read view，然后整个事务期间都在用这个read view。</li></ul><h2 id="解决幻读的办法"><a href="#解决幻读的办法" class="headerlink" title="解决幻读的办法"></a>解决幻读的办法</h2><ul><li>将事务隔离级别调整为<code>serializable</code>；</li><li>在可重复读的事务下，给事务操作的这张表添加表锁；</li><li>在可重复读的事务下，给事务操作的这张表添加Next-key Lock（Record Lock + Gap Lock）。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;事务的特性&quot;&gt;&lt;a href=&quot;#事务的特性&quot; class=&quot;headerlink&quot; title=&quot;事务的特性&quot;&gt;&lt;/a&gt;事务的特性&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;原子性（Atomicity）&lt;/strong&gt;：一个事务中的所有操作，&lt;font col</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="MySQL" scheme="http://lixrangel.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL存储引擎</title>
    <link href="http://lixrangel.com/2025/12/16/java-ba-gu/mysql/mysql-cun-chu-yin-qing/"/>
    <id>http://lixrangel.com/2025/12/16/java-ba-gu/mysql/mysql-cun-chu-yin-qing/</id>
    <published>2025-12-15T16:00:00.000Z</published>
    <updated>2026-01-19T11:48:26.405Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MySQL的存储引擎"><a href="#MySQL的存储引擎" class="headerlink" title="MySQL的存储引擎"></a>MySQL的存储引擎</h2><ul><li><strong>InnoDB</strong>：InnoDB是MySQL的默认存储引擎，具有<font color="#ff0000">ACID事务支持</font>、<font color="#ff0000">行级锁</font>、<font color="#ff0000">外键约束</font>等特性。</li><li><strong>MyISAM</strong>：MyISAM是MySQL的另一种常见的存储引擎，具有<font color="#ff0000">较低的存储空间</font>和<font color="#ff0000">内存消耗</font>，适用于<font color="#ff0000">大量读操作</font>的场景。然而，MyISAM不支持事务、行级锁和外键约束，因此在并发写入和数据完整性方面有一定的限制。</li><li><strong>Memory</strong>：Memory引擎将数据<font color="#ff0000">存储在内存中</font>，适用于对性能要求较高的读操作，但是在服务器重启或崩溃时数据会丢失。不支持事务、行级锁和外键约束。</li></ul><h2 id="MySQL为什么InnoDB是默认引擎（InnoDB的优势）？"><a href="#MySQL为什么InnoDB是默认引擎（InnoDB的优势）？" class="headerlink" title="MySQL为什么InnoDB是默认引擎（InnoDB的优势）？"></a>MySQL为什么InnoDB是默认引擎（InnoDB的优势）？</h2><p>InnoDB引擎在事务支持、并发性能、崩溃恢复等方面具有优势，因此被MySQL选择为默认的存储引擎。</p><ul><li><strong>事务支持</strong>：InnoDB引擎提供了对事务的支持，可以进行ACID（原子性、一致性、隔离性、持久性）属性的操作。</li><li><strong>并发性能</strong>：InnoDB引擎采用了<font color="#ff0000">行级锁定</font>的机制，可以提供更好的并发性能。</li><li><strong>崩溃恢复</strong>：InnoDB引擎<font color="#ff0000">通过redolog日志</font>实现了崩溃恢复，可以在数据库发生异常情况（如断电）时，通过日志文件进行恢复，保证数据的持久性和一致性。</li></ul><h2 id="InnoDB和MyISAM的区别"><a href="#InnoDB和MyISAM的区别" class="headerlink" title="InnoDB和MyISAM的区别"></a>InnoDB和MyISAM的区别</h2><ul><li><strong>锁粒度</strong>：InnoDB支持行级别的锁粒度，MyISAM不支持，只支持表级别的锁粒度。</li><li><strong>事务支持</strong>：MyISAM不提供事务支持。InnoDB提供事务支持，实现了SQL标准定义的四个隔离级别。</li><li><strong>外键</strong>：MyISAM不支持外键，而InnoDB支持。</li><li><strong>崩溃恢复</strong>：MyISAM不支持数据库异常崩溃后的安全恢复，而InnoDB支持，依赖于redo log。</li><li><strong>MVCC</strong>：MyISAM不支持MVCC，而InnoDB支持。</li><li><strong>索引</strong>：虽然MyISAM和InnoDB都是使用B+树作为索引结构，但是两者的实现方式不太一样。<font color="#ff0000">InnoDB是聚簇索引</font>，MyISAM是非聚簇索引。聚簇索引的文件存放在主键索引的叶子节点上，因此InnoDB必须要有主键，通过主键索引效率很高。MyISAM是非聚簇索引，数据文件是分离的，索引保存的是数据文件的指针。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;MySQL的存储引擎&quot;&gt;&lt;a href=&quot;#MySQL的存储引擎&quot; class=&quot;headerlink&quot; title=&quot;MySQL的存储引擎&quot;&gt;&lt;/a&gt;MySQL的存储引擎&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;InnoDB&lt;/strong&gt;：InnoDB是M</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="MySQL" scheme="http://lixrangel.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL索引</title>
    <link href="http://lixrangel.com/2025/12/15/java-ba-gu/mysql/mysql-suo-yin/"/>
    <id>http://lixrangel.com/2025/12/15/java-ba-gu/mysql/mysql-suo-yin/</id>
    <published>2025-12-14T16:00:00.000Z</published>
    <updated>2026-01-19T11:46:41.203Z</updated>
    
    <content type="html"><![CDATA[<h2 id="索引为什么快？"><a href="#索引为什么快？" class="headerlink" title="索引为什么快？"></a>索引为什么快？</h2><ul><li>大大减少了磁盘I/O的次数。</li></ul><h2 id="为什么InnoDB没有使用哈希作为索引？"><a href="#为什么InnoDB没有使用哈希作为索引？" class="headerlink" title="为什么InnoDB没有使用哈希作为索引？"></a>为什么InnoDB没有使用哈希作为索引？</h2><ul><li>优点：等值查询时理论上时间复杂度是O(1)。</li><li>缺点：<ul><li><strong>不支持范围查询</strong>，会将范围内的值映射到哈希表完全不相邻的地方。</li><li><strong>不支持排序</strong>，因为哈希值是无序的，所以无法利用哈希索引来优化order by子句。</li><li><strong>不支持部分索引键查询</strong>，对于联合索引，比如(col1, col2)，哈希索引必须使用所有索引列进行查询，它无法单独利用col1来加速查询。</li><li><strong>哈希冲突问题</strong>，当不同的键产生相同的哈希值时，需要额外的链表或开放寻址来解决，这会降低性能。</li></ul></li></ul><h2 id="B树和B-树的区别"><a href="#B树和B-树的区别" class="headerlink" title="B树和B+树的区别"></a>B树和B+树的区别</h2><ul><li>在B+树中，<strong>数据都存储在叶子节点上</strong>，而<strong>非叶子节点只存储索引信息</strong>；而B树的非叶子节点既存储索引信息也存储部分数据。<ul><li>好处：B+树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比既存储索引又存储记录的B树，<strong>B+树的非叶子节点可以存放更多的索引</strong>，因此B+树可以比B树更“矮胖”，查询底层节点的<strong>磁盘I/O次数会更少</strong>。</li></ul></li><li>B+树的叶子节点使用链表相连，便于<strong>范围查询和顺序访问</strong>；B树的叶子节点没有链表连接。<ul><li>好处：B+树叶子节点之间用链表连接了起来，有利于范围查询，而B树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会设计多个节点的磁盘I/O操作，范围查询效率不如B+树。</li></ul></li><li>B+树每次查找都需要查找到叶子节点，<strong>查询性能更稳定</strong>；而B树的查找可能会在非叶子节点找到数据，性能相对不稳定。</li></ul><h2 id="B-树作为索引数据结构的优势？"><a href="#B-树作为索引数据结构的优势？" class="headerlink" title="B+树作为索引数据结构的优势？"></a>B+树作为索引数据结构的优势？</h2><ul><li>B+树的非叶子节点不存放实际的数据，仅存放索引，因此数据量相同的情况下，B+树的非叶子节点可以存放更多的索引，因此更“矮胖”，查询底层节点的<strong>磁盘I/O次数会更少</strong>。</li><li>B+树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让B+树<strong>在插入、删除的效率都更高</strong>，比如删除根节点的时候，只会删除叶子节点，不会像B树那样发生复杂的树的变化。</li><li>B+树的叶子节点是一个双向链表，<strong>有利于范围查询</strong>。</li></ul><h2 id="聚簇索引和非聚簇索引"><a href="#聚簇索引和非聚簇索引" class="headerlink" title="聚簇索引和非聚簇索引"></a>聚簇索引和非聚簇索引</h2><ul><li><strong>聚簇索引</strong>：聚簇索引是<font color="#ff0000">索引结构和数据一起存放</font>的索引，数据行按照索引键值的顺序存储。一个表只能有一个聚簇索引，因为数据只能有一种物理排序方式。<ul><li>优点：<ul><li>查询速度非常快，相比于非聚簇索引，少了一次读取数据的IO操作。</li><li>对排序查找和范围查找优化：聚簇索引对于主键的排序查找和范围查找速度非常快。</li></ul></li><li>缺点：<ul><li>依赖于有序的数据。</li><li>更新代价大。</li></ul></li></ul></li><li><strong>非聚簇索引</strong>：<font color="#ff0000">索引结构和数据分开存放的索引</font>。非聚簇索引的叶子节点存放的可能是<font color="#ff0000">数据行的指针</font>，也可能是<font color="#ff0000">主键值</font>。数据行本身存储在聚簇索引。<ul><li>优点：更新代价比聚簇索引要小，因为叶子节点不存放数据。</li><li>缺点：<ul><li>依赖于有序的数据。</li><li>可能会二次查询（回表）。</li></ul></li></ul></li></ul><h2 id="覆盖索引和联合索引"><a href="#覆盖索引和联合索引" class="headerlink" title="覆盖索引和联合索引"></a>覆盖索引和联合索引</h2><ul><li><strong>覆盖索引</strong>：如果<font color="#ff0000">一个索引包含所有需要查询的字段的值</font>，就称为覆盖索引。覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引就可以查到数据了，无需回表查询。</li><li><strong>联合索引</strong>：使用表中的多个字段创建索引，就是联合索引。<ul><li><code>ALTER TABLE cus_order ADD INDEX id_score_name(score, name);</code>这里的联合索引是先按照score排序，在score相同的情况下再按照name排序；</li><li><font color="#ff0000">最左匹配原则</font>：在使用联合索引时，会按照最左优先的方式进行索引匹配。也就是说先匹配score，如果score相同，再匹配name。</li><li>比如，如果创建了一个(a, b, c)的联合索引，如果查询条件是以下几种，就可以匹配上联合索引：<ul><li><code>where a = 1;</code></li><li><code>where a = 1 and b = 2 and c = 3;</code></li><li><code>where a = 1 and b = 2;</code></li></ul></li><li>注：因为有查询优化器，所以<font color="#ff0000">a字段在where子句的顺序并不重要</font>。但是如果是以下几种，不符合最左匹配原则，所以无法匹配上联合索引，联合索引就会失效：<ul><li><code>where b = 2;</code></li><li><code>where c = 3;</code></li><li><code>where b = 2 and c = 3;</code></li></ul></li></ul></li></ul><h2 id="什么是索引下推？"><a href="#什么是索引下推？" class="headerlink" title="什么是索引下推？"></a>什么是索引下推？</h2><ul><li>索引下推（Index Condition Pushdown，简称ICP）是MySQL 5.6版本引入的一项优化技术。</li><li>场景设定：<ul><li>假设有一张员工表user，有一个联合索引 idx_name_age(name, age)。我们执行下面这条SQL：<code>SELECT * FROM user WHERE name LIKE &#39;张%&#39; AND age = 10;</code>。<ul><li>没有索引下推时：根据最左匹配原则，<code>name LIKE &#39;张%&#39;</code> 可以用到索引，但后面的<code>age = 10</code>无法用到索引查找（因为name是范围查询，导致后面的列无序的）。执行流程是这样的：<ul><li><strong>存储引擎层</strong>：在索引树上找到所有name以“张”开头的记录（假设有100条）。因为它是负责“找数据”的，它不管age是多少（虽然索引里明明有age），它会把这100条记录的主键ID拿出来，<font color="#ff0000">进行100次回表查询</font>，把完整的行数据取出来。</li><li><strong>Server层</strong>：拿到这100条完整数据后，再判断WHERE age = 10。</li><li>结果：假设只有1个人是10岁，那么那99次回表都是浪费的IO。</li></ul></li><li>有了索引下推后：<ul><li><strong>存储引擎层</strong>：在索引树上找到name以“张”开头的记录。在读取索引记录时，直接判断索引里的age是否等于10。如果不等于10，直接跳过（根本不去回表）。如果等于10，才去回表。</li><li>结果：假设100只有1个人是10岁，那么<font color="#ff0000">只需要1次回表</font>。</li></ul></li></ul></li></ul></li><li>下推的意思就是：<font color="#ff0000">把原本只能在Server层进行的过滤操作（检查age），下推到了存储引擎层进行</font>。</li><li>核心优势：<ul><li><strong>减少回表次数</strong>：这是核心目的。回表涉及随机IO，成本很高。</li><li><strong>减少IO操作</strong>：减少了<font color="#ff0000">Server层和存储引擎层之间的数据交互量</font>。</li></ul></li></ul><h2 id="索引失效有哪些情况？"><a href="#索引失效有哪些情况？" class="headerlink" title="索引失效有哪些情况？"></a>索引失效有哪些情况？</h2><ul><li>当使用<strong>左或者左右模糊匹配</strong>的时候，也就是<code>like%xx</code>或者<code>like%xx%</code></li><li>当在查询条件中<strong>对索引列使用函数</strong>；</li><li>当在查询条件中<strong>对索引列进行表达式计算</strong>；</li><li>MySQL在遇到字符串和数字比较时，会自动把字符串转为数字，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生<strong>隐式类型转换</strong>，由于隐式类型转换是通过CAST函数实现的，就等同于对索引使用了函数；</li><li>联合索引需要<strong>遵循最左匹配原则</strong>，也就是按照最左优先的方式进行索引匹配；</li><li>在WHERE子句中，如果<strong>在OR前的条件列是索引列</strong>，而<strong>在OR条件后的列不是索引列</strong>，那么索引会失效。因为OR条件后的列不是索引列，而结果必须返回满足这个条件的数据，必须需要全表扫描，那自然就是两个条件都进行一边全表扫描就好。</li></ul><h2 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h2><ul><li><strong>前缀索引优化</strong>：使用前缀索引是为了减少索引字段的大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减少索引项的大小。</li><li><strong>覆盖索引优化</strong>：尽量使用覆盖索引。</li><li><strong>主键索引最好是自增的</strong>。</li><li><strong>防止索引失效</strong>。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;索引为什么快？&quot;&gt;&lt;a href=&quot;#索引为什么快？&quot; class=&quot;headerlink&quot; title=&quot;索引为什么快？&quot;&gt;&lt;/a&gt;索引为什么快？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;大大减少了磁盘I/O的次数。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;为什么InnoDB没</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="MySQL" scheme="http://lixrangel.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>JVM调优</title>
    <link href="http://lixrangel.com/2025/12/09/java-ba-gu/jvm/jvm-diao-you/"/>
    <id>http://lixrangel.com/2025/12/09/java-ba-gu/jvm/jvm-diao-you/</id>
    <published>2025-12-08T16:00:00.000Z</published>
    <updated>2026-01-18T11:03:00.109Z</updated>
    
    <content type="html"><![CDATA[<h2 id="JVM参数设置"><a href="#JVM参数设置" class="headerlink" title="JVM参数设置"></a>JVM参数设置</h2><h3 id="设置堆内存大小（-Xms和-Xmx）"><a href="#设置堆内存大小（-Xms和-Xmx）" class="headerlink" title="设置堆内存大小（-Xms和-Xmx）"></a>设置堆内存大小（-Xms和-Xmx）</h3><ul><li>推荐显式设置这两个参数，并且通常建议<strong>将他们设置为相同的值</strong>，以避免堆内存的动态调整带来的性能开销。</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">-Xms&lt;heap</span> <span class="string">size&gt;[unit]</span> <span class="comment">#设置JVM初始堆大小 </span></span><br><span class="line"><span class="string">-Xmx&lt;heap</span> <span class="string">size&gt;[unit]</span> <span class="comment">#设置JVM最大堆大小</span></span><br></pre></td></tr></table></figure><ul><li><code>&lt;heap size&gt;</code>是指定内存的具体数值；</li><li><code>[unit]</code>是指定内存的单位，如G(GB)、M(MB)、K(KB)。</li></ul><h3 id="设置新生代内存大小（Young-Generation）"><a href="#设置新生代内存大小（Young-Generation）" class="headerlink" title="设置新生代内存大小（Young Generation）"></a>设置新生代内存大小（Young Generation）</h3><p>调优策略：</p><blockquote><p>尽量让新创建的对象在新生代分配内存并被回收，因为 Minor GC 的成本通常远低于 Full GC。通过分析 GC 日志，判断新生代空间分配是否合理。如果大量新对象过早进入老年代（Promotion），可以适当通过 -Xmn 或 -XX:NewSize/-XX:MaxNewSize 调整新生代大小，目标是最大限度地减少对象直接进入老年代的情况。</p></blockquote><ol><li> 通过<code>-XX:NewSize</code>和<code>-XX:MaxNewSize</code>指定<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">-XX:NewSize=&lt;young</span> <span class="string">size&gt;[unit]</span> <span class="comment">#指定新生代初始大小</span></span><br><span class="line"><span class="string">-XX:MaxNewSize=&lt;young</span> <span class="string">size&gt;[unit]</span> <span class="comment">#设置新生代最大大小</span></span><br></pre></td></tr></table></figure></li><li>通过<code>-Xmn&lt;young size&gt;[unit]</code>指定<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">-Xmn512m</span></span><br></pre></td></tr></table></figure></li><li>通过<code>-XX:NewRatio=&lt;int&gt;</code>参数来设置老年代与新生代（不含Survivor区）的内存大小比例。<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">-XX:NewRatio=2</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="设置永久代-元空间大小（PermGen-Metaspace）"><a href="#设置永久代-元空间大小（PermGen-Metaspace）" class="headerlink" title="设置永久代/元空间大小（PermGen/Metaspace）"></a>设置永久代/元空间大小（PermGen/Metaspace）</h3><p>从Java 8开始，如果我们没有指定Metaspace的大小，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。</p><ul><li>JDK1.8之前永久代还没被彻底移除的时候通常通过下面这些参数来调节方法区大小。<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">-XX:PermSize=N</span> <span class="comment">#方法区(永久代)初始大小</span></span><br><span class="line"><span class="string">-XX:MaxPermSize=N</span> <span class="comment">#方法区(永久代)最大大小,超过这个值将会抛出 OutOfMemoryError 异常:java.lang.OutOfMemoryError: PermGen</span></span><br></pre></td></tr></table></figure></li><li>JDK1.8的时候，方法区（HotSpot的永久代）被彻底移除了，取而代之的是元空间，元空间使用的是本地内存。<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">-XX:MetaspaceSize=N</span> <span class="comment">#首次触发Full GC的阈值</span></span><br><span class="line"><span class="string">-XX:MaxMetaspaceSize=N</span> <span class="comment">#设置Metaspace的最大大小</span></span><br></pre></td></tr></table></figure>注意：</li><li><code>XX:MetaspaceSize</code>并非初始容量：Metaspace 的初始容量并不是<code>-XX:MetaspaceSize</code>设置，无论<code>-XX:MetaspaceSize</code>配置什么值，对于 64 位 JVM，元空间的<font color="#ff0000">初始容量通常是一个固定的较小值</font>（Oracle 文档提到约 12MB 到 20MB 之间，实际观察约 20.8MB）。</li><li>扩容与 Full GC：当 Metaspace 的使用量增长并首次达到<code>-XX:MetaspaceSize</code>指定的阈值时，会触发一次 Full GC。在此之后，JVM 会动态调整这个触发 GC 的阈值。如果元空间继续增长，每次达到新的阈值需要扩容时，仍然可能触发 Full GC（具体行为与垃圾收集器和版本有关）。垃圾搜集器内部是根据变量<code>_capacity_until_GC</code>来判断 Metaspace 区域是否达到阈值的，初始化代码如下所示：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> MetaspaceGC::initialize() &#123;</span><br><span class="line">  <span class="comment">// Set the high-water mark to MaxMetapaceSize during VM initialization since</span></span><br><span class="line">  <span class="comment">// we can&#x27;t do a GC during initialization.</span></span><br><span class="line">  _capacity_until_GC = MaxMetaspaceSize;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><strong><code>-XX:MaxMetaspaceSize</code>的重要性</strong>：如果不显式设置<code>-XX:MaxMetaspaceSize</code>，元空间的最大大小理论上受限于可用的本地内存。在极端情况下（如类加载器泄漏导致不断加载类），这确实可能耗尽大量本地内存。因此，强烈建议设置一个合理的<code>-XX:MaxMetaspaceSize</code>上限，以防止对系统造成影响。</li></ul><h3 id="垃圾回收器相关参数"><a href="#垃圾回收器相关参数" class="headerlink" title="垃圾回收器相关参数"></a>垃圾回收器相关参数</h3><ul><li>Serial GC（串行垃圾收集器）：单线程执行GC，使用于客户端模式或单核cpu环境。参数<code>-XX:+UseParallelGC</code>。</li><li>Parallel GC（并行垃圾收集器）：多线程执行新生代GC（Minor GC），以及可选的多线程老年代GC（Full GC，通过<code>-XX:+UseParallelOldGC</code>)。关注吞吐量，是JDK 8的默认GC。参数<code>-XX:+UseParallelGC</code>。</li><li>CMS GC：以获取最短回收停顿时间为目标，大部分GC阶段可与用户线程并发执行。适用于对响应时间要求高的引应用。在JDK 9中被标记为弃用，JDK14中被移除。参数：<code>-XX:+UseConcMarkSweepGC</code>。</li><li>G1 GC：JDK 9及之后版本的默认GC。将堆划分为多个region，兼顾吞吐量和停顿时间，试图在可预测的停顿时间内完成GC。参数：<code>-XX:+UseG1GC</code>。</li></ul><h3 id="GC日志记录"><a href="#GC日志记录" class="headerlink" title="GC日志记录"></a>GC日志记录</h3><p>在生产环境或进行GC问题排查时，务必开启GC日志记录。以下是一些推荐配置的GC日志参数：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># --- 推荐的基础配置 ---</span></span><br><span class="line"><span class="comment"># 打印详细 GC 信息</span></span><br><span class="line"><span class="string">-XX:+PrintGCDetails</span></span><br><span class="line"><span class="comment"># 打印 GC 发生的时间戳 (相对于 JVM 启动时间)</span></span><br><span class="line"><span class="comment"># -XX:+PrintGCTimeStamps</span></span><br><span class="line"><span class="comment"># 打印 GC 发生的日期和时间 (更常用)</span></span><br><span class="line"><span class="string">-XX:+PrintGCDateStamps</span></span><br><span class="line"><span class="comment"># 指定 GC 日志文件的输出路径，%t 可以输出日期时间戳</span></span><br><span class="line"><span class="string">-Xloggc:/path/to/gc-%t.log</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 推荐的进阶配置 ---</span></span><br><span class="line"><span class="comment"># 打印对象年龄分布 (有助于判断对象晋升老年代的情况)</span></span><br><span class="line"><span class="string">-XX:+PrintTenuringDistribution</span></span><br><span class="line"><span class="comment"># 在 GC 前后打印堆信息</span></span><br><span class="line"><span class="string">-XX:+PrintHeapAtGC</span></span><br><span class="line"><span class="comment"># 打印各种类型引用 (强/软/弱/虚) 的处理信息</span></span><br><span class="line"><span class="string">-XX:+PrintReferenceGC</span></span><br><span class="line"><span class="comment"># 打印应用暂停时间 (Stop-The-World, STW)</span></span><br><span class="line"><span class="string">-XX:+PrintGCApplicationStoppedTime</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- GC 日志文件滚动配置 ---</span></span><br><span class="line"><span class="comment"># 启用 GC 日志文件滚动</span></span><br><span class="line"><span class="string">-XX:+UseGCLogFileRotation</span></span><br><span class="line"><span class="comment"># 设置滚动日志文件的数量 (例如，保留最近 14 个)</span></span><br><span class="line"><span class="string">-XX:NumberOfGCLogFiles=14</span></span><br><span class="line"><span class="comment"># 设置每个日志文件的最大大小 (例如，50MB)</span></span><br><span class="line"><span class="string">-XX:GCLogFileSize=50M</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 可选的辅助诊断配置 ---</span></span><br><span class="line"><span class="comment"># 打印安全点 (Safepoint) 统计信息 (有助于分析 STW 原因)</span></span><br><span class="line"><span class="comment"># -XX:+PrintSafepointStatistics</span></span><br><span class="line"><span class="comment"># -XX:PrintSafepointStatisticsCount=1</span></span><br></pre></td></tr></table></figure><h3 id="处理OOM"><a href="#处理OOM" class="headerlink" title="处理OOM"></a>处理OOM</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在发生 OOM 时生成堆转储文件</span></span><br><span class="line"><span class="string">-XX:+HeapDumpOnOutOfMemoryError</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定堆转储文件的输出路径。&lt;pid&gt; 会被替换为进程 ID</span></span><br><span class="line"><span class="string">-XX:HeapDumpPath=/path/to/heapdump/java_pid&lt;pid&gt;.hprof</span></span><br><span class="line"><span class="comment"># 示例：-XX:HeapDumpPath=/data/dumps/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (可选) 在发生 OOM 时执行指定的命令或脚本</span></span><br><span class="line"><span class="comment"># 例如，发送告警通知或尝试重启服务（需谨慎使用）</span></span><br><span class="line"><span class="string">-XX:OnOutOfMemoryError=&quot;&lt;command&gt;</span> <span class="string">&lt;args&gt;&quot;</span></span><br><span class="line"><span class="comment"># 示例：-XX:OnOutOfMemoryError=&quot;sh /path/to/notify.sh&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (可选) 启用 GC 开销限制检查</span></span><br><span class="line"><span class="comment"># 如果 GC 时间占总时间比例过高（默认 98%）且回收效果甚微（默认小于 2% 堆内存），</span></span><br><span class="line"><span class="comment"># 会提前抛出 OOM，防止应用长时间卡死在 GC 中。</span></span><br><span class="line"><span class="string">-XX:+UseGCOverheadLimit</span></span><br></pre></td></tr></table></figure><h3 id="其他常用参数"><a href="#其他常用参数" class="headerlink" title="其他常用参数"></a>其他常用参数</h3><ul><li><code>server</code>: 明确启用 Server 模式的 HotSpot VM。（在 64 位 JVM 上通常是默认值）。</li><li><code>XX:+UseStringDeduplication</code>: (JDK 8u20+) 尝试识别并共享底层 <code>char[]</code> 数组相同的 String 对象，以减少内存占用。适用于存在大量重复字符串的场景。</li><li><code>XX:SurvivorRatio=&lt;ratio&gt;</code>: 设置 Eden 区与单个 Survivor 区的大小比例。例如 <code>XX:SurvivorRatio=8</code> 表示 Eden:Survivor = 8:1。</li><li><code>XX:MaxTenuringThreshold=&lt;threshold&gt;</code>: 设置对象从新生代晋升到老年代的最大年龄阈值（对象每经历一次 Minor GC 且存活，年龄加 1）。默认值通常是 15。</li><li><code>XX:+DisableExplicitGC</code>: 禁止代码中显式调用 <code>System.gc()</code>。推荐开启，避免人为触发不必要的 Full GC。</li><li><code>XX:+UseLargePages</code>: (需要操作系统支持) 尝试使用大内存页（如 2MB 而非 4KB），可能提升内存密集型应用的性能，但需谨慎测试。</li><li><code>XX:MinHeapFreeRatio=&lt;percent&gt; / -XX:MaxHeapFreeRatio=&lt;percent&gt;</code>: 控制 GC 后堆内存保持空闲的最小/最大百分比，用于动态调整堆大小（如果 <code>Xms</code> 和 <code>Xmx</code> 不相等）。通常建议将 <code>Xms</code> 和 <code>Xmx</code> 设为一致，避免调整开销。</li></ul><h2 id="JVM调优"><a href="#JVM调优" class="headerlink" title="JVM调优"></a>JVM调优</h2><ol><li>堆内存配置：建议显示设置初始与最大堆内存（<code>-Xms</code>、<code>-Xmx</code>，通常设为一致）和新生代大小（<code>-Xmn</code>或<code>-XX:NewSize/-XX:MaxNewSize</code>）。</li><li>元空间管理（Java 8+）：强烈建议设置<code>-XX:MaxMetaspaceSize</code>以防止潜在的本地内存耗尽。</li><li>垃圾收集器选择与日志：不同GC算法有不同的适用场景，在生产和测试环境中开启详细的GC日志。</li><li>OOM故障排查：通过<code>-XX:+HeapDumpOnOutOfMemoryError</code>等参数在发生OOM时自动生成堆转储文件，以便进行后续的内存泄漏分析。</li></ol><h2 id="遇到了OOM如何排查？"><a href="#遇到了OOM如何排查？" class="headerlink" title="遇到了OOM如何排查？"></a>遇到了OOM如何排查？</h2><ol><li>确保线上配置了<code>-XX:+HeapDumpOnOutOfMemoryError</code>，OOM时自动生成Dump文件。</li><li>使用MAT（Memory Analyzer Tool）或VisualVM打开Dump文件。</li><li>看<strong>Dominator Tree（支配树）</strong>，找到<strong>占用内存最大的对象</strong>。<ol><li>如果是<strong>内存泄漏</strong>：看它的GC Roots引用链，定位是哪个静态变量或组件持有了它。</li><li>如果是<strong>内存溢出</strong>：分析这些对象是否是业务必须的。如果是，考虑扩容堆内存或优化业务逻辑（如分页查询）。</li></ol></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;JVM参数设置&quot;&gt;&lt;a href=&quot;#JVM参数设置&quot; class=&quot;headerlink&quot; title=&quot;JVM参数设置&quot;&gt;&lt;/a&gt;JVM参数设置&lt;/h2&gt;&lt;h3 id=&quot;设置堆内存大小（-Xms和-Xmx）&quot;&gt;&lt;a href=&quot;#设置堆内存大小（-Xms和-X</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="JVM" scheme="http://lixrangel.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>JVM垃圾回收</title>
    <link href="http://lixrangel.com/2025/12/08/java-ba-gu/jvm/jvm-la-ji-hui-shou/"/>
    <id>http://lixrangel.com/2025/12/08/java-ba-gu/jvm/jvm-la-ji-hui-shou/</id>
    <published>2025-12-07T16:00:00.000Z</published>
    <updated>2026-01-18T11:04:21.472Z</updated>
    
    <content type="html"><![CDATA[<h2 id="JVM怎么判断对象是否是垃圾对象？"><a href="#JVM怎么判断对象是否是垃圾对象？" class="headerlink" title="JVM怎么判断对象是否是垃圾对象？"></a>JVM怎么判断对象是否是垃圾对象？</h2><ul><li><strong>引用计数法</strong>：<ul><li>原理：为每个对象分配一个<font color="#ff0000">引用计数器</font>，每当有一个地方引用它时，计数器加1；当引用失效时，计数器减1。当<font color="#ff0000">计数器为0</font>时，表示对象不再被任何变量引用，可以被回收。</li><li>缺点：不能解决<font color="#ff0000">循环引用</font>的问题，即<font color="#ff0000">两个对象相互引用</font>，但<font color="#ff0000">不再被其他任何对象引用</font>，这时引用计数器不会为0，导致对象无法被回收。</li></ul></li><li><strong>可达性分析算法</strong>：<ul><li>原理：扫描堆中的对象，以<font color="#ff0000">GC Roots对象为起点向下搜索</font>，节点所走过的路径叫做引用链，当一个对象到GC Roots没有任何引用链相连的话，证明此对象是不可用的，则表示可以回收。</li></ul></li></ul><h3 id="追问：哪些对象是GC-Roots对象？——两栈两区"><a href="#追问：哪些对象是GC-Roots对象？——两栈两区" class="headerlink" title="追问：哪些对象是GC Roots对象？——两栈两区"></a>追问：哪些对象是GC Roots对象？——两栈两区</h3><ul><li>虚拟机栈（栈帧中的局部变量表）中引用的对象</li><li>本地方法栈（Native方法）中引用的对象</li><li>方法区中类静态属性引用的对象</li><li>方法区中常量引用的对象</li><li>JNI（Java Native Interface）引用的对象</li></ul><h2 id="垃圾回收算法有哪些？"><a href="#垃圾回收算法有哪些？" class="headerlink" title="垃圾回收算法有哪些？"></a>垃圾回收算法有哪些？</h2><ul><li><strong>标记-清除算法</strong>：分为“标记”和“清除”两个阶段，首先通过可达性分析，标记出所有不需要回收的对象，在标记完成后统一回收所有没有被标记的对象。<ul><li>缺点：<ul><li>标记和清除的过程<font color="#ff0000">效率都不高</font>；</li><li>清除结束后会<font color="#ff0000">造成大量的碎片空间</font>。有可能会导致在申请大块内存的时候因为没有足够的连续空间导致再次出现GC。<br><img src="%E6%A0%87%E8%AE%B0%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95.png" alt="标记清除算法"></li></ul></li></ul></li><li><strong>复制算法</strong>：复制算法是为了解决碎片空间的问题。原理是<font color="#ff0000">将内存分为两块</font>，每次申请时都是用其中的一块，当内存不够时，将<font color="#ff0000">这一块的内存中所有存活的复制到另一块上</font>。（每当遇到一个存活对象，就复制到另一块内存中）然后再把已使用的内存整个清理掉。复制算法解决了空间碎片的问题，<font color="#ff0000">适合对象存活率较小</font>的情况（新生代）。<ul><li>缺点：<ul><li>可用内存变小，每次在申请内存时，都<font color="#ff0000">只能使用一半的内存空间</font>。内存利用率不足；</li><li>不适合老年代，如果存活对象的数量比较大，<font color="#ff0000">复制性能会变得很差</font>。<br><img src="%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95.png" alt="复制算法"></li></ul></li></ul></li><li><strong>标记-整理算法</strong>：标记-整理算法的“标记”过程与标记-清除算法一致，但标记之后不会直接清理，而是<font color="#ff0000">将所有存活对象都移到内存的一端</font>。移动结束后直接清理掉端边界以外的内存。<font color="#ff0000">适合老年代</font>这种垃圾回收频率不是很高的场景。<br><img src="%E6%A0%87%E8%AE%B0%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95.png" alt="标记整理算法"></li></ul><h2 id="垃圾回收器有哪些？"><a href="#垃圾回收器有哪些？" class="headerlink" title="垃圾回收器有哪些？"></a>垃圾回收器有哪些？</h2><table><thead><tr><th align="center">垃圾收集器</th><th align="center">类型</th><th align="center">作用域</th><th align="center">使用算法</th><th align="center">特点</th><th align="center">适用场景</th></tr></thead><tbody><tr><td align="center">Serial</td><td align="center">串行回收</td><td align="center">新生代</td><td align="center">复制算法</td><td align="center">响应速度优先</td><td align="center">适用于单核cpu环境下的Client模式</td></tr><tr><td align="center">Serial Old</td><td align="center">串行回收</td><td align="center">老年代</td><td align="center">标记-整理算法</td><td align="center">响应速度优先</td><td align="center">适用于单核cpu环境下的Client模式</td></tr><tr><td align="center">ParNew</td><td align="center">并行回收</td><td align="center">新生代</td><td align="center">复制算法</td><td align="center">响应速度优先</td><td align="center">多核cpu环境下Server模式下与CMS配合使用</td></tr><tr><td align="center">Parallel Scavenge</td><td align="center">并行回收</td><td align="center">新生代</td><td align="center">复制算法</td><td align="center">吞吐量优先</td><td align="center">适用于后台运算，而交互少的场景</td></tr><tr><td align="center">Parallel Old</td><td align="center">并行回收</td><td align="center">老年代</td><td align="center">标记-整理算法</td><td align="center">吞吐量优先</td><td align="center">适用于后台运算，而交互少的场景</td></tr><tr><td align="center">CMS（Concurrent Mark Sweep）</td><td align="center">并发回收</td><td align="center">老年代</td><td align="center">标记-清除算法</td><td align="center">响应速度优先</td><td align="center">适用于B/S业务，也就是交互多的场景。</td></tr><tr><td align="center">G1（Garbage-First）</td><td align="center">并发，并行回收</td><td align="center">新生代&amp;老年代（整堆收集器）</td><td align="center">整体上：标记-整理算法；局部：复制算法</td><td align="center">响应速度优先</td><td align="center">面向服务端的应用</td></tr></tbody></table><ul><li><strong>Seria收集器（复制算法）</strong>：新生代单线程回收器，其他线程会阻塞，优点是简单高效；</li><li><strong>Serial Old收集器（标记-整理算法）</strong>：老年代单线程回收器，<font color="#ff0000">Serial回收器老年代版本</font>。<br><img src="Serial&Serial_Old%E5%9B%9E%E6%94%B6%E5%99%A8.png" alt="Serial&amp;Serial Old回收器"></li><li><strong>ParNew回收器（复制算法）</strong>：新生代并行回收器，实际上是<font color="#ff0000">Serial回收器的多线程版本</font>，目标是缩短垃圾收集时的单次停顿时间，在多核cpu环境下有比Serial更好的表现。<br><img src="ParNew%E5%9B%9E%E6%94%B6%E5%99%A8.png" alt="ParNew回收器"></li><li><strong>Parallel Scavenge收集器（复制算法）</strong>：新生代并行回收器，追求高吞吐量，高效利用cpu。适合后台应用对交互响应要求不高的场景。</li><li><strong>Parallel Old收集器（标记-整理算法）</strong>：老年代并行回收器，吞吐量优先，Parallel Scavenge回收器的老年代版本。<br><img src="Parallel_Scavenge&Parallel_Old%E5%9B%9E%E6%94%B6%E5%99%A8.png" alt="Parallel Scavenge&amp;Parallel Old回收器"></li><li><strong>CMS收集器（标记-清除算法）</strong>：老年代并行回收器，以<font color="#ff0000">获取最短回收停顿时间</font>为目标。具有高并发、低停顿的特点，追求最短GC回收停顿时间。<ul><li><font color="#0070c0">初始标记</font>：短暂停顿，标记直接与root相连的对象；</li><li><font color="#0070c0">并发标记</font>：同时开启GC和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象，因为用户线程可能会不断的更新引用域，所以GC线程无法保证可达性分析的实时性。</li><li><font color="#0070c0">重新标记</font>：重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间长，远远比并发标记阶段的时间短。</li><li><font color="#0070c0">并发清除</font>：开启用户线程，同时GC线程开始对未标记的区域做清扫。<br><img src="CMS%E6%94%B6%E9%9B%86%E5%99%A8.png" alt="CMS收集器"></li></ul></li><li><strong>G1收集器（标记-整理算法）</strong>：Java堆并行回收器，不会产生内存碎片。G1回收的范围是<font color="#ff0000">整个Java堆</font>（包括新生代、老年代）。<ul><li><font color="#0070c0">初始标记</font>：短暂停顿，标记从GC Roots可直接引用的对象，即标记所有直接可达的活跃对象。</li><li><font color="#0070c0">并发标记</font>：与应用并发运行，标记所有可达对象。</li><li><font color="#0070c0">最终标记</font>：短暂停顿，处理并发标记阶段结束后残留的少量未处理的引用变更。</li><li><font color="#0070c0">筛选回收</font>：根据标记结果，选择回收价值高的区域，复制存活对象到新区域，回收旧区域内存。这个阶段包含一个或多个停顿，取决于回收的复杂度。<br><img src="G1%E5%9B%9E%E6%94%B6%E5%99%A8.png" alt="G1回收器"></li></ul></li></ul><h2 id="垃圾回收器CMS和G1的区别？"><a href="#垃圾回收器CMS和G1的区别？" class="headerlink" title="垃圾回收器CMS和G1的区别？"></a>垃圾回收器CMS和G1的区别？</h2><ul><li><strong>使用的范围不一样</strong>：<ul><li>CMS收集器是<font color="#ff0000">老年代的收集器</font>，可以配合新生代的Serial和ParNew收集器一起使用。</li><li>G1收集器收集范围是<font color="#ff0000">老年代和新生代</font>，不需要结合其他收集器使用。</li></ul></li><li><strong>STW的时间</strong>：<ul><li>CMS收集器是以<font color="#ff0000">最小的停顿时间为目标</font>的收集器。</li><li>G1收集器可以<font color="#ff0000">预测垃圾回收的停顿时间</font>。</li></ul></li><li><strong>垃圾碎片</strong>：<ul><li>CMS收集器使用<font color="#ff0000">“标记-清除”算法</font>进行垃圾回收，容易产生内存碎片。</li><li>G1收集器使用的是<font color="#ff0000">“标记-整理”算法</font>，进行了空间整合，没有内存空间碎片。</li></ul></li><li><strong>垃圾回收的过程不一样</strong></li></ul><h2 id="什么情况下使用CMS，什么情况使用G1？"><a href="#什么情况下使用CMS，什么情况使用G1？" class="headerlink" title="什么情况下使用CMS，什么情况使用G1？"></a>什么情况下使用CMS，什么情况使用G1？</h2><ul><li>CMS适用场景：<ul><li><strong>低延迟需求</strong>：适用于对停顿时间要求敏感的应用程序。</li><li><strong>老年代收集</strong>：主要针对老年代的垃圾回收。</li><li><strong>碎片化管理</strong>：容易出现内存碎片，可能需要定期Full GC来压缩内存空间。</li></ul></li><li>G1适用场景：<ul><li><strong>大堆内存</strong>：适用于需要管理大内存堆的场景，能够有效处理数GB以上的堆内存。</li><li><strong>对内存碎片敏感</strong>：G1通过紧凑整理来减少内存碎片，降低了碎片化对性能的影响。</li><li><strong>比较平衡的性能</strong>：G1在提供较低停顿时间的同时，也保持了相对较高的吞吐量。</li></ul></li></ul><h2 id="G1回收器的特色是什么？"><a href="#G1回收器的特色是什么？" class="headerlink" title="G1回收器的特色是什么？"></a>G1回收器的特色是什么？</h2><ul><li>G1的特点：<ul><li>引入分区的思路，<strong>弱化了分代的概念</strong>；</li></ul></li><li>G1相比较CMS的改进：<ul><li><strong>算法</strong>：G1基于标记-整理算法，<font color="#ff0000">不会产生空间碎片</font>，在分配大对象时，不会因为无法得到连续的空间而<font color="#ff0000">提前触发一次Full GC</font>；</li><li><strong>停顿时间可控</strong>：G1可以通过设置<font color="#ff0000">预期停顿时间</font>来控制垃圾收集时间避免应用雪崩现象。</li><li><strong>并行与并发</strong>：G1能更充分的利用cpu多核环境下的硬件优势，来<font color="#ff0000">缩短STW的停顿时间</font>。</li></ul></li></ul><h2 id="minorGC、majorGC、fullGC的区别？"><a href="#minorGC、majorGC、fullGC的区别？" class="headerlink" title="minorGC、majorGC、fullGC的区别？"></a>minorGC、majorGC、fullGC的区别？</h2><ul><li><strong>minorGC（YoungGC）</strong><ul><li><strong>作用范围</strong>：<font color="#ff0000">只针对新生代进行回收</font>，包括Eden区和Survivor区；</li><li><strong>触发条件</strong>：当<font color="#ff0000">Eden区空间不足</font>时，JVM会触发一次minorGC，将Eden区和一个Survivor区中的存活对象移动到另一个Survivor区或老年代。</li><li><strong>特点</strong>：通常发生的非常频繁，因为新生代中对象生命周期短，回收效率高，暂停时间相对较短。</li></ul></li><li><strong>majorGC</strong><ul><li><strong>作用范围</strong>：主要针对<font color="#ff0000">老年代进行回收</font>，但不一定只回收老年代；</li><li><strong>触发条件</strong>：当<font color="#ff0000">老年代空间不足</font>时，或者系统检测到<font color="#ff0000">新生代对象晋升到老年代的速度过快</font>，可能会触发majorGC。</li><li><strong>特点</strong>：相比minorGC，majorGC发生的频率较低，但每次回收可能需要更长的时间，因为老年代中的对象存活率较高，需要花费更多开销去整理。</li></ul></li><li><strong>FullGC</strong><ul><li><strong>作用范围</strong>：对<font color="#ff0000">整个堆内存进行回收</font>。</li><li><strong>触发条件</strong>：<ul><li>直接调用<code>system.gc()</code>或<code>Runtime.getRuntime.gc()</code>方法时，虽然不能保证立即执行，但JVM会尝试执行FullGC。</li><li>minorGC时，如果<font color="#ff0000">存活的对象无法全部放入老年代</font>，或者老年代空间不足以容纳存活的对象，则会触发FullGC，对整个堆内存进行回收。</li><li>当<font color="#ff0000">永久代或者元空间空间不足</font>时。</li></ul></li><li><strong>特点</strong>：FullGC是最昂贵的操作，因为它需要停止所有的工作线程，遍历整个堆内存来查找和回收不再使用的对象，因此应尽量减少FullGC的触发。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;JVM怎么判断对象是否是垃圾对象？&quot;&gt;&lt;a href=&quot;#JVM怎么判断对象是否是垃圾对象？&quot; class=&quot;headerlink&quot; title=&quot;JVM怎么判断对象是否是垃圾对象？&quot;&gt;&lt;/a&gt;JVM怎么判断对象是否是垃圾对象？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;str</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="JVM" scheme="http://lixrangel.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>Java内存区域&amp;类加载</title>
    <link href="http://lixrangel.com/2025/12/07/java-ba-gu/jvm/java-nei-cun-qu-yu-lei-jia-zai/"/>
    <id>http://lixrangel.com/2025/12/07/java-ba-gu/jvm/java-nei-cun-qu-yu-lei-jia-zai/</id>
    <published>2025-12-06T16:00:00.000Z</published>
    <updated>2026-01-18T10:56:27.161Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Java内存区域-运行时数据区域"><a href="#Java内存区域-运行时数据区域" class="headerlink" title="Java内存区域/运行时数据区域"></a>Java内存区域/运行时数据区域</h2><h3 id="JDK1-7"><a href="#JDK1-7" class="headerlink" title="JDK1.7"></a>JDK1.7</h3><p><img src="JDK1.7%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F.png" alt="JDK1.7内存区域"></p><h3 id="JDK1-8"><a href="#JDK1-8" class="headerlink" title="JDK1.8"></a>JDK1.8</h3><p><img src="JDK1.8%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F.png" alt="JDK1.8内存区域"></p><ul><li><strong>线程私有区域</strong>：随线程创建而创建，随线程销毁而销毁，不需要垃圾回收。<ul><li><strong>程序计数器</strong>：用于存储当前<font color="#ff0000">线程正在执行的Java方法的JVM指令地址</font>。程序计数器是<font color="#ff0000">唯一一个不会出现OutOfMemoryError的内存区域</font>，生命周期与线程相同。</li><li><strong>Java虚拟机栈</strong>：每个线程有自己独立的Java虚拟机栈，生命周期与线程相同。<font color="#ff0000">每个方法在执行时都会创建一个栈帧</font>，用于存储局部变量表、操作数栈、动态链接、方法返回地址等。可能会抛出<code>StackOverflowError</code>和<code>OutOfMemoryError</code>异常。<ul><li><code>StackOverflowError</code>：如果<font color="#ff0000">栈的内存大小不允许动态扩展</font>，那么当线程请求栈的深度超过当前Java虚拟机栈的最大深度的时候，就抛出StackOverflowError错误。</li><li><code>OutOfMemoryError</code>：如果<font color="#ff0000">栈的内存大小可以动态扩展</font>，那么当虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。</li></ul></li><li><strong>本地方法栈</strong>：与Java虚拟机栈类似，主要为<font color="#ff0000">虚拟机使用到的native方法</font>服务。本地方法执行时也会创建栈帧，同样可能出现<code>StackOverflowError</code>和<code>OutOfMemoryError</code>异常。</li></ul></li><li><strong>线程共享区域</strong>：是所有线程共用的，是垃圾回收的主要战场。<ul><li><strong>Java堆</strong>：JVM中最大的一块内存区域，几乎<font color="#ff0000">所有的对象实例和数组都在这里分配</font>。从垃圾回收角度，堆被划分为<font color="#ff0000">新生代和老年代</font>，新生代又分为Eden区和两个Survive区，如果在堆中没有内存完成实例分配，并且堆也无法扩展时会抛出<code>OutOfMemoryError</code>异常。</li><li><strong>方法区（元空间）</strong>：用于存储已经<font color="#ff0000">被虚拟机加载的类信息、常量、静态变量</font>等数据。虽然方法区被描述为堆的逻辑部分，但有”非堆“的别名。<ul><li>JDK1.8之前，HotSpot虚拟机用<font color="#ff0000">“永久代”来实现方法区</font>。</li><li>JDK1.8及以后，永久代被移除，取而代之的是“<font color="#ff0000">元空间</font>”，它直接使用本地内存，不再受JVM堆大小的限制，只受本机物理内存限制。</li></ul></li></ul></li></ul><h2 id="创建对象的过程？"><a href="#创建对象的过程？" class="headerlink" title="创建对象的过程？"></a>创建对象的过程？</h2><p><img src="Java%E5%AF%B9%E8%B1%A1%E5%88%9B%E5%BB%BA%E8%BF%87%E7%A8%8B.png" alt="Java对象创建过程"></p><ol><li><strong>类加载检查</strong>：虚拟机遇到一条new指令时，首先去检查这个指令的参数（即类名）是否能够<font color="#ff0000">在常量池中定位到一个类的符号引用</font>，并且检查这个类是否已被加载、解析和初始化过。如果没有，就必须先执行相应的类加载过程。</li><li><strong>分配内存</strong>：在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定。<ol><li><font color="#0070c0">分配方式</font>：<ol><li><font color="#00b050">指针碰撞</font>：适用于<font color="#ff0000">堆内存没有内存碎片</font>的情况下。用过的内存全部整合到一边，没有用过的内存放在另一边，中间<font color="#ff0000">有一个分界指针</font>，只需要向着没用过的内存方向将该指针移动对象内存大小即可。</li><li><font color="#00b050">空闲列表</font>：适用于<font color="#ff0000">堆内存有内存碎片</font>的情况下。虚拟机会<font color="#ff0000">维护一个列表</font>，记录哪些内存块是可用的，在分配的时候，找一块足够大的内存块来划分给对象实例，最后更新列表记录。</li></ol></li><li><font color="#0070c0">内存分配并发问题</font>：<ol><li><font color="#ff0000">优先使用TLAB（本地线程分配缓冲）进行分配</font>，TLAB是在Eden区为每个线程预先分配的一小块私有内存；</li><li>如果TLAB用完了，才会在堆上使用<font color="#ff0000">CAS+失败重试</font>的机制进行原子分配。</li></ol></li></ol></li><li><strong>初始化零值</strong>：内存分配完成之后，虚拟机需要将分配到的内存空间都<font color="#ff0000">初始化为零值（不包括对象头）</font>。这一步保证了对象的实例字段在Java代码中可以不赋初值就直接使用。</li><li><strong>设置对象头</strong>：包括<font color="#ff0000">mark word</font>（存储哈希码、GC分代年龄、锁状态标志等）、<font color="#ff0000">Class Pointer</font>（类型指针，指向该对象的类元数据，确定它是哪个类的实例）。</li><li><strong>执行init方法</strong>：从JVM视角看对象已经创建好了，但从Java程序视角看，对象才刚刚开始。虚拟机<font color="#ff0000">执行init方法</font>，即按照程序员的意愿进行初始化（执行构造函数、成员变量赋值和构造代码块）。</li></ol><h2 id="类加载过程"><a href="#类加载过程" class="headerlink" title="类加载过程"></a>类加载过程</h2><p><img src="%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B.png" alt="类加载过程"></p><ul><li><strong>加载</strong>：通过<font color="#ff0000">类的全限定名</font>（包名+类名）获取<font color="#ff0000">二进制字节流</font>，然后将这个字节流所代表的静态存储结构转化为<font color="#ff0000">方法区的运行时数据结构</font>，并在堆中<font color="#ff0000">生成一个代表该类的java.lang.Class对象</font>，作为访问入口。</li><li><strong>验证</strong>：<font color="#ff0000">检查文件格式</font>、<font color="#ff0000">元数据验证</font>、<font color="#ff0000">字节码验证</font>、<font color="#ff0000">符号引用验证</font>。确保Class文件的字节流包含的信息符合当前虚拟机的要求，不会危害虚拟机自身的安全。</li><li><strong>准备</strong>：在方法区中为类的<font color="#ff0000">类变量（Static变量）分配内存</font>，并将其<font color="#ff0000">初始化为默认零值</font>。这时候只分配static变量，不包括实例变量。这里初始化的值只是零值，但是如果被final static修饰，那么在准备阶段就会直接赋值。</li><li><strong>解析</strong>：虚拟机将常量池中的<font color="#ff0000">符号引用</font>替换为<font color="#ff0000">直接引用</font>。</li><li><strong>初始化</strong>：<font color="#ff0000">执行类构造器clinit方法</font>。就是把刚刚准备阶段赋的零值，替换为在代码中<font color="#ff0000">显式赋值</font>的数据，并执行<font color="#ff0000">静态代码块</font>。</li></ul><h2 id="类加载器有哪些？"><a href="#类加载器有哪些？" class="headerlink" title="类加载器有哪些？"></a>类加载器有哪些？</h2><p><img src="%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8.png" alt="类加载器"></p><ul><li><strong>启动类加载器（Bootstrap Class Loader）</strong>：最顶层的加载器，是JVM自身的一部分。是由C++实现的，负责<font color="#ff0000">加载JAVA_HOME/lib目录下的核心类库</font>（比如rt.jar，里面包含java.lang.* 、java.util.* 等最基础的类）。</li><li><strong>扩展类加载器（Extension Class Loader）</strong>：Java语言实现的，继承自ClassLoader类。负责加载<font color="#ff0000">JAVA_HOME/lib/ext目录下的扩展类库</font>。扩展类加载器由启动类加载器加载。</li><li><strong>应用程序类加载器（Application Class Loader）</strong>：Java语言实现的，负责加载<font color="#ff0000">用户类路径（ClassPath）上的指定类库</font>，是我们自己编写的Java类的加载器。</li><li><strong>自定义类加载器</strong>：开发者可以根据需求定制类的加载方式。</li></ul><h2 id="双亲委派"><a href="#双亲委派" class="headerlink" title="双亲委派"></a>双亲委派</h2><ul><li>类加载的核心原则：一个类加载器要加载类时，<strong>先让父加载器去尝试加载</strong>，只有父加载器加载不了，自己才会去加载。</li><li>核心作用：<ul><li><strong>保证类的唯一性和安全性</strong>：避免同一个类被不同加载器重复加载，确保核心类（如JDK的String、Integer）不会被篡改。</li><li><strong>实现类的复用</strong>：核心类只会被顶层加载器加载一次，所有子加载器都能共享这个类，减少内存消耗。</li></ul></li></ul><h2 id="双亲委派模型的作用"><a href="#双亲委派模型的作用" class="headerlink" title="双亲委派模型的作用"></a>双亲委派模型的作用</h2><ul><li><strong>保证类的唯一性</strong>：确保所有加载请求都会传递到启动类加载器，<font color="#ff0000">避免了不同类加载器重复加载相同类</font>的情况。保证了Java核心类库的统一性，也<font color="#ff0000">防止了用户自定义类覆盖核心类库</font>的可能。</li><li><strong>保证安全性</strong>：由于Java核心类库被启动类加载器加载，而<font color="#ff0000">启动类加载器只加载信任的类路径中的类</font>，这样可以防止不可信的类假冒核心类，增加了系统的安全性。</li><li><strong>支持隔离和层次划分</strong>：双亲委派模型支持<font color="#ff0000">不同层次的类加载器服务于不同的类加载需求</font>，如应用程序类加载器加载用户代码，扩展类加载器加载扩展框架，启动类加载器加载核心库。这种层次的划分保证了各个层级类加载器的职责清晰，也便于维护和扩展。</li><li><strong>简化了加载流程</strong>：大部分类能够被正确的类加载器加载，减少了每个加载器需要处理的类的数量，<font color="#ff0000">简化了类的加载过程</font>，提高了加载效率。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Java内存区域-运行时数据区域&quot;&gt;&lt;a href=&quot;#Java内存区域-运行时数据区域&quot; class=&quot;headerlink&quot; title=&quot;Java内存区域/运行时数据区域&quot;&gt;&lt;/a&gt;Java内存区域/运行时数据区域&lt;/h2&gt;&lt;h3 id=&quot;JDK1-7&quot;&gt;&lt;</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="JVM" scheme="http://lixrangel.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>ThreadLocal &amp; 线程池</title>
    <link href="http://lixrangel.com/2025/12/04/java-ba-gu/duo-xian-cheng-bing-fa/threadlocal-xian-cheng-chi/"/>
    <id>http://lixrangel.com/2025/12/04/java-ba-gu/duo-xian-cheng-bing-fa/threadlocal-xian-cheng-chi/</id>
    <published>2025-12-03T16:00:00.000Z</published>
    <updated>2026-01-18T10:44:08.894Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ThreadLocal原理了解吗？"><a href="#ThreadLocal原理了解吗？" class="headerlink" title="ThreadLocal原理了解吗？"></a>ThreadLocal原理了解吗？</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Thread</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span> &#123;</span><br><span class="line">    <span class="comment">//......</span></span><br><span class="line">    <span class="comment">//与此线程有关的ThreadLocal值。由ThreadLocal类维护</span></span><br><span class="line">    ThreadLocal.<span class="type">ThreadLocalMap</span> <span class="variable">threadLocals</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护</span></span><br><span class="line">    ThreadLocal.<span class="type">ThreadLocalMap</span> <span class="variable">inheritableThreadLocals</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="comment">//......</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ThreadLocal</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">set</span><span class="params">(T value)</span> &#123;</span><br><span class="line">    <span class="comment">//获取当前请求的线程</span></span><br><span class="line">    <span class="type">Thread</span> <span class="variable">t</span> <span class="operator">=</span> Thread.currentThread();</span><br><span class="line">    <span class="comment">//取出 Thread 类内部的 threadLocals 变量(哈希表结构)</span></span><br><span class="line">    <span class="type">ThreadLocalMap</span> <span class="variable">map</span> <span class="operator">=</span> getMap(t);</span><br><span class="line">    <span class="keyword">if</span> (map != <span class="literal">null</span>)</span><br><span class="line">        <span class="comment">// 将需要存储的值放入到这个哈希表中</span></span><br><span class="line">        map.set(<span class="built_in">this</span>, value);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        createMap(t, value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ThreadLocalMap <span class="title function_">getMap</span><span class="params">(Thread t)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> t.threadLocals;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>每个Thread对象内部有一个私有成员变量<code>threadlocals</code>，是一个<code>ThreadLocalMap</code>（是ThreadLocal的静态内部类）对象。默认情况下这个变量为null，当调用<code>set()</code>方法时才会创建。</li><li>当调用<code>threadlocal.set(value)</code>时，ThreadLocal会<font color="#ff0000">先获取当前线程</font>，然后从该线程中<font color="#ff0000">获取它的ThreadLocalMap</font>。接着<font color="#ff0000">ThreadLocal以它自己为key</font>，<font color="#ff0000">将value存入当前线程的ThreadLocalMap中</font>。调用<code>threadlocal.get()</code>时，会获取当前线程的ThreadLocalMap，然后以ThreadLocal为key，查找对应的value并返回。<br><img src="ThreadLocal%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="ThreadLocal数据结构"></li></ul><h2 id="ThreadLocal内存泄漏是什么原因导致的？"><a href="#ThreadLocal内存泄漏是什么原因导致的？" class="headerlink" title="ThreadLocal内存泄漏是什么原因导致的？"></a>ThreadLocal内存泄漏是什么原因导致的？</h2><ul><li>根本原因：ThreadLocalMap中Entry的设计结构——它的<strong>key（ThreadLocal对象）是弱引用</strong>，而<strong>value是强引用</strong>。</li><li>具体过程：<ul><li>当一个<font color="#ff0000">ThreadLocal对象在外部的强引用消失</font>后，GC会根据<font color="#ff0000">Entry中的弱引用来回收它</font>。ThreadLocal对象被回收后，Entry中的key就变成了null。</li><li>但是，这个Entry对象本身以及它所强引用的value仍然被ThreadLocalMap强引用着。</li><li>如果这个线程是一个<font color="#ff0000">线程池中的复用线程</font>，它不会被销毁，它的ThreadLocalMap也就一直存在着。</li><li>这就导致了ThreadLocalMap中存在大量key=null的Entry，它们强引用着本应被回收的value对象，造成了内存泄漏。</li></ul></li><li>内存泄漏需要同时满足两个条件：<ul><li><font color="#ff0000">ThreadLocal实例不再被强引用</font>；</li><li>线程池复用线程，导致<font color="#ff0000">线程持续存活</font>，导致ThreadLocalMap长期存在。</li></ul></li><li>解决办法：在使用完ThreadLocal后，务必调用<code>remove()</code>方法。</li></ul><h2 id="如何创建线程池？"><a href="#如何创建线程池？" class="headerlink" title="如何创建线程池？"></a>如何创建线程池？</h2><ul><li>通过<code>ThreadPoolExecutor</code>构造函数直接创建<br><img src="ThreadPoolExecutor%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E6%B1%A0.png" alt="ThreadPoolExecutor创建线程池"></li><li>通过<code>Executors</code>工具类创建<br><img src="Executors%E5%B7%A5%E5%85%B7%E7%B1%BB%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E6%B1%A0.png" alt="Executors工具类创建线程池.png"></li></ul><h2 id="线程池的种类"><a href="#线程池的种类" class="headerlink" title="线程池的种类"></a>线程池的种类</h2><ul><li><code>FixedThreadPool</code>：固定线程数量的线程池，<strong>核心线程数和最大线程数是一样的</strong>。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则<strong>新的任务会被暂存在一个任务队列</strong>（阻塞队列LinkedBlockingQueue）中，待有线程空闲时，便处理在任务队列中的任务。</li><li><code>SingleThreadExecutor</code>：<strong>只有一个线程的线程池</strong>。若多于一个任务被提交到线程池，任务会被保存在一个任务队列（阻塞队列LinkedBlockingQueue）中，待线程空闲，按先入先出的顺序执行队列中的任务。</li><li><code>CachedThreadPool</code>：<strong>可根据实际情况调整线程数量的线程池</strong>，允许创建的线程数量为Integer.MAX_VALUE。队列是SynchronousQueue，队列的容量为0，实际不存储任何任务，生产者将任务放入队列后会一直阻塞，直到有消费者线程来取走他。</li><li><code>ScheduledThreadPool</code>和<code>SingleThreadScheduledExecutor</code>：可以设置定期的执行任务，<strong>支持定期或周期性执行任务</strong>。使用的无界的延迟阻塞队列DelayedWorkQueue。</li></ul><h3 id="这些线程池的弊端"><a href="#这些线程池的弊端" class="headerlink" title="这些线程池的弊端"></a>这些线程池的弊端</h3><ol><li>允许创建的“队列”无界（堆内存溢出）：<code>FixedThreadPool</code>和<code>SingleThreadExecutor</code><ul><li>队列是用的LinkedBlockingQueue，并且没有指定队列容量。此时<strong>队列的默认容量是Integer.MAX_VALUE</strong>。如果任务提交的速度&gt;任务处理的速度，任务就会在队列中无限堆积。</li><li>后果：<strong>大量的任务对象占用堆内存，导致Java Heap Space OOM</strong>。</li></ul></li><li>允许创建的“线程数”无界（系统资源耗尽）：<code>CachedThreadPool</code>和<code>ScheduledThreadPool</code><ul><li>将最大线程数设置为了Integer.MAX_VALUE。CachedThreadPool使用的SynchronousQueue。意味着只要有新任务来了，且没有空闲线程，它就会创建一个新线程去处理。如果任务提交速度非常快，线程池会疯狂创建成千上万个线程。</li><li>后果：<ul><li><strong>CPU爆满</strong>：大量<font color="#ff0000">线程上下文切换</font>拖垮cpu；</li><li><strong>OOM</strong>：每个线程都需要<font color="#ff0000">分配栈内存</font>，创建过多线程会导致unable to create new native thread OOM。</li></ul></li></ul></li></ol><h2 id="线程池的常见参数有哪些？"><a href="#线程池的常见参数有哪些？" class="headerlink" title="线程池的常见参数有哪些？"></a>线程池的常见参数有哪些？</h2><ul><li><code>corePoolSize</code>：任务队列未达到队列容量时，最大可以同时运行的线程数量。</li><li><code>maximumPoolSize</code>：任务队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。</li><li><code>keepAliveTime</code>：当线程池中的线程数量大于corePoolSize，即有非核心线程时，这些非核心线程空闲后不会立即销毁，而是会等待，直到<font color="#ff0000">等待的时间超过了keepAliveTime才会回收销毁</font>。</li><li><code>until</code>：keepAliveTime参数的时间单位。</li><li><code>workQueue</code>：新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。</li><li><code>threadFactory</code>：线程工厂。executor创建新线程的时候会用到。</li><li><code>handler</code>：如果当时同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时，会执行拒绝策略。<br><img src="%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%8F%82%E6%95%B0.png" alt="线程池参数"></li></ul><h2 id="线程池的拒绝策略有哪些？"><a href="#线程池的拒绝策略有哪些？" class="headerlink" title="线程池的拒绝策略有哪些？"></a>线程池的拒绝策略有哪些？</h2><ul><li><code>AbortPolicy</code>：抛出<code>RejectedExecutionException</code>来拒绝新任务的处理。任务会丢失。</li><li><code>CallerRunsPolicy</code>：直接<font color="#ff0000">在调用execute方法的线程中运行被拒绝的任务</font>，如果执行程序已经关闭，则会丢弃该任务。</li><li><code>DiscardPolicy</code>：不处理新任务，<font color="#ff0000">直接丢弃</font>。</li><li><code>DiscardOldestPolicy</code>：<font color="#ff0000">丢弃最早的未处理</font>的任务请求。</li></ul><h2 id="如何设定线程池的大小？"><a href="#如何设定线程池的大小？" class="headerlink" title="如何设定线程池的大小？"></a>如何设定线程池的大小？</h2><ul><li><strong>cpu密集型任务（N + 1）</strong>：这种任务消耗的主要是CPU资源，可以将线程数设置为N（CPU核心数）+1。比CPU核心数多出来一个线程就是<font color="#ff0000">为了防止线程偶发的缺页中断</font>，或者其他原因导致的<font color="#ff0000">任务暂停而带来的影响</font>。一旦任务暂停，CPU就会处于空闲状态，而在这种情况下多出来一个线程就可以充分利用CPU的空闲时间。</li><li><strong>I/O密集型任务（2N）</strong>：这种任务系统会用<font color="#ff0000">大部分的时间来处理I/O交互</font>，而线程在处理I/O的时间段内不会占用CPU来处理，这时就可以将CPU交出给其他线程使用。因此在I/O密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是2N。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ThreadLocal原理了解吗？&quot;&gt;&lt;a href=&quot;#ThreadLocal原理了解吗？&quot; class=&quot;headerlink&quot; title=&quot;ThreadLocal原理了解吗？&quot;&gt;&lt;/a&gt;ThreadLocal原理了解吗？&lt;/h2&gt;&lt;figure class</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="多线程" scheme="http://lixrangel.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>线程安全</title>
    <link href="http://lixrangel.com/2025/12/03/java-ba-gu/duo-xian-cheng-bing-fa/xian-cheng-an-quan/"/>
    <id>http://lixrangel.com/2025/12/03/java-ba-gu/duo-xian-cheng-bing-fa/xian-cheng-an-quan/</id>
    <published>2025-12-02T16:00:00.000Z</published>
    <updated>2026-01-18T10:36:32.722Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Java如何保证多线程安全？"><a href="#Java如何保证多线程安全？" class="headerlink" title="Java如何保证多线程安全？"></a>Java如何保证多线程安全？</h2><ul><li><strong>synchronized关键字</strong>：可以使用synchronized关键字来<font color="#ff0000">同步代码块或方法</font>，确保同一时刻只有一个线程可以访问这些代码。对象锁是通过synchronized关键字<font color="#ff0000">锁定对象的监视器</font>来实现的。</li><li><strong>Lock接口和ReentrantLock类</strong>：<code>java.util.concurrent.locks.Lock</code>接口提供了比synchronized更强大的锁机制，ReentrantLock是一个实现该接口的例子，提供了<font color="#ff0000">更灵活的锁管理和更高的性能</font>。</li><li><strong>volatile关键字</strong>：volatile关键字用于变量，确保所有线程<font color="#ff0000">看到的是该变量的最新值</font>，而不是可能存储在本地寄存器的副本。</li><li><strong>原子类</strong>：Java并发库（<code>Java.util.concurrent.atomic</code>）提供了原子类，如AtomicInteger、AtomicLong等，这些类<font color="#ff0000">提供了原子操作</font>，可以用于<font color="#ff0000">更新基本类型的变量</font>而无需额外的同步。</li><li><strong>线程局部变量</strong>：ThreadLocal类可以为<font color="#ff0000">每个线程提供独立的变量副本</font>，这样每个线程拥有自己的变量，消除了竞争条件。</li><li><strong>并发集合</strong>：使用<code>java.util.concurrent</code>包中的<font color="#ff0000">线程安全集合</font>，如ConcurrentHashMap、ConcurrentLinkedQueue等，这些集合内部已经实现了线程安全的逻辑。</li></ul><h2 id="公平锁和非公平锁的区别？"><a href="#公平锁和非公平锁的区别？" class="headerlink" title="公平锁和非公平锁的区别？"></a>公平锁和非公平锁的区别？</h2><ul><li><strong>公平锁</strong>：锁被释放之后，<font color="#ff0000">先申请的线程先得到锁</font>。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。</li><li><strong>非公平锁</strong>：锁被释放之后，<font color="#ff0000">后申请的线程可能会先获取到锁</font>，是随机或者按照其他优先级排序的。性能更好，但可能会导致某些线程永远无法获取到锁。</li></ul><h2 id="乐观锁和悲观锁"><a href="#乐观锁和悲观锁" class="headerlink" title="乐观锁和悲观锁"></a>乐观锁和悲观锁</h2><ul><li><strong>乐观锁</strong>：乐观锁总是假设最好的情况，<font color="#ff0000">认为共享资源每次被访问时不会发生冲突</font>，线程可以不停地执行，无需加锁无需等待，只是<font color="#ff0000">在提交修改的时候去验证对应的数据是否被其他线程修改</font>了。乐观锁通常用于<font color="#ff0000">写比较少的情况</font>，这样可以避免频繁加锁影响性能。乐观锁住要针对的对象是<font color="#ff0000">单个共享变量</font>。CAS是乐观锁的核心思想。</li><li><strong>悲观锁</strong>：总是假设最坏的情况，<font color="#ff0000">认为共享资源每次被访问时都会发生冲突</font>，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源的时候就会阻塞直到锁被上一个持有者释放。悲观锁通常用于<font color="#ff0000">写比较多的情况</font>，这样可以避免频繁失败和重试影响性能。synchronized和ReentrantLock是悲观锁的典型实现。</li></ul><h2 id="CAS（CompareAndSwap，比较再交换）"><a href="#CAS（CompareAndSwap，比较再交换）" class="headerlink" title="CAS（CompareAndSwap，比较再交换）"></a>CAS（CompareAndSwap，比较再交换）</h2><ul><li>体现了一种<font color="#ff0000">乐观锁</font>的思想，在<font color="#ff0000">无锁的状态下保证操作数据的原子性</font>。</li><li>CAS操作包含三个核心的参数：<ul><li>V：要更新的内存地址</li><li>A：预期的旧值</li><li>B：要更新的新值</li></ul></li><li>执行CAS时，当且仅当内存地址V处的值等于预期旧值A时，才会原子地将V处的值改为新值B。如果V处的值不等于A，说明其他线程已经修改了它，此时CAS失败，不做任何操作。</li><li>在java中，CAS底层依赖<code>Unsafe</code>类的方法，调用的是<font color="#ff0000">cpu级别的原子指令</font>。<code>java.util.concurrent.atomic</code>包下的所有原子类都广泛使用了CAS技术。通常配合while(true)循环使用，<font color="#ff0000">失败后不断重试</font>（也就是<font color="#ff0000">自旋</font>）。</li></ul><h2 id="ABA问题"><a href="#ABA问题" class="headerlink" title="ABA问题"></a>ABA问题</h2><ul><li>ABA问题是CAS机制的一个漏洞。</li><li>CAS在操作时，只关心“预期值A“和”当前值“是否相等。但<strong>如果一个值从A变成了B，然后又变回了A</strong>，CAS检查时会发现值仍然是A，误认为它没有被修改过，于是执行了交换操作。但在某些业务场景下，A-&gt;B-&gt;A的过程是需要被感知的。</li><li>解决办法：在变量前面追加上版本号或时间戳。JDK1.5之后的<code>AtomicStampedReference</code>类就是用来解决ABA问题的，其中的<code>compareAndSet()</code>方法就是在比较时，<strong>不但会比较当前值，还会比较一个戳记（Stamp）</strong>，这个戳记就相当于版本号，只有当值和版本号都同时满足预期时，CAS才会成功。</li></ul><h2 id="Java有哪些常用的锁？"><a href="#Java有哪些常用的锁？" class="headerlink" title="Java有哪些常用的锁？"></a>Java有哪些常用的锁？</h2><h3 id="从“实现方式”分类"><a href="#从“实现方式”分类" class="headerlink" title="从“实现方式”分类"></a>从“实现方式”分类</h3><p>分为JVM层面的锁和JDK代码层面的锁</p><ul><li>synchronized<ul><li>来源：Java关键字，由JVM也就是Hotspot虚拟机实现。</li><li>特点：<ul><li>加锁和释放锁自动完成</li><li>是可重入锁</li><li>一旦阻塞等待，无法被中断</li><li>默认是非公平锁，不能改成公平</li><li>为了性能优化，JVM内部实现了偏向锁-&gt;轻量级锁-&gt;重量级锁的升级机制。</li></ul></li></ul></li><li>Lock接口及其实现<ul><li>来源：JDK的java.util.concurrent.locks包，基于Java代码（AQS）实现。</li><li>核心实现类：<ul><li>ReentrantLock</li><li>ReentrantReadWriteLock</li></ul></li><li>特点：<ul><li>必须调用lock()加锁，必须在finally中调用unlock()释放锁。</li><li>支持尝试获取锁、超时获取、响应中断。</li><li>默认非公平，但是可以构造为公平锁。</li></ul></li></ul></li></ul><h3 id="从“锁的特性”分类"><a href="#从“锁的特性”分类" class="headerlink" title="从“锁的特性”分类"></a>从“锁的特性”分类</h3><ol><li>悲观锁 vs 乐观锁</li><li>可重入锁 vs 不可重入锁</li><li>公平锁 vs 非公平锁</li><li>独占锁 vs 共享锁</li></ol><h2 id="synchronized关键字的底层原理"><a href="#synchronized关键字的底层原理" class="headerlink" title="synchronized关键字的底层原理"></a>synchronized关键字的底层原理</h2><h3 id="核心实现机制"><a href="#核心实现机制" class="headerlink" title="核心实现机制"></a>核心实现机制</h3><ul><li>synchronized底层是<strong>基于monitor</strong>来实现的。编译器会在同步的代码块的<strong>开始位置插入<code>monitorenter</code>指令</strong>，在<strong>结束为止插入<code>monitorexit</code>指令</strong>。monitor底层是依赖于操作系统的<font color="#ff0000">Mutex Lock（互斥锁</font>）来实现的。</li></ul><h3 id="monitor的工作原理"><a href="#monitor的工作原理" class="headerlink" title="monitor的工作原理"></a>monitor的工作原理</h3><ul><li>在加锁时，JVM会<strong>修改对象头里的mark work中的数据</strong>，让它指向一个重量级的monitor对象。</li><li>monitor内部有三个属性：<ul><li><strong>owner</strong>：指向当前持有该monitor锁的线程。如果为null，表示锁为被占用。</li><li><strong>entrylist</strong>：一个队列，存放所有处于阻塞状态、等待获取该锁的线程。</li><li><strong>waitset</strong>：一个集合，存放了所有调用了该对象wait()方法而处于等待状态的线程。</li></ul></li></ul><h3 id="锁的获取与释放流程"><a href="#锁的获取与释放流程" class="headerlink" title="锁的获取与释放流程"></a>锁的获取与释放流程</h3><ul><li><strong>抢锁过程</strong>：当一个线程执行到monitorenter指令时，它会尝试获取monitor的所有权，也就是尝试将owner设为自己<ul><li>如果monitor的计数器为0，或者owner本来就是自己，线程会成功拿到锁，并将计数器+1；</li><li>如果锁已经被别人持有了，当前线程就会被阻塞，并进入Entrylist中排队等待。</li></ul></li><li><strong>释放过程</strong>：当执行monitorexit时，monitor的计数器会-1<ul><li>如果减完之后不是0，说明是可重入锁，线程依然持有锁；</li><li>如果减完之后是0，说明锁完全释放，owner被设置为null。此时会从Entrylist中唤醒一个等待的线程来重新竞争锁。</li></ul></li></ul><h2 id="synchronized可重入锁是怎么实现的？"><a href="#synchronized可重入锁是怎么实现的？" class="headerlink" title="synchronized可重入锁是怎么实现的？"></a>synchronized可重入锁是怎么实现的？</h2><ul><li>synchronized底层是利用操作系统Mutex Lock实现的，每一个可重入锁都会关联一个线程ID和一个计数器。</li><li>当一个线程请求获取锁时，会去检查锁的状态：<ul><li>如果计数器为0，代表该锁没有被占用，使用CAS操作获取锁，将线程ID替换为自己的线程ID。</li><li>如果计数器不为0，代表有线程在访问该对象。此时，如果线程ID是自己的线程ID：<ul><li>可重入锁：将计数器自增1，然后获取到该锁；</li><li>不可重入锁：进入阻塞队列等待。</li></ul></li></ul></li><li>在释放锁时：<ul><li>如果是可重入锁，每一个退出方法，会将计数器减1，直至计数器的值为0，最后释放该锁；</li><li>如果是不可重入锁，线程退出方法，直接就会释放该锁。</li></ul></li></ul><h2 id="synchronized锁升级的过程"><a href="#synchronized锁升级的过程" class="headerlink" title="synchronized锁升级的过程"></a>synchronized锁升级的过程</h2><ul><li>JDK1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。整个锁升级的过程，其实就是一个随着竞争加剧，锁的状态逐步升级的过程：从<strong>无锁-&gt;偏向锁-&gt;轻量级锁-&gt;重量级锁</strong>。</li><li>一共三个阶段：<ul><li><strong>偏向锁</strong>：当 JVM 启动 4 秒后（因为有 <code>-XX:BiasedLockingStartupDelay</code> 默认延迟），如果一个对象被创建，它默认是可偏向状态。<ul><li><strong>触发时机</strong>：当<font color="#ff0000">第一个线程访问同步块</font>时。</li><li><strong>核心操作</strong>：JVM不会加锁，而是通过<font color="#ff0000">CAS操作</font>将当前线程的ID记录在对象头的mark word中。</li><li><strong>优势</strong>：当这个线程再次进入同步块时，只需要对比mark word中的线程ID是不是自己。如果是，完全不需要CAS也不需要加锁，直接执行。</li></ul></li><li><strong>轻量级锁</strong>：一旦有第二个线程尝试获取该锁，JVM会撤销偏向锁，将其升级为轻量级锁。<ul><li><strong>触发时机</strong>：<font color="#ff0000">出现了轻微的竞争</font>，或者两个线程交替执行，没有发生同时抢占。</li><li><strong>核心操作</strong>：<ul><li>JVM会在<font color="#ff0000">当前线程的栈帧</font>中建立一个名为<font color="#ff0000">Lock Record</font>（锁记录）的空间。</li><li>然后尝试<font color="#ff0000">用CAS将对象头的mark word替换为指向Lock Record</font>的指针。</li></ul></li><li><strong>自旋</strong>：如果CAS失败，线程不会立刻被挂起，而是会<font color="#ff0000">进行自旋</font>，看看能不能等持有锁的线程把锁释放掉。</li></ul></li><li><strong>重量级锁</strong><ul><li><strong>触发时机</strong>：<ul><li><font color="#ff0000">自旋超过了阈值</font>；</li><li>等待队列里已经有一个线程在自旋了，<font color="#ff0000">又来了第三个线程</font>。</li></ul></li><li><strong>核心操作</strong>：<ul><li>锁标志位变为10，<font color="#ff0000">mark word指向堆中的monitor对象</font>。</li><li>此时，通过CAS抢不到锁的线程，不再自旋，而是直接调用操作系统的底层互斥锁将自己挂起，进入阻塞队列等待唤醒。</li></ul></li></ul></li></ul></li></ul><h2 id="什么是AQS？"><a href="#什么是AQS？" class="headerlink" title="什么是AQS？"></a>什么是AQS？</h2><ul><li><code>AQS(AbstractQueuedSynchronizer)</code>是抽象队列同步器，是<code>java.util.concurrent</code>包下构建锁和同步器的核心基础框架。</li><li>AQS的核心设计：<ul><li><strong>一个state状态</strong>：<ul><li>是一个<font color="#ff0000">volatile的int类型的变量</font>，代表共享资源的状态；比如在ReentrantLock中，state=0代表锁空闲，state=1代表被占用，state&gt;1代表可重入次数。</li><li>AQS使用<font color="#ff0000">CAS操作来原子地修改这个state值</font>；</li></ul></li><li><strong>CHL变体双向队列</strong>：<ul><li><strong>Node节点</strong>：每个<font color="#ff0000">被阻塞的线程都会被封装成一个Node节点放入队列</font>。Node里包含了线程本身、状态以及前驱和后继指针。</li><li><strong>结构</strong>：队列头通常代表当前持有锁的线程，后续节点则是等待的线程。</li></ul></li></ul></li><li>核心过程：<ul><li><strong>抢锁</strong>：线程进来<font color="#ff0000">先尝试用CAS修改state</font>。如果成功，就拿到了锁，设置当前线程为exclusiveOwnerThread。</li><li><strong>入队与阻塞</strong>：如果CAS失败，线程会被封装成Node加入队尾。加入后，它会检查前驱节点是不是 Head，如果是就有机会再试一次。如果还不行，就调用 <code>LockSupport.park()</code> 让线程进入阻塞状态（此时线程交出 CPU，不再空转）。</li><li><strong>唤醒</strong>：当持有锁的线程调用 release() 时，它会修改 state，并调用 <code>LockSupport.unpark()</code> 唤醒队列中 Head 节点的下一个节点（Next），让其重新尝试 CAS 抢锁。<br><img src="AQS%E7%BB%93%E6%9E%84.png" alt="AQS结构"></li></ul></li></ul><h2 id="ReentrantLock底层原理"><a href="#ReentrantLock底层原理" class="headerlink" title="ReentrantLock底层原理"></a>ReentrantLock底层原理</h2><p><img src="ReentrantLock%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86.png" alt="ReentrantLock底层原理"></p><ul><li><code>ReentrantLock</code>里面有一个内部类<code>Sync</code>，<code>Sync</code>继承自AQS，添加锁和释放锁的大部分操作实际上都是在<code>Sync</code>中实现的。<code>Sync</code>有公平锁<code>FairSync</code>和非公平锁<code>NonfairSync</code>两个子类。</li><li><code>ReentrantLock</code>的底层就是由AQS实现的：<ul><li><strong>状态变量（state）</strong>：AQS内部维护一个<code>volatile int state</code>变量，用于表示锁的计数器或同步状态。<ul><li><font color="#ff0000">state=0</font>：表示锁当前处于未被占用状态；</li><li><font color="#ff0000">state&gt;0</font>：表示锁被占用，state的值即为重入次数。</li></ul></li><li><strong>获取锁（lock()）</strong>：线程尝试使用CAS将state从0设置为1。<ul><li>成功：表示获取锁成功，<font color="#ff0000">将当前线程设置为锁的独占线程</font>，是通过AQS的<code>exclusiveOwnerThread</code>变量记录。</li><li>失败：判断是否是<font color="#ff0000">重入</font>或<font color="#ff0000">阻塞</font>。</li></ul></li><li><strong>锁的重入</strong>：如果发现当前线程就是锁的独占线程，则直接将state+1，实现锁的重入。</li><li><strong>锁的阻塞</strong>：如果获取锁失败，且不是重入，则将<font color="#ff0000">当前线程封装成一个Node节点，加入到AQS的CLH等待队列中</font>，并进入阻塞状态。</li><li>AQS 使用一个<strong>双向链表</strong>作为同步队列（也称 CLH 队列），用于管理所有未能成功获取锁的线程。<ul><li><strong>队列结构：</strong> 队列的头节点（<code>head</code>）表示当前持有锁的线程的 Node，后续节点是等待锁的线程。</li><li><strong>入队：</strong> 竞争失败的线程会被封装成 Node，通过 <strong>CAS 尾插法</strong>安全地加入队列末尾。</li><li><strong>唤醒机制：</strong> 当持有锁的线程释放锁时，会唤醒队列中的<font color="#ff0000">头节点的后继节点</font>，被唤醒的线程会再次尝试竞争锁。</li></ul></li><li>**锁的释放 (<code>unlock()</code>)**：锁的释放过程是递减 <code>state</code> 计数器。<ul><li><strong>递减状态：</strong> 每次调用 <code>unlock()</code>，都将 <code>state</code> 减 1。</li><li><strong>完全释放：</strong> 当 <code>state</code> 递减到 0 时，表示锁被<strong>彻底释放</strong>。</li><li><strong>唤醒后继：</strong> 锁释放后，当前线程会设置 <code>exclusiveOwnerThread</code> 为 <code>null</code>，然后<strong>唤醒 CLH 队列中的下一个等待线程</strong>。</li></ul></li></ul></li></ul><h2 id="synchronized和ReentrantLock有什么区别？"><a href="#synchronized和ReentrantLock有什么区别？" class="headerlink" title="synchronized和ReentrantLock有什么区别？"></a>synchronized和ReentrantLock有什么区别？</h2><ul><li><strong>实现层面</strong>：<ul><li><code>synchronized</code>：是Java关键字，<font color="#ff0000">由JVM底层实现</font>。依赖于对象头mark word和操作系统的monitor监视器锁。</li><li><code>ReentrantLock</code>：是JUC包中的一个API类。完全是<font color="#ff0000">用Java实现的</font>，底层依赖AQS。</li></ul></li><li><strong>锁的释放</strong>：<ul><li><code>synchronized</code>：synchronized会<font color="#ff0000">自动加锁和释放锁</font>，当进入synchronized修饰的代码块后会自动加锁，当离开synchronized的代码块后会自动释放锁。</li><li><code>ReentrantLock</code>：<font color="#ff0000">必须手动释放锁</font>。必须在finally块中显式调用unlock()方法。如果忘记释放，将导致灾难性的死锁。</li></ul></li><li>ReentrantLock提供了synchronized不具备的几个高级功能：<ul><li><strong>公平性选择</strong>：<ul><li><code>synchronized</code>是<font color="#ff0000">非公平锁</font>；</li><li><code>ReentrantLock</code>默认为非公平锁，但可以通过构造函数<code>new ReentrantLock(true)</code>创建公平锁。公平锁会按照线程请求的顺序（FIFO）来分配锁，但性能开销更大。</li></ul></li><li><strong>可中断的锁获取：</strong><ul><li><code>synchronized</code> 获取锁是<font color="#ff0000">阻塞且不可中断</font>的。如果一个线程拿不到锁，它会一直死等。</li><li><code>ReentrantLock</code> 提供了 <code>lockInterruptibly()</code> 方法，<font color="#ff0000">允许线程在等待锁的过程中响应中断</font>，增加了灵活性，可以避免死锁。</li></ul></li><li><strong>可超时的锁获取/非阻塞获取：</strong><ul><li><code>synchronized</code> <font color="#ff0000">只能一直等待</font>。</li><li><code>ReentrantLock</code> 提供了 <code>tryLock()</code> 和 <code>tryLock(time, unit)</code> 方法：<ul><li><code>tryLock()</code>：立即尝试获取锁，成功返回 <code>true</code>，失败返回 <code>false</code>，<font color="#ff0000">不阻塞</font>。</li><li><code>tryLock(time, unit)</code>：在指定时间内<font color="#ff0000">可超时地尝试获取锁</font>，超时则放弃。</li></ul></li></ul></li><li><strong>线程等待/唤醒机制：</strong><ul><li><code>synchronized</code>：配合 <code>Object</code> 类的 <code>wait()</code> / <code>notify()</code> / <code>notifyAll()</code> 使用。它只提供一个条件队列，<code>notifyAll</code> 会唤醒所有等待的线程，效率较低。</li><li><code>ReentrantLock</code>：配合 <code>Condition</code> 接口使用。它可以通过 <code>newCondition()</code> 创建多个 <code>Condition</code> 对象，实现更精确的线程分组等待和唤醒，灵活性和效率远高于 <code>wait/notify</code>。</li></ul></li></ul></li></ul><h2 id="指令重排序（单例模式举例）"><a href="#指令重排序（单例模式举例）" class="headerlink" title="指令重排序（单例模式举例）"></a>指令重排序（单例模式举例）</h2><ul><li><p>在JMM的规范下，编译器和cpu为了性能，会进行<font color="#ff0000">指令重排序</font>。重排序在单线程下有<code>as-if-serial</code>语义保证结果正确，但在多线程下，就可能破坏代码的逻辑。比如经典的<strong>双重检查锁定（DCL）下单例模式失效</strong>，就是重排序导致的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123; </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton uniqueInstance; </span><br><span class="line"><span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123; </span><br><span class="line">&#125; </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getUniqueInstance</span><span class="params">()</span> &#123; </span><br><span class="line"><span class="comment">//第一次检查，只有为空的时候才加锁 </span></span><br><span class="line"><span class="keyword">if</span> (uniqueInstance == <span class="literal">null</span>) &#123; </span><br><span class="line"><span class="comment">//类对象加锁 </span></span><br><span class="line"><span class="keyword">synchronized</span> (Singleton.class) &#123; </span><br><span class="line"><span class="comment">// 第二次检查，为了线程安全</span></span><br><span class="line"><span class="keyword">if</span> (uniqueInstance == <span class="literal">null</span>) &#123; </span><br><span class="line">uniqueInstance = <span class="keyword">new</span> <span class="title class_">Singleton</span>(); </span><br><span class="line">&#125; </span><br><span class="line">&#125; </span><br><span class="line">&#125; <span class="keyword">return</span> uniqueInstance; </span><br><span class="line">&#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>uniqueInstance = new Singleton();这段代码其实是分为三步执行：</p><ol><li>为<code>uniqueInstance</code>分配内存空间；</li><li>初始化<code>uniqueInstance</code>；</li><li>将<code>uniqueInstance</code>指向分配的内存地址；</li></ol></li><li><p>但是由于JVM具有指令重排序的特性，执行顺序有可能会变成1-&gt;3-&gt;2。在多线程环境下，线程T1执行了1和3，此时T2调用<code>getUniqueInstance()</code> 后发现<code>uniqueInstance</code>不为空，因此返回<code>uniqueInstance</code>，但此时<code>uniqueInstance</code>还未被初始化。</p></li></ul><h2 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h2><ul><li><strong>保证线程间的可见性</strong>：当一个线程修改了volatile修饰的变量，这个修改<font color="#ff0000">会立刻被强制写回主内存</font>。同时，当其他线程在读取这个变量时，会立即使本地的工作内存失效，<font color="#ff0000">强制从主内存重新读取</font>。这样就确保了所有线程看到的都是最新值。</li><li><strong>禁止进行指令重排序</strong>：用volatile修饰共享变量会在读、写共享变量时加入不同的内存屏障，阻止其他读写操作越过屏障，从而达到阻止重排序的效果：<ul><li><font color="#245bdb">写-写（Write-Write）屏障</font>：在对volatile变量执行写操作前，会插入一个写屏障。这确保了在该变量写操作之前的所有普通写操作都已完成，防止了这些写操作被移到volatile写操作之后。</li><li><font color="#245bdb">读-读（Read-Read）屏障</font>：在对volatile变量执行读操作后，会插入一个读屏障。它确保了对volatile变量的读操作后的所有普通读操作都不会被提前到volatile读之前执行，保证了读取的数据是最新的。</li><li><font color="#245bdb">写-读（Write-Read）屏障</font>：发生在volatile写之后和volatile读之前。这个屏障确保了volatile写操作之前的所有内存操作都不会被重排序到volatile读之后，同时也确保了volatile读操作之后所有的内存操作都不会被重排序到volatile写之前。</li></ul></li><li>volatile<font color="#ff0000">只保证了可见性和有序性，不保证原子性</font>。比如i++这样的复合操作（也就是只能一个线程写，多个线程读）。</li></ul><h2 id="synchronized和volatile有什么区别？"><a href="#synchronized和volatile有什么区别？" class="headerlink" title="synchronized和volatile有什么区别？"></a>synchronized和volatile有什么区别？</h2><ul><li><strong>使用范围</strong>：<ul><li><code>volatile</code>只能<font color="#ff0000">修饰变量</font>；</li><li><code>synchronized</code>可以<font color="#ff0000">修饰方法或代码块</font>；</li></ul></li><li><strong>保持的特性</strong>：<ul><li><code>volatile</code>只能保证<font color="#ff0000">可见性和有序性</font>；</li><li><code>synchronized</code>可以保证可见性、有序性，还能<font color="#ff0000">保证原子性</font>；</li></ul></li><li><strong>是否阻塞</strong>：<ul><li><code>volatile</code>是<font color="#ff0000">非阻塞的</font>，不会引起线程上下文切换；</li><li><code>synchronized</code>是<font color="#ff0000">阻塞的</font>。如果一个线程获取不到锁，会进入阻塞状态，等待锁被释放，涉及线程上下文的切换。</li></ul></li><li><strong>性能</strong>：<ul><li><code>volatile</code>是<font color="#ff0000">轻量级同步机制</font>，性能开销小；</li><li><code>synchronized</code>是<font color="#ff0000">重量级锁</font>；</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Java如何保证多线程安全？&quot;&gt;&lt;a href=&quot;#Java如何保证多线程安全？&quot; class=&quot;headerlink&quot; title=&quot;Java如何保证多线程安全？&quot;&gt;&lt;/a&gt;Java如何保证多线程安全？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;synchron</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="多线程" scheme="http://lixrangel.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>线程基础</title>
    <link href="http://lixrangel.com/2025/12/02/java-ba-gu/duo-xian-cheng-bing-fa/xian-cheng-ji-chu/"/>
    <id>http://lixrangel.com/2025/12/02/java-ba-gu/duo-xian-cheng-bing-fa/xian-cheng-ji-chu/</id>
    <published>2025-12-01T16:00:00.000Z</published>
    <updated>2026-01-18T10:39:52.684Z</updated>
    
    <content type="html"><![CDATA[<h2 id="线程和进程的区别？"><a href="#线程和进程的区别？" class="headerlink" title="线程和进程的区别？"></a>线程和进程的区别？</h2><ul><li><strong>本质区别</strong>：进程是<font color="#ff0000">操作系统资源分配</font>的基本单位，而线程是<font color="#ff0000">任务调度和执行</font>的基本单位。</li><li><strong>在开销方面</strong>：每个进程有<font color="#ff0000">独立的代码和数据空间</font>，程序之间的切换会有较大的开销；线程可以看作轻量级的进程，同一类线程共享代码和数据空间，每个线程有自己<font color="#ff0000">独立的运行栈和程序计数器</font>，线程之间切换的开销小。</li><li><strong>稳定性方面</strong>：进程中某个线程崩溃了，可能会导致整个进程都崩溃。而进程中的子进程崩溃，并不会影响其他进程。</li><li><strong>内存分配方面</strong>：进程是资源分配的基本单位，拥有独立的地址空间；而线程是cpu调度的基本单位，<font color="#ff0000">几乎不拥有系统资源</font>，只保留少量私有数据（PC、栈、寄存器），主要共享其所属进程的资源。</li></ul><h2 id="进程、线程、协程的区别是什么？"><a href="#进程、线程、协程的区别是什么？" class="headerlink" title="进程、线程、协程的区别是什么？"></a>进程、线程、协程的区别是什么？</h2><ul><li><strong>进程</strong>是操作系统中进行<font color="#ff0000">资源分配和调度的基本单位</font>，拥有自己的独立内存空间和系统资源。每个进程都有独立的堆和栈，不与其他进程共享。<font color="#ff0000">进程间通信需要通过特定的机制</font>，如管道、消息队列、信号量等。由于进程拥有独立的内存空间，因此其<font color="#ff0000">稳定性和安全性相对较高</font>，但同时<font color="#ff0000">上下文切换的开销也大</font>，因为需要保存和恢复整个进程的状态。</li><li><strong>线程</strong>是进程内的一个执行单元，也是<font color="#ff0000">cpu调度和分派的基本单位</font>。与进程不同，线程共享进程的内存空间，包括堆和全局变量。<font color="#ff0000">线程之间通信更加高效</font>，因为它们可以直接读写共享内存。线程的<font color="#ff0000">上下文切换开销较小</font>，因为只需要保存和恢复线程的上下文，而不是整个进程的状态。然而，由于多个线程共享内存空间，因此<font color="#ff0000">存在数据竞争和线程安全</font>的问题，需要通过同步和互斥机制来解决。</li><li><strong>协程</strong>是一种<font color="#ff0000"><strong>用户态</strong>的轻量级线程</font>，其调度完全由用户程序控制，而<font color="#ff0000">不需要内核的参与</font>。协程拥有自己的寄存器上下文和栈，但与其他协程共享堆内存。协程的<font color="#ff0000">切换开销非常小</font>，因为只需要保存和恢复协程的上下文，而<font color="#ff0000">无需进行内核级的上下文切换</font>。这使得协程在处理大量并发任务时具有非常高的效率。然而，协程需要程序员显式地进行调度和管理，相对于线程和进程来说，其<font color="#ff0000">编程模型更为复杂</font>。</li></ul><h2 id="线程间的同步方式有哪些？"><a href="#线程间的同步方式有哪些？" class="headerlink" title="线程间的同步方式有哪些？"></a>线程间的同步方式有哪些？</h2><ol><li><strong>互斥锁（Mutex）</strong>：采用<font color="#ff0000">互斥对象机制</font>，只有拥有互斥对象的线程才能访问公共资源。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如<font color="#ff0000">synchronized关键字和各种Lock都是这种机制</font>。</li><li><strong>读写锁（Read-Write Lock）</strong>：允许多个线程同时读取共享资源，但只有一个线程可以对共享资源进行写操作。<font color="#ff0000">读锁不互斥，写锁互斥</font>。大大提高读多写少的共享资源访问效率。</li><li><strong>信号量（Semaphore）</strong>：它允许同一时刻多个线程访问同一资源，但是需要控制<font color="#ff0000">同一时刻访问此资源的最大线程数量</font>。维护一个计数器，线程获取资源时计数器减1，释放时加1。</li><li><strong>屏障（Barrier）</strong>：屏障是一种<font color="#ff0000">同步原语</font>，用于<font color="#ff0000">等待多个线程到达某个点再一起继续执行</font>。当一个线程到达屏障时，它会停止执行并等待其他线程到达屏障，直到所有线程都达到屏障后，它们才会一起执行。</li><li><strong>事件（Event）</strong>：<font color="#ff0000">Wait()/notify()</font>，通过通知操作的方式来保持多线程同步。</li></ol><h2 id="创建线程的方式有哪些？"><a href="#创建线程的方式有哪些？" class="headerlink" title="创建线程的方式有哪些？"></a>创建线程的方式有哪些？</h2><ol><li><strong>继承Thread类</strong>：重写<code>run()</code>方法，不能再继承其他父类；</li><li><strong>实现Runnable接口</strong>：重写<code>run()</code>方法，然后将此Runnable对象作为参数传递给Thread类的构造器，创建Thread对象后调用其<code>start()</code>方法启动线程；</li><li><strong>实现Callable接口</strong>：重写<code>call()</code>方法，<code>call()</code>方法可以有返回值并且可以抛出异常。将此对象包装进一个<code>FutureTask</code>，然后将<code>FutureTask</code>传入Thread构造器（Thread构造器只接收Runnable参数，而FutureTask实现了Runnable接口）；</li><li><strong>使用线程池创建</strong><h3 id="追问：Runnable和Callable有什么区别？"><a href="#追问：Runnable和Callable有什么区别？" class="headerlink" title="追问：Runnable和Callable有什么区别？"></a>追问：Runnable和Callable有什么区别？</h3></li><li><strong>Runnable接口</strong>run方法<font color="#ff0000">没有返回值</font>。<strong>Callable接口</strong>call方法<font color="#ff0000">有返回值</font>，是个泛型，和Future、FutureTask配合<font color="#ff0000">可以用来获取异步执行的结果</font>。</li><li><strong>Callable接口</strong>的call方法<font color="#ff0000">允许抛出异常</font>；而<strong>Runnable接口</strong>的run方法的<font color="#ff0000">异常只能在内部消化</font>，不能继续上抛。</li></ol><h2 id="进程有哪几种状态？"><a href="#进程有哪几种状态？" class="headerlink" title="进程有哪几种状态？"></a>进程有哪几种状态？</h2><ul><li><strong>创建状态（new）</strong>：进程<font color="#ff0000">正在被创建</font>，尚未到就绪状态。</li><li><strong>就绪状态（ready）</strong>：进程已处于准备运行状态，即进程<font color="#ff0000">获得了除了处理器之外的一切所需资源</font>，一旦得到处理器资源即可运行。</li><li><strong>运行状态（running）</strong>：进程正在处理器上运行。</li><li><strong>阻塞状态（waiting）</strong>：又称为等待状态，进程正在<font color="#ff0000">等待某一事件而暂停运行</font>如等待某些资源或者等待IO操作完成。即使cpu空闲，该进程也不能运行。</li><li><strong>结束状态（terminated）</strong>：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。</li></ul><h2 id="线程包含哪些状态？状态之间如何切换？"><a href="#线程包含哪些状态？状态之间如何切换？" class="headerlink" title="线程包含哪些状态？状态之间如何切换？"></a>线程包含哪些状态？状态之间如何切换？</h2><ul><li><strong>新建（NEW）</strong>、<strong>可运行（RUNNABLE）</strong>、<strong>阻塞（BLOCKED）</strong>、<strong>等待(WAITING)<strong>、</strong>计时等待（TIMED_WAITING）</strong>、<strong>终止（TERMINATED）</strong></li><li><font color="#ff0000">创建线程对象</font>是<font color="#ff0000">新建状态</font>，但此时还没有调用start方法；</li><li><font color="#ff0000">调用了start()方法</font>转变为<font color="#ff0000">就绪状态</font>，等待调度。<font color="#ff0000">调度后</font>变为<font color="#ff0000">运行状态</font>；</li><li>线程获取到了cpu的执行权，<font color="#ff0000">执行结束</font>是<font color="#ff0000">终止状态</font>。</li><li>在可运行状态的过程中，如果没有获取cpu的执行权，可能会切换到其他状态：<ul><li>如果<font color="#ff0000">没有获取锁</font>（synchronized或lock）进入<font color="#ff0000">阻塞状态</font>，获得锁再切换为可运行状态；</li><li>如果线程<font color="#ff0000">调用了wait()方法</font>进入<font color="#ff0000">等待状态</font>，其他线程调用notify()唤醒后可切换为可运行状态；</li><li>如果线程<font color="#ff0000">调用了sleep(50)方法</font>，进入<font color="#ff0000">计时等待状态</font>，到时间后可切换为可运行状态。<br><img src="%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%8A%E5%85%B6%E5%88%87%E6%8D%A2.png" alt="线程状态及其切换"></li></ul></li></ul><h2 id="进程间通信方式有哪些？"><a href="#进程间通信方式有哪些？" class="headerlink" title="进程间通信方式有哪些？"></a>进程间通信方式有哪些？</h2><ol><li><strong>管道/匿名管道（Pipes）</strong>：用于具有<font color="#ff0000">亲缘关系的父子进程间</font>或者<font color="#ff0000">兄弟进程</font>之间的通信。通信的数据是<font color="#ff0000">无格式的字节流</font>并且<font color="#ff0000">大小受限</font>，<font color="#ff0000">通信的方式是单向的</font>。存在于内存中，进程结束，管道就消失了。</li><li><strong>有名管道（Named Pipes）</strong>：匿名管道由于没有名字，只能用于亲缘关系的进程间通信。有名管道需要在文件系统中创建一个类型为p的设备文件，那么毫无关系的进程就可以<font color="#ff0000">通过这个设备文件进行通信</font>。有名管道严格遵循先进先出。</li><li><strong>消息队列（Message Queuing）</strong>：存放在<font color="#ff0000">内核内存中的消息链表</font>，通过消息队列标识符识别。数据是<font color="#ff0000">有格式、结构化的数据</font>，消息体是用户自定义的数据类型。发送和接收方必须保持数据类型一致。默认遵循先进先出原则，但是也可以<font color="#ff0000">实现消息的随机查询</font>。<font color="#ff0000">生命周期独立于进程</font>，只有在内核重启或显式删除时，消息队列才会被真正删除。每次读写都需要<font color="#ff0000">经过用户态和内核态之间的数据拷贝过程</font>，因此通信速度不是最及时的。</li><li><strong>共享内存（Shared memory）</strong>：使得<font color="#ff0000">多个进程可以访问同一块内存空间</font>，不同进程可以及时看到对方进程中对共享内存中数据的更新。可以<font color="#ff0000">解决</font>消息队列通信中用户态和内核态之间数据<font color="#ff0000">拷贝过程带来的开销</font>。这种方式需要<font color="#ff0000">依靠某种同步操作</font>，如互斥锁和信号量等。但是多进程竞争同个共享资源会造成数据的错乱。</li><li><strong>信号量（Semaphore）</strong>：信号量是一个<font color="#ff0000">计数器</font>，用于多进程对共享数据的访问。这种通信方式主要用于<font color="#ff0000">解决共享内存的问题</font>。</li><li><strong>信号（Signal）</strong>：一种模拟硬件中断的机制，传递的信息量极少，主要<font color="#ff0000">用于通知进程某个事件的发生</font>。</li><li><strong>套接字（Socket）</strong>：此方法主要用于<font color="#ff0000">不同主机之间通过网络进行通信</font>。支持TCP/IP的网络通信的基本操作单元，可以看作是不同主机之间的进程进行双向通信的端点。</li></ol><h2 id="线程间的通信方式有哪些？"><a href="#线程间的通信方式有哪些？" class="headerlink" title="线程间的通信方式有哪些？"></a>线程间的通信方式有哪些？</h2><ol><li><strong>共享变量</strong><ol><li><strong>volatile关键字</strong>。保证可见性；</li><li><strong>synchronized关键字</strong>。保证可见性和原子性。</li></ol></li><li><strong>等待/通知机制</strong><ol><li>**Object的wait() / notify()**。必须配合synchronized使用。</li><li>**Condition的await() / signal()**。必须配合ReentrantLock使用。</li></ol></li></ol><h2 id="Java中wait和sleep方法的不同？"><a href="#Java中wait和sleep方法的不同？" class="headerlink" title="Java中wait和sleep方法的不同？"></a>Java中wait和sleep方法的不同？</h2><ul><li><strong>方法归属不同</strong>：<ul><li>sleep(long)是<font color="#ff0000">Thread的静态方法</font>，可以在任何地方通过Thread.sleep()调用，无需依赖实例对象。</li><li>wait()、wait(long)都是<font color="#ff0000">Object的成员方法</font>，每个对象都有，<font color="#ff0000">必须通过对象实例来调用</font>。</li></ul></li><li><strong>锁释放的情况</strong>：<ul><li>Thread.sleep()在调用时，线程会暂停执行指定的时间，但是<font color="#ff0000">不会释放持有的对象锁</font>。</li><li>Object.wait()在调用时，线程<font color="#ff0000">会释放持有的对象锁</font>，进入等待状态，直到其他线程调用相同对象的notify()或notifyAll()方法唤醒他。</li></ul></li><li><strong>使用条件</strong>：<ul><li>sleep可以<font color="#ff0000">在任意位置调用</font>，无需事先获得锁。</li><li>wait必须在<font color="#ff0000">同步块或同步方法内调用</font>，即线程需持有该对象的锁，否则抛出异常。</li></ul></li><li><strong>醒来时机不同</strong>：<ul><li>执行sleep(long)和wait(long)的线程都会在<font color="#ff0000">等待相应毫秒后醒来</font></li><li>wait(long)和wait()还<font color="#ff0000">可以被notify唤醒</font>，wait如果<font color="#ff0000">不唤醒就会一直等下去</font>。</li><li>它们都可以被打断唤醒。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;线程和进程的区别？&quot;&gt;&lt;a href=&quot;#线程和进程的区别？&quot; class=&quot;headerlink&quot; title=&quot;线程和进程的区别？&quot;&gt;&lt;/a&gt;线程和进程的区别？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;本质区别&lt;/strong&gt;：进程是&lt;font color</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="多线程" scheme="http://lixrangel.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>HashMap&amp;ConcurrentHashMap</title>
    <link href="http://lixrangel.com/2025/11/29/java-ba-gu/ji-he/hashmap-concurrenthashmap/"/>
    <id>http://lixrangel.com/2025/11/29/java-ba-gu/ji-he/hashmap-concurrenthashmap/</id>
    <published>2025-11-28T16:00:00.000Z</published>
    <updated>2026-01-18T10:52:23.644Z</updated>
    
    <content type="html"><![CDATA[<h2 id="HashMap的底层实现？"><a href="#HashMap的底层实现？" class="headerlink" title="HashMap的底层实现？"></a>HashMap的底层实现？</h2><h3 id="JDK1-8之前"><a href="#JDK1-8之前" class="headerlink" title="JDK1.8之前"></a>JDK1.8之前</h3><ul><li><strong>数据结构</strong>：<font color="#ff0000">数组</font>+<font color="#ff0000">链表</font>结合在一起使用，也就是<font color="#ff0000">链表散列</font>。</li><li>获取key的hashcode，hashcode经过扰动函数（<code>(h = key.hashCode()) ^ (h &gt;&gt;&gt; 16)</code>）hashcode的高16位和低16位进行异或（这样处理是为了混合高位和低位，以此来加大低位的随机性）处理后得到哈希值，然后通过 <code>(n - 1) &amp; hash</code> 判断当前元素存放的位置。<ul><li>如果当前位置存在元素的话，就判断该元素与要存入元素的hash值（hash值的比较非常快）以及key（key比较很慢）是否相同，如果相同的话，直接覆盖；如果不相同的话就通过拉链法解决冲突。<br><img src="HashMap1.8%E4%BB%A5%E5%89%8D.png" alt="HashMap1.8以前"></li></ul></li></ul><h3 id="JDK1-8之后"><a href="#JDK1-8之后" class="headerlink" title="JDK1.8之后"></a>JDK1.8之后</h3><ul><li><strong>数据结构</strong>：<font color="#ff0000">数组+链表+红黑树</font></li><li><strong>扩容</strong>：当链表长度大于阈值（默认为8），先判断数组长度是不是小于64，如果小于64，则先进行数组的扩容。</li><li><strong>链表-&gt;红黑树</strong>：当数组长度大于64时，将链表转化为红黑树。</li><li><strong>目的</strong>：减少搜索时间。链表的查询效率为O(n)，红黑树的查询效率为O(logn)。当链表较短时，O(n)和O(logn)的性能差异不明显。但当链表变长时，查询性能会显著下降。<br><img src="HashMap1.8%E4%BB%A5%E5%90%8E.png" alt="HashMap1.8以后.png"></li></ul><h2 id="为什么优先扩容而不是直接转化为红黑树？"><a href="#为什么优先扩容而不是直接转化为红黑树？" class="headerlink" title="为什么优先扩容而不是直接转化为红黑树？"></a>为什么优先扩容而不是直接转化为红黑树？</h2><ul><li>数组扩容能<strong>减少哈希冲突的发生概率</strong>，在多数情况下比直接转为红黑树更有效。</li><li>红黑树需要保持自平衡，<strong>维护成本较高</strong>。并且，过早引入红黑树反而会增加复杂度。</li></ul><h2 id="HashMap的长度为什么是2的幂次方？"><a href="#HashMap的长度为什么是2的幂次方？" class="headerlink" title="HashMap的长度为什么是2的幂次方？"></a>HashMap的长度为什么是2的幂次方？</h2><ul><li><strong>位运算效率更高</strong>：位运算比取余运算效率更高。当数组长度为2的幂次方时，<code>hash % length</code> 等价于 <code>hash &amp; (length - 1)</code>。</li><li> <strong>扩容机制变得简单高效</strong>：扩容后<font color="#00b0f0">只需要检查哈希值高位的变化</font>来决定元素的新位置，要么位置不变（高位为0），要么就是移动到新位置（高位为1）。</li><li><strong>可以更好的保证哈希值均匀分布</strong>：扩容之后，在旧数组元素hash值分布比较均匀的情况下，新数组元素也会分配的比较均匀，最好的情况是会有一半在新数组的前半部分，另一半在新数组的后半部分。</li></ul><h2 id="HashMap为什么线程不安全？"><a href="#HashMap为什么线程不安全？" class="headerlink" title="HashMap为什么线程不安全？"></a>HashMap为什么线程不安全？</h2><p>多线程环境下对HashMap进行并发写操作，主要会有两个问题：</p><ol><li><strong>put操作覆盖，数据丢失</strong>：并发put操作可能导致一个线程的写入被另一个线程覆盖。</li><li><strong>无限循环</strong>：在JDK7及以前版本中，并发扩容时，由于头插法可能导致链表形成环，从而在get操作时引发无限循环，cpu飙升至100%。</li></ol><h2 id="HashMap的put流程"><a href="#HashMap的put流程" class="headerlink" title="HashMap的put流程"></a>HashMap的put流程</h2><ul><li><strong>确定位置</strong>：计算key的哈希值，经过扰动函数，结合数组长度计算出存储的索引位置。</li><li><strong>直接插入</strong>：如果数组为空，就触发 <code>resize()</code> 方法进行初始化。然后如果该位置为空，直接插入新节点。</li><li><strong>处理冲突</strong>：如果该位置不为空，则检查头节点是否匹配，如果匹配直接覆盖掉；否则遍历链表/红黑树进行查找或插入（尾插法）。插入后检查链表长度，满足条件则进行树化。</li><li><strong>扩容检查</strong>：如果成功插入了新节点，size会加1。最后判断size是否超过了阈值，如果超过了，就进行扩容。</li></ul><h2 id="ConcurrentHashMap底层原理"><a href="#ConcurrentHashMap底层原理" class="headerlink" title="ConcurrentHashMap底层原理"></a>ConcurrentHashMap底层原理</h2><ul><li><code>ConcurrentHashMap</code>是Java并发包<code>java.util.concurrent</code>下的一个核心类，是一个线程安全的HashMap。在保证线程安全的前提下，通过<strong>降低锁的粒度</strong>来实现最大的并发性能。</li></ul><h3 id="JDK1-7：分段锁（Segment）"><a href="#JDK1-7：分段锁（Segment）" class="headerlink" title="JDK1.7：分段锁（Segment）"></a>JDK1.7：分段锁（Segment）</h3><p><img src="ConcorrentHashMap1.7.png" alt="ConcorrentHashMap1.7"></p><ul><li><strong>底层结构</strong>：<font color="#ff0000">Segment数组+HashEntry数组</font><ul><li>整个Map被分割成多个Segment，每个Segment内部又是一个小的HashMap，管理着自己的HashEntry数组。</li></ul></li><li><strong>锁的粒度</strong>：<font color="#ff0000">Segment本身继承了ReentrantLock</font>，所以每个Segment就是一把可重入锁，不是锁住整个map。并发度就是segment的数量。</li><li><strong>put操作</strong>：首先根据key的哈希值定位到对应的Segment，然后获取这个Segment得到锁，<font color="#ff0000">在锁定的Segment内部进行put操作</font>。</li><li><strong>get操作</strong>：get操作几乎是不加锁的，<font color="#ff0000">依赖volatile关键字</font>保证HashMap数组的内存可见性。</li></ul><h3 id="JDK1-8：CAS-synchronized"><a href="#JDK1-8：CAS-synchronized" class="headerlink" title="JDK1.8：CAS+synchronized"></a>JDK1.8：CAS+synchronized</h3><p><img src="ConcurrentHashMap1.8.png" alt="ConcurrentHashMap1.8"></p><ul><li><strong>底层结构</strong>：<font color="#ff0000">数组+链表+红黑树</font></li><li><strong>锁的粒度</strong>：降低到了哈希桶的头节点</li><li><strong>put操作</strong>：<ul><li>根据key的哈希值计算出数组的槽位</li><li>如果槽位为空，不会加锁，而是<font color="#ff0000">使用CAS尝试原子地将新节点放入</font>，如果失败，则自旋重试。</li><li>如果槽位不为空，即发生冲突了，使用<font color="#ff0000">synchronized关键字锁住这个槽位的头节点</font>。锁住之后，再判断是链表还是红黑树，进行后续的插入或更新操作。</li></ul></li><li><strong>get操作</strong>：get不加锁，node节点的val和next指针都由volatile修饰，保证了内存可见性。</li></ul><h3 id="JDK1-7-vs-JDK1-8"><a href="#JDK1-7-vs-JDK1-8" class="headerlink" title="JDK1.7 vs JDK1.8"></a>JDK1.7 vs JDK1.8</h3><ul><li><strong>锁粒度</strong>：1.7锁segment（是一段数组），1.8锁node（一个节点）。只有在哈希冲突的时候才加锁，大大降低了锁竞争的概率。</li><li><strong>并发性能</strong>：1.8在无冲突的时候完全依赖CAS，性能极高。</li><li><strong>结构</strong>：1.8引入了红黑树，在哈希冲突严重的时候，查询效率也能维持在O(logn)。</li><li><strong>锁的选用</strong>：1.8使用synchronized代替ReentrantLock，是因为JVM对synchronized进行了大量优化，如锁升级，在锁住小代码块的场景下，性能已经不输ReentrantLock。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;HashMap的底层实现？&quot;&gt;&lt;a href=&quot;#HashMap的底层实现？&quot; class=&quot;headerlink&quot; title=&quot;HashMap的底层实现？&quot;&gt;&lt;/a&gt;HashMap的底层实现？&lt;/h2&gt;&lt;h3 id=&quot;JDK1-8之前&quot;&gt;&lt;a href=&quot;#J</summary>
      
    
    
    
    
    <category term="八股" scheme="http://lixrangel.com/tags/%E5%85%AB%E8%82%A1/"/>
    
    <category term="集合" scheme="http://lixrangel.com/tags/%E9%9B%86%E5%90%88/"/>
    
  </entry>
  
</feed>
